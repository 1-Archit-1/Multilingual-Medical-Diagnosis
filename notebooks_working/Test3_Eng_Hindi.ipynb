{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true\n",
      "~/scratch/hf-cache\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# disable Weights and Biases\n",
    "os.environ['WANDB_DISABLED']=\"true\"\n",
    "os.environ[\"HF_HOME\"] = \"~/scratch/hf-cache\"\n",
    "token=\"\"\n",
    "print(os.environ['WANDB_DISABLED'])  # Should output \"true\"\n",
    "print(os.environ['HF_HOME'])  # Should output \"~/scratch/hf-cache\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/ice1/1/2/spadmanabha3/satkp/BigData/LLM/conda/LLM_test/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from datasets import load_dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    GenerationConfig\n",
    ")\n",
    "\n",
    "from trl import SFTTrainer\n",
    "import torch\n",
    "from pynvml import *\n",
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from huggingface_hub import HfApi, login\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from bert_score import score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to ./nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package alpino to ./nltk_data...\n",
      "[nltk_data]    |   Package alpino is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     ./nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]    |     ./nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_eng is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     ./nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_rus to\n",
      "[nltk_data]    |     ./nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_rus is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package basque_grammars to ./nltk_data...\n",
      "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package bcp47 to ./nltk_data...\n",
      "[nltk_data]    |   Package bcp47 is already up-to-date!\n",
      "[nltk_data]    | Downloading package biocreative_ppi to ./nltk_data...\n",
      "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     ./nltk_data...\n",
      "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to ./nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to ./nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown_tei to ./nltk_data...\n",
      "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_cat to ./nltk_data...\n",
      "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_esp to ./nltk_data...\n",
      "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to ./nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to ./nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to ./nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     ./nltk_data...\n",
      "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package comtrans to ./nltk_data...\n",
      "[nltk_data]    |   Package comtrans is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to ./nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to ./nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2007 to ./nltk_data...\n",
      "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
      "[nltk_data]    | Downloading package crubadan to ./nltk_data...\n",
      "[nltk_data]    |   Package crubadan is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     ./nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package dolch to ./nltk_data...\n",
      "[nltk_data]    |   Package dolch is already up-to-date!\n",
      "[nltk_data]    | Downloading package europarl_raw to ./nltk_data...\n",
      "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
      "[nltk_data]    | Downloading package extended_omw to ./nltk_data...\n",
      "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package floresta to ./nltk_data...\n",
      "[nltk_data]    |   Package floresta is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v15 to ./nltk_data...\n",
      "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v17 to ./nltk_data...\n",
      "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to ./nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to ./nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to ./nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to ./nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to ./nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package indian to ./nltk_data...\n",
      "[nltk_data]    |   Package indian is already up-to-date!\n",
      "[nltk_data]    | Downloading package jeita to ./nltk_data...\n",
      "[nltk_data]    |   Package jeita is already up-to-date!\n",
      "[nltk_data]    | Downloading package kimmo to ./nltk_data...\n",
      "[nltk_data]    |   Package kimmo is already up-to-date!\n",
      "[nltk_data]    | Downloading package knbc to ./nltk_data...\n",
      "[nltk_data]    |   Package knbc is already up-to-date!\n",
      "[nltk_data]    | Downloading package large_grammars to ./nltk_data...\n",
      "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package lin_thesaurus to ./nltk_data...\n",
      "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
      "[nltk_data]    | Downloading package mac_morpho to ./nltk_data...\n",
      "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
      "[nltk_data]    | Downloading package machado to ./nltk_data...\n",
      "[nltk_data]    |   Package machado is already up-to-date!\n",
      "[nltk_data]    | Downloading package masc_tagged to ./nltk_data...\n",
      "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     ./nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]    |     ./nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker_tab is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     ./nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger_tab to\n",
      "[nltk_data]    |     ./nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger_tab is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package moses_sample to ./nltk_data...\n",
      "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to ./nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package mte_teip5 to ./nltk_data...\n",
      "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
      "[nltk_data]    | Downloading package mwa_ppdb to ./nltk_data...\n",
      "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to ./nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package nombank.1.0 to ./nltk_data...\n",
      "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     ./nltk_data...\n",
      "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to ./nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to ./nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to ./nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package opinion_lexicon to ./nltk_data...\n",
      "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to ./nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package paradigms to ./nltk_data...\n",
      "[nltk_data]    |   Package paradigms is already up-to-date!\n",
      "[nltk_data]    | Downloading package pe08 to ./nltk_data...\n",
      "[nltk_data]    |   Package pe08 is already up-to-date!\n",
      "[nltk_data]    | Downloading package perluniprops to ./nltk_data...\n",
      "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
      "[nltk_data]    | Downloading package pil to ./nltk_data...\n",
      "[nltk_data]    |   Package pil is already up-to-date!\n",
      "[nltk_data]    | Downloading package pl196x to ./nltk_data...\n",
      "[nltk_data]    |   Package pl196x is already up-to-date!\n",
      "[nltk_data]    | Downloading package porter_test to ./nltk_data...\n",
      "[nltk_data]    |   Package porter_test is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to ./nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package problem_reports to ./nltk_data...\n",
      "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     ./nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     ./nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package propbank to ./nltk_data...\n",
      "[nltk_data]    |   Package propbank is already up-to-date!\n",
      "[nltk_data]    | Downloading package pros_cons to ./nltk_data...\n",
      "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
      "[nltk_data]    | Downloading package ptb to ./nltk_data...\n",
      "[nltk_data]    |   Package ptb is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to ./nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt_tab to ./nltk_data...\n",
      "[nltk_data]    |   Package punkt_tab is already up-to-date!\n",
      "[nltk_data]    | Downloading package qc to ./nltk_data...\n",
      "[nltk_data]    |   Package qc is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to ./nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package rslp to ./nltk_data...\n",
      "[nltk_data]    |   Package rslp is already up-to-date!\n",
      "[nltk_data]    | Downloading package rte to ./nltk_data...\n",
      "[nltk_data]    |   Package rte is already up-to-date!\n",
      "[nltk_data]    | Downloading package sample_grammars to ./nltk_data...\n",
      "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package semcor to ./nltk_data...\n",
      "[nltk_data]    |   Package semcor is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to ./nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     ./nltk_data...\n",
      "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentiwordnet to ./nltk_data...\n",
      "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to ./nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package sinica_treebank to ./nltk_data...\n",
      "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package smultron to ./nltk_data...\n",
      "[nltk_data]    |   Package smultron is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to ./nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     ./nltk_data...\n",
      "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to ./nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to ./nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package subjectivity to ./nltk_data...\n",
      "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to ./nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package switchboard to ./nltk_data...\n",
      "[nltk_data]    |   Package switchboard is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to ./nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets_json to ./nltk_data...\n",
      "[nltk_data]    |   Package tagsets_json is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to ./nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to ./nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to ./nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to ./nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to ./nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to ./nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to ./nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     ./nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     ./nltk_data...\n",
      "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package vader_lexicon to ./nltk_data...\n",
      "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet to ./nltk_data...\n",
      "[nltk_data]    |   Package verbnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet3 to ./nltk_data...\n",
      "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to ./nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wmt15_eval to ./nltk_data...\n",
      "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
      "[nltk_data]    | Downloading package word2vec_sample to ./nltk_data...\n",
      "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to ./nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to ./nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2022 to ./nltk_data...\n",
      "[nltk_data]    |   Package wordnet2022 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to ./nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to ./nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to ./nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package ycoe to ./nltk_data...\n",
      "[nltk_data]    |   Package ycoe is already up-to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the download directory for NLTK data\n",
    "nltk.data.path.append('./nltk_data')\n",
    "nltk.download('all', download_dir='./nltk_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_token_and_login(token_file):\n",
    "    with open(token_file, 'r') as file:\n",
    "        token = file.read().strip()\n",
    "    api = HfApi()\n",
    "    login(token=token)\n",
    "    return api\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_gpu_utilization():\n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(f\"GPU memory occupied: {info.used//1024**2} MB.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pretrained_mbart_large_50_many_to_many_mmt():\n",
    "    model_name = \"facebook/mbart-large-50-many-to-many-mmt\"\n",
    "    tokenizer = MBart50TokenizerFast.from_pretrained(model_name)\n",
    "    model = MBartForConditionalGeneration.from_pretrained(model_name)\n",
    "    return tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_sentences(example):\n",
    "    # Check sentence length\n",
    "    if not (3 < len(example['translation']['en'].split()) < 30):\n",
    "        return False\n",
    "    if not (3 < len(example['translation']['hi'].split()) < 30):\n",
    "        return False\n",
    "    \n",
    "    # Check for non-ASCII non-Unicode characters in Hindi text\n",
    "    if re.search(r'[^\\u0000-\\u007F\\u0900-\\u097F]', example['translation']['hi']):\n",
    "        return False\n",
    "    \n",
    "    # Hook for further restrictions (can be customized)\n",
    "    # Example: if 'specific_word' in example['translation']['en']:\n",
    "    #     return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reduced_dataset(dataset_name, train_size=14000, val_size=2000, test_size=4000):\n",
    "    orig_data_set = load_dataset(dataset_name)\n",
    "    print(orig_data_set)\n",
    "    # Filter the dataset based on the criteria\n",
    "    filtered_dataset = orig_data_set['train'].filter(filter_sentences)\n",
    "    print(filtered_dataset)\n",
    "    \n",
    "    # Split the filtered dataset into train, validation, and test sets\n",
    "    train_val_test_split = filtered_dataset.train_test_split(test_size=val_size + test_size, seed=42)\n",
    "    val_test_split = train_val_test_split['test'].train_test_split(test_size=test_size, seed=42)\n",
    "    \n",
    "    small_data_set = DatasetDict({\n",
    "        'train': train_val_test_split['train'].select(range(train_size)),\n",
    "        'validation': val_test_split['train'],\n",
    "        'test': val_test_split['test']\n",
    "    })\n",
    "\n",
    "    # Verify the size of the new dataset\n",
    "    print(small_data_set)\n",
    "    print(f\"New train set size: {len(small_data_set['train'])}\")\n",
    "    print(f\"New validation set size: {len(small_data_set['validation'])}\")\n",
    "    print(f\"New test set size: {len(small_data_set['test'])}\")\n",
    "    \n",
    "    return small_data_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples, tokenizer):\n",
    "    global last_print_time\n",
    "    current_time = time.time()\n",
    "    \n",
    "    if current_time - last_print_time >= 10:\n",
    "        print(\"Examples:\", examples['translation'][:2])\n",
    "        last_print_time = current_time\n",
    "    \n",
    "    inputs = [ex['en'] for ex in examples['translation'] if ex['en'] is not None]\n",
    "    targets = [ex['hi'] for ex in examples['translation'] if ex['hi'] is not None]\n",
    "    \n",
    "    if current_time - last_print_time >= 10:\n",
    "        print(\"Inputs:\", inputs[:2])\n",
    "        print(\"Targets:\", targets[:2])\n",
    "    \n",
    "    if len(inputs) == 0 or len(targets) == 0:\n",
    "        return {}\n",
    "    \n",
    "    model_inputs = tokenizer(inputs, max_length=128, padding=\"max_length\", truncation=True)\n",
    "    \n",
    "    if current_time - last_print_time >= 10:\n",
    "        print(\"Model Inputs:\", {k: v[:2] for k, v in model_inputs.items()})\n",
    "    \n",
    "    labels = tokenizer(targets, max_length=128, padding=\"max_length\", truncation=True)\n",
    "    \n",
    "    if current_time - last_print_time >= 10:\n",
    "        print(\"Labels:\", {k: v[:2] for k, v in labels.items()})\n",
    "    \n",
    "    if \"input_ids\" not in labels or len(labels[\"input_ids\"]) == 0:\n",
    "        print(\"Labels are empty or not properly structured\")\n",
    "        return {}\n",
    "    \n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    \n",
    "    if current_time - last_print_time >= 10:\n",
    "        print(\"Final Model Inputs:\", {k: v[:2] for k, v in model_inputs.items()})\n",
    "    \n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_model_for_training(model, tokenizer, tokenized_datasets, output_dir=\"./results\", learning_rate=2e-5, batch_size=16, num_train_epochs=5, gradient_accumulation_steps=4):\n",
    "    # Set up training arguments\n",
    "    training_args = Seq2SeqTrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        learning_rate=learning_rate,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        weight_decay=0.01,\n",
    "        save_total_limit=3,\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        predict_with_generate=True,\n",
    "        gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        warmup_steps=500,\n",
    "        logging_dir='./logs',\n",
    "        logging_steps=10,\n",
    "    )\n",
    "\n",
    "    # Initialize the Trainer\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_datasets[\"train\"],\n",
    "        eval_dataset=tokenized_datasets[\"validation\"],\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "    # Freeze all layers except the last few layers\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Unfreeze the last few layers\n",
    "    for param in model.model.decoder.layers[-2:].parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    # Unfreeze the classification head\n",
    "    for param in model.lm_head.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_and_save(trainer, model, tokenizer, output_dir=\"./trained_model\"):\n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "\n",
    "    # Save the trained model and tokenizer\n",
    "    model.save_pretrained(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fine_tuned_model(output_dir=\"./trained_model\"):\n",
    "    model = MBartForConditionalGeneration.from_pretrained(output_dir)\n",
    "    tokenizer = MBart50TokenizerFast.from_pretrained(output_dir)\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_text(model, tokenizer, input_text, src_lang=\"en_XX\", tgt_lang=\"hi_IN\"):\n",
    "    # Tokenize the input text\n",
    "    tokenizer.src_lang = src_lang\n",
    "    encoded_input = tokenizer(input_text, return_tensors=\"pt\")\n",
    "\n",
    "    # Generate translation\n",
    "    generated_tokens = model.generate(\n",
    "        **encoded_input,\n",
    "        forced_bos_token_id=tokenizer.lang_code_to_id[tgt_lang]\n",
    "    )\n",
    "\n",
    "    # Decode the generated tokens\n",
    "    translated_text = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0]\n",
    "    print(\"Translated text:\", translated_text)\n",
    "    return translated_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_test_data(small_data_set, tokenizer, num_examples=200):\n",
    "    # Load the test data\n",
    "    test_data = small_data_set['test']\n",
    "    print(test_data['translation'][0])\n",
    "    print(len(test_data['translation']))\n",
    "    \n",
    "    # Select a subset of the test data\n",
    "    test_data = test_data.select(range(num_examples))\n",
    "    print(test_data['translation'][0])\n",
    "    print(len(test_data['translation']))\n",
    "\n",
    "    # Preprocess the test data\n",
    "    def preprocess_test_data(examples):\n",
    "        inputs = [ex['en'] for ex in examples['translation'] if ex['en'] is not None]\n",
    "        model_inputs = tokenizer(inputs, max_length=128, padding=\"max_length\", truncation=True)\n",
    "        return model_inputs\n",
    "\n",
    "    tokenized_test_data = test_data.map(preprocess_test_data, batched=True, remove_columns=[\"translation\"])\n",
    "    \n",
    "    return test_data, tokenized_test_data\n",
    "\n",
    "#count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_translation_testing(model, tokenizer, test_data, tokenized_test_data, src_lang=\"en_XX\", tgt_lang=\"hi_IN\"):\n",
    "    count = 0\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    count = 0\n",
    "\n",
    "    def generate_translation(batch):\n",
    "        nonlocal count\n",
    "        # Ensure input_ids and attention_mask are tensors\n",
    "        input_ids = torch.tensor(batch[\"input_ids\"]).to(device)\n",
    "        attention_mask = torch.tensor(batch[\"attention_mask\"]).to(device)\n",
    "        \n",
    "        count += 1\n",
    "        print(f\"Processing batch {count}\")\n",
    "        \n",
    "        # Generate translation\n",
    "        generated_tokens = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            forced_bos_token_id=tokenizer.lang_code_to_id[tgt_lang]\n",
    "            #max_length=128,\n",
    "            #num_beams=5,\n",
    "            #early_stopping=True\n",
    "        )\n",
    "        # Decode the generated tokens\n",
    "        batch[\"translation\"] = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "        return batch\n",
    "\n",
    "    translated_test_data = tokenized_test_data.map(generate_translation, batched=True)\n",
    "\n",
    "    # Extract test_data from small_data_set\n",
    "    #test_data = small_data_set['test']\n",
    "\n",
    "    # Print the first 5 translations for inspection\n",
    "    for i in range(5):\n",
    "        print(f\"Original: {test_data[i]['translation']['en']}\")\n",
    "        print(f\"Translated: {translated_test_data[i]['translation']}\")\n",
    "        print(f\"Reference: {test_data[i]['translation']['hi']}\")\n",
    "        print()\n",
    "\n",
    "    return translated_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def evaluate_translations_bertscore(test_data, translated_test_data):\n",
    "    references = [test_data[i]['translation']['hi'] for i in range(len(test_data))]\n",
    "    translations = [translated_test_data[i]['translation'] for i in range(len(test_data))]\n",
    "    \n",
    "    P, R, F1 = score(translations, references, lang=\"hi\", verbose=True)\n",
    "    \n",
    "    # Print BERTScore for each example\n",
    "    for i in range(len(test_data)):\n",
    "        print(f\"Original: {test_data[i]['translation']['en']}\")\n",
    "        print(f\"Translated: {translated_test_data[i]['translation']}\")\n",
    "        print(f\"Reference: {test_data[i]['translation']['hi']}\")\n",
    "        print(f\"BERTScore F1: {F1[i].item():.4f}\")\n",
    "        print()\n",
    "    \n",
    "    print(f\"Average BERTScore F1: {F1.mean().item():.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACTUAL CODE FLOW STARTS NOW!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = read_token_and_login('hf_token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "original_tokenizer, original_model = get_pretrained_mbart_large_50_many_to_many_mmt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 1659083\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 520\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 2507\n",
      "    })\n",
      "})\n",
      "Dataset({\n",
      "    features: ['translation'],\n",
      "    num_rows: 839876\n",
      "})\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 140000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 20000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 40000\n",
      "    })\n",
      "})\n",
      "New train set size: 140000\n",
      "New validation set size: 20000\n",
      "New test set size: 40000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset_name = \"cfilt/iitb-english-hindi\"\n",
    "#small_data_set = get_reduced_dataset(dataset_name)\n",
    "small_data_set = get_reduced_dataset(dataset_name, train_size = 140000, val_size=20000, test_size=40000)\n",
    "# Initialize a global variable to keep track of the last print time\n",
    "last_print_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:  32%|███▏      | 45000/140000 [00:10<00:23, 4115.57 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples: [{'en': 'Undefined identifier \"% 1\".', 'hi': 'अपारिभाषित पहचानकर्ता \"% 1\". '}, {'en': 'My sincere regards to every person who has raised this institution to this height; I congratulate them.', 'hi': 'इस संस्था को इस ऊंचाई पर पहुंचाने वाले प्रत्येक व्यक्ति को मैं आदरपूवर्क नमन करता हूं, उनका अभिनंदन करता हूं।'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:  65%|██████▌   | 91000/140000 [00:20<00:10, 4694.39 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples: [{'en': 'Secretary-General of the United Nations', 'hi': 'संयुक्त राष्ट्र के महासचिव '}, {'en': 'are going to be y is equal to plus or minus b over ax, so', 'hi': 'y है बी शून्य या अधिक के लिए बराबर कुल्हाड़ी से अधिक होने जा रहे हैं तो'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:  97%|█████████▋| 136000/140000 [00:30<00:00, 4300.93 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples: [{'en': 'STARTTLS command failed:% s', 'hi': 'STARTTLS कमांड असफलः% s'}, {'en': 'Please update the following fields:', 'hi': 'कृपया निम्नलिखित क्षेत्र का अद्यतन करेंः'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 140000/140000 [00:31<00:00, 4456.02 examples/s]\n",
      "Map: 100%|██████████| 20000/20000 [00:04<00:00, 4550.79 examples/s]\n",
      "Map:  55%|█████▌    | 22000/40000 [00:04<00:03, 4721.15 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples: [{'en': 'Unable to open URI', 'hi': 'URI खोलने में असमर्थ'}, {'en': 'Tests fundamental GUI application accessibility', 'hi': 'मूलभूत जीयूआई अनुप्रयोग पहुंचनीयता का परीक्षण करता है'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 40000/40000 [00:08<00:00, 4552.89 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = small_data_set.map(lambda examples: preprocess_function(examples, original_tokenizer), batched=True, remove_columns=[\"translation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'en': 'But this disillusionment was with the policies of Stalin and the system prevailing in the Soviet Union, not with Marxism as such.', 'hi': 'परंतु यह मोहभंग स्टालिन की नीतियों और सोवियत संघ की तत्कालीन व्यवस्था से था, मार्क्सवाद से नहीं। '}\n",
      "40000\n",
      "{'en': 'But this disillusionment was with the policies of Stalin and the system prevailing in the Soviet Union, not with Marxism as such.', 'hi': 'परंतु यह मोहभंग स्टालिन की नीतियों और सोवियत संघ की तत्कालीन व्यवस्था से था, मार्क्सवाद से नहीं। '}\n",
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 200/200 [00:00<00:00, 6038.62 examples/s]\n",
      "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 200/200 [00:15<00:00, 12.65 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: But this disillusionment was with the policies of Stalin and the system prevailing in the Soviet Union, not with Marxism as such.\n",
      "Translated: लेकिन यह निराशा स्टालिन की नीतियों और सोवियत संघ में प्रचलित प्रणाली से थी, मार्क्सवाद के रूप में नहीं।\n",
      "Reference: परंतु यह मोहभंग स्टालिन की नीतियों और सोवियत संघ की तत्कालीन व्यवस्था से था, मार्क्सवाद से नहीं। \n",
      "\n",
      "Original: 2. Brief history of the electronics company including products being made, capacities, related collaborators, achievements, capabilities etc. may be provided (including recent annual reports and company brochure)\n",
      "Translated: 2. इलेक्ट्रॉनिक कंपनी का संक्षिप्त इतिहास जिसमें उत्पादों का निर्माण किया जा रहा है, क्षमताएं, संबद्ध सहयोगियों, उपलब्धियां, क्षमताएं आदि उपलब्ध हो सकती हैं (जिसके अंतर्गत हाल के वार्षिक प्रतिवेदन और कंपनी पुस्तिका भी उपलब्ध हो सकती है)\n",
      "Reference: 6. बनाए जाने वाले उत्पा) दक, क्षमताओं, संबंधित सहयोगियों, उपलब्धिषयों, क्षमताओं आदि सहित इलेक्ट्रॉानिक्स् कंपनी का संक्षिप्त, इतिहास उपलब्ध कराया जाए (नवीनतम वार्षिक रिपोर्ट और कंपनी ब्रोशर सहित) \n",
      "\n",
      "Original: On the hills and mountains and particularly on the Himalaya, we find the frittilaries Argynnis, whose home is the grassy meadow.\n",
      "Translated: पहाड़ियों और पर्वतों पर और विशेषकर हिमालय पर हम अर्गिनियों को पाते हैं, जिनके घर घास के मैदान हैं।\n",
      "Reference: पहाडियों और पर्वतों और विशेषतया हिमालय पर हमें आर्गाइनिस तितली मिलती है जो घास के मैदानों की निवासी है। \n",
      "\n",
      "Original: For the seven years preceding the launching of the Eighth Plan, which was delayed by two years, the growth rate works out to 5. 3 per cent per annum.\n",
      "Translated: आठवीं योजना के आरंभ से सात वर्ष पूर्व, जो दो वर्षों से देरी हुई थी, विकास दर  5.3 प्रतिशत प्रति वर्ष थी।\n",
      "Reference: यदि प्रारम्भ में मध्यमवर्गीय व्यक्ति वैज्ञानिक और तकनीकी शिक्षा के पक्ष में नहीं थे, इसका कारण उनके दृष्टिकोण की वजह से कम तथा मांग की कमी से अधिक थी। \n",
      "\n",
      "Original: Select to the previous word\n",
      "Translated: पिछली शब्द में चुनें\n",
      "Reference: परिणामों को लाने में अक्षमQODBCResult\n",
      "\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  4.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 2.72 seconds, 73.64 sentences/sec\n",
      "Original: But this disillusionment was with the policies of Stalin and the system prevailing in the Soviet Union, not with Marxism as such.\n",
      "Translated: लेकिन यह निराशा स्टालिन की नीतियों और सोवियत संघ में प्रचलित प्रणाली से थी, मार्क्सवाद के रूप में नहीं।\n",
      "Reference: परंतु यह मोहभंग स्टालिन की नीतियों और सोवियत संघ की तत्कालीन व्यवस्था से था, मार्क्सवाद से नहीं। \n",
      "BERTScore F1: 0.9028\n",
      "\n",
      "Original: 2. Brief history of the electronics company including products being made, capacities, related collaborators, achievements, capabilities etc. may be provided (including recent annual reports and company brochure)\n",
      "Translated: 2. इलेक्ट्रॉनिक कंपनी का संक्षिप्त इतिहास जिसमें उत्पादों का निर्माण किया जा रहा है, क्षमताएं, संबद्ध सहयोगियों, उपलब्धियां, क्षमताएं आदि उपलब्ध हो सकती हैं (जिसके अंतर्गत हाल के वार्षिक प्रतिवेदन और कंपनी पुस्तिका भी उपलब्ध हो सकती है)\n",
      "Reference: 6. बनाए जाने वाले उत्पा) दक, क्षमताओं, संबंधित सहयोगियों, उपलब्धिषयों, क्षमताओं आदि सहित इलेक्ट्रॉानिक्स् कंपनी का संक्षिप्त, इतिहास उपलब्ध कराया जाए (नवीनतम वार्षिक रिपोर्ट और कंपनी ब्रोशर सहित) \n",
      "BERTScore F1: 0.8007\n",
      "\n",
      "Original: On the hills and mountains and particularly on the Himalaya, we find the frittilaries Argynnis, whose home is the grassy meadow.\n",
      "Translated: पहाड़ियों और पर्वतों पर और विशेषकर हिमालय पर हम अर्गिनियों को पाते हैं, जिनके घर घास के मैदान हैं।\n",
      "Reference: पहाडियों और पर्वतों और विशेषतया हिमालय पर हमें आर्गाइनिस तितली मिलती है जो घास के मैदानों की निवासी है। \n",
      "BERTScore F1: 0.8446\n",
      "\n",
      "Original: For the seven years preceding the launching of the Eighth Plan, which was delayed by two years, the growth rate works out to 5. 3 per cent per annum.\n",
      "Translated: आठवीं योजना के आरंभ से सात वर्ष पूर्व, जो दो वर्षों से देरी हुई थी, विकास दर  5.3 प्रतिशत प्रति वर्ष थी।\n",
      "Reference: यदि प्रारम्भ में मध्यमवर्गीय व्यक्ति वैज्ञानिक और तकनीकी शिक्षा के पक्ष में नहीं थे, इसका कारण उनके दृष्टिकोण की वजह से कम तथा मांग की कमी से अधिक थी। \n",
      "BERTScore F1: 0.6826\n",
      "\n",
      "Original: Select to the previous word\n",
      "Translated: पिछली शब्द में चुनें\n",
      "Reference: परिणामों को लाने में अक्षमQODBCResult\n",
      "BERTScore F1: 0.6816\n",
      "\n",
      "Original: The piquancy of the moment tended to suggest that the only course was to go with the tide.\n",
      "Translated: उस क्षण की सूक्ष्मता इस बात का संकेत करती थी कि ज्वार के साथ ही चलना ही एकमात्र मार्ग है।\n",
      "Reference: आंदोलन के उत्कर्ष से यही संकेत मिलता है कि धारा के साथ चलना ही एकमात्र विकल्प था। \n",
      "BERTScore F1: 0.8103\n",
      "\n",
      "Original: \"% s\": unknown disc image type\n",
      "Translated: \"% s\": अज्ञात डिस्क छवि प्रकार\n",
      "Reference: \"% s\": अज्ञात डिस्क छवि प्रकार\n",
      "BERTScore F1: 1.0000\n",
      "\n",
      "Original: It is for the global giants to seize this opportunity and take lead to forge long-term partnerships.\n",
      "Translated: यह वैश्विक महाकायों के लिए है कि वे इस अवसर का लाभ उठाएं और दीर्घकालिक साझीदारी बनाने के लिए अग्रणी बनें।\n",
      "Reference: यह वैश्विक कंपनियों का दायित्व है कि वे इस अवसर का लाभ उठाएं और दीर्घकालिक साझेदारियां स्थापित करने के लिए आगे आएं।\n",
      "BERTScore F1: 0.9013\n",
      "\n",
      "Original: In return of this, Portuguese gave passes to Akbar 's family for Hajj.\n",
      "Translated: इसके बदले पुर्तगालियों ने अकबर के परिवार को हज के लिए पास दिये।\n",
      "Reference: इसके बदले में पुर्तगालियों ने अकबर के परिवार के लिये हज को जाने हेतु पास जारी किये थे। \n",
      "BERTScore F1: 0.9238\n",
      "\n",
      "Original: 2. The above appointments will take effect from the dates they assume charge of their respective offices.\n",
      "Translated: 2. उपर्युक्त नियुक्तियां उन तारीखों से प्रभावी होंगी जब वे अपने संबंधित कार्यालयों के लिए उत्तरदायी होंगे।\n",
      "Reference: 2. उपर्युक्त नियुक्तियां, सम्बंधित राज्यपालों द्वारा अपना-अपना कार्यभार ग्रहण करने की तिथियों से प्रभावी होंगी।\n",
      "BERTScore F1: 0.8324\n",
      "\n",
      "Original: More than 1000 accessions have been collected and characterized.\n",
      "Translated: 1000 से अधिक सदस्यों को एकत्रित किया गया है और उनकी पहचान की गई है।\n",
      "Reference: देश भर से लगभग 1000 नमूने जुटाकर उनकी पहचान की गयी है। \n",
      "BERTScore F1: 0.8065\n",
      "\n",
      "Original: prothrombin is blood coagulant\n",
      "Translated: प्रोथ्रोम्बिन रक्त कोशक होता है\n",
      "Reference: प्रोथ्रॅम्बाइन एन्जाइम एक रक्त स्कंदक है\n",
      "BERTScore F1: 0.8188\n",
      "\n",
      "Original: Connection to% s timed out. Abort?\n",
      "Translated: % s से कनेक्शन समय समाप्त हो गया. परित्याग करें?\n",
      "Reference: % s से सम्बन्ध बंद हो गया\n",
      "BERTScore F1: 0.7874\n",
      "\n",
      "Original: And they ask thee of Zul Qarnain. Say thou: shall recite unto you of him some mention.\n",
      "Translated: और (ऐ रसूल) तुमसे लोग ज़ुल क़ारनैन के बारे में पूछते हैं (ऐ रसूल) तुम कह दो कि मैं तुमको उसके बारे में कुछ बयान कर दूँगा\n",
      "Reference: और (ऐ रसूल) तुमसे लोग ज़ुलक़रनैन का हाल (इम्तेहान) पूछा करते हैं तुम उनके जवाब में कह दो कि मैं भी तुम्हें उसका कुछ हाल बता देता हूँ\n",
      "BERTScore F1: 0.8355\n",
      "\n",
      "Original: The suggestion was made that the Government should bear all the expenses.\n",
      "Translated: यह सुझाव दिया गया कि सरकार को सभी खर्च उठाना चाहिए।\n",
      "Reference: एक सुझाव यह आया था कि सरकार को पूरा खर्चा उठाना चाहिए। \n",
      "BERTScore F1: 0.9067\n",
      "\n",
      "Original: ions and then water, if you make this porous only to\n",
      "Translated: आयनों और फिर पानी, यदि आप सिर्फ इस porous करने के लिए कर रहे हैं\n",
      "Reference: आयनों और फिर पानी, अगर तुम यह केवल करने के लिए असुरक्षित बना\n",
      "BERTScore F1: 0.8100\n",
      "\n",
      "Original: An alcoholic beverage made by distillation rather than by fermentation.\n",
      "Translated: एक अल्कोहलीय पेय जो उष्मा के बजाय डिस्टिलन द्वारा बनाया जाता है।\n",
      "Reference: एक अल्कोहलीय पेय जो किण्वन के बजाए आसवन विधि द्वारा निर्मित होता है\n",
      "BERTScore F1: 0.8469\n",
      "\n",
      "Original: Lord of the heavens and the earth, and everything between them; and Lord of the Easts.\n",
      "Translated: आकाशों और धरती का रब और जो कुछ इन दोनों के बीच है उसका रब और पूर्वों का रब\n",
      "Reference: वह आकाशों और धरती और जो कुछ उनके बीच है सबका रब है और पूर्व दिशाओं का भी रब है\n",
      "BERTScore F1: 0.8560\n",
      "\n",
      "Original: He made it clear to the court that the legal adviser would neither cross - examine the witness, nor address the court.\n",
      "Translated: उसने अदालत को स्पष्ट कर दिया कि विधिक सलाहकार न तो गवाह की जांच करेगा और न अदालत को संबोधित करेगा.\n",
      "Reference: उन्होंने अदालत के सामने यह स्पष्ट किया कि यह कानूनी परामर्शदाता न तो गवाहों से जिरह करेगा और न ही न्यायालय को संबोधित करेगा। \n",
      "BERTScore F1: 0.8697\n",
      "\n",
      "Original: Import Lotus Notes Emails\n",
      "Translated: लोटस नोट्स ईमेल आयात करें\n",
      "Reference: लोटस नोट्स ई-मेल आयात करें\n",
      "BERTScore F1: 0.9489\n",
      "\n",
      "Original: have it reflected in their feelings -\n",
      "Translated: कि वह उनके भावों में प्रतिबिंबित हो जाए-\n",
      "Reference: और ऐसे की वो प्रतिबिम्बित हो उनके अहसासों में\n",
      "BERTScore F1: 0.7928\n",
      "\n",
      "Original: For this it is important that the URL has been used before.\n",
      "Translated: इसके लिए यह महत्वपूर्ण है कि यूआरएल पहले से ही प्रयोग किया गया हो।\n",
      "Reference: इसके लिये जरूरी है कि वह URL पहले प्रयोग किया गया हो। \n",
      "BERTScore F1: 0.8257\n",
      "\n",
      "Original: It is the decompression utility corresponding to gzip which is a GNU compression utility.\n",
      "Translated: यह जीएनयू कम्प्रिशन यूटिलिटी है जो जीजीपी के अनुरूप डिकम्प्रिशन यूटिलिटी है।\n",
      "Reference: यह् जी सिप के समांतर असंपीडनीय उपयोगिता है जो एक जी एन यू संपीडनीय उपयोगिता भी है। \n",
      "BERTScore F1: 0.7298\n",
      "\n",
      "Original: And at daybreak a determined punishment came upon them.\n",
      "Translated: और सुबह होते ही उन पर सख्त अज़ाब नाज़िल हुआ\n",
      "Reference: सुबह सवेरे ही एक अटल यातना उनपर आ पहुँची, \n",
      "BERTScore F1: 0.7418\n",
      "\n",
      "Original: Your letter have been disapproved.\n",
      "Translated: आपका पत्र अस्वीकृत कर दिया गया है।\n",
      "Reference: तुम्हारे पत्रों का अननुमोदन किया गया। \n",
      "BERTScore F1: 0.7785\n",
      "\n",
      "Original: Copies the text from the selected cells and places it on the clipboard\n",
      "Translated: चयनित कक्षों से पाठ को प्रतिलिपि बनाता है और इसे क्लिपबोर्ड पर रखता है\n",
      "Reference: चयनित कक्षों से पाठ की नक़ल करता है तथा इसे क्लिपबोर्ड में रखता है\n",
      "BERTScore F1: 0.9180\n",
      "\n",
      "Original: The act of expanding in form of branches.\n",
      "Translated: शाखाओं के रूप में विस्तार करने की क्रिया।\n",
      "Reference: मुख्य व्यवसाय को शाखाओं के रूप में विस्तारित करने का कार्य। \n",
      "BERTScore F1: 0.8676\n",
      "\n",
      "Original: saying how quickly do 7 people consume cans over some period,\n",
      "Translated: कहते हैं कि सात लोग किस तरह से जल्दी कुछ अवधि के दौरान बर्तनों का उपयोग करते हैं,\n",
      "Reference: कहाँ एक लिए कितनी जल्दी 7 लोग कुछ समय मैं ख़तम कर लेंगे\n",
      "BERTScore F1: 0.6754\n",
      "\n",
      "Original: There was continous increment in the severity of the symptoms of disease.\n",
      "Translated: रोग के लक्षणों की गंभीरता में निरंतर वृद्धि हुई।\n",
      "Reference: बीमारी के लक्षणों की कठोरता में लगातार बृद्धि हुई। \n",
      "BERTScore F1: 0.9089\n",
      "\n",
      "Original: nor are the living and the dead. God makes to listen whomever He wants. (Muhammad), you cannot make people in the graves to listen.\n",
      "Translated: और न जीवित और निर्जीव है। अल्लाह जिसे चाहता है सुनाता है। तुम कब्रों में रहनेवालों को सुना नहीं सकते\n",
      "Reference: और न जीवित और मृत बराबर है। निश्चय ही अल्लाह जिसे चाहता है सुनाता है। तुम उन लोगों को नहीं सुना सकते, जो क़ब्रों में हो। \n",
      "BERTScore F1: 0.8654\n",
      "\n",
      "Original: I got an opportunity to know about the work of Jonas Masetti, also known as Vishwanath.\n",
      "Translated: मुझे जोनास मासेटी के कार्य के बारे में जानने का अवसर मिला, जिसे विश्वनाथ भी कहते हैं।\n",
      "Reference: मुझे जोनास मैसेट्टी के काम के बारे में जानने का मौका मिला, जिसे विश्वनाथ के नाम से भी जाना जाता है।\n",
      "BERTScore F1: 0.9089\n",
      "\n",
      "Original: Therefore body, mind and orgrans when not performing correctly is also called as disease\n",
      "Translated: इसीलिए शरीर, मन और अंगूरों का सही कार्य न करने पर रोग भी कहा जाता है।\n",
      "Reference: अतः शरीर & #44; इंद्रिय और मन के प्राकृतिक (स्वाभाविक) रूप या क्रिया में विकृति होना रोग है। \n",
      "BERTScore F1: 0.7510\n",
      "\n",
      "Original: Retrieving message '% s' in% s\n",
      "Translated: संदेश '% s' को% s में प्राप्त कर रहा है\n",
      "Reference: संदेश '% s' की पुनर्प्राप्ति% s में\n",
      "BERTScore F1: 0.8256\n",
      "\n",
      "Original: Rotates the earth counterclockwise around its axis.\n",
      "Translated: अपने अक्ष के चारों ओर पृथ्वी को घड़ी की विपरीत दिशा में घुमाता है.\n",
      "Reference: पृथ्वी को इसके अक्ष के चारों ओर घड़ी के विपरीत दिशा में घुमाता है. \n",
      "BERTScore F1: 0.9582\n",
      "\n",
      "Original: In Orissa, the puppeteer plays on the dholak with one hand and manipulates the puppet with the other.\n",
      "Translated: उड़ीसा में पुतलीकार एक हाथ से दोलक पर खेलता है और दूसरी हाथ से पुतली का manipulation करता है।\n",
      "Reference: उड़ीसा में संचालक एक हाथ में ढोलक बजाता है और दूसरे हाथ से पुतले का संचालन करता है ।\n",
      "BERTScore F1: 0.8883\n",
      "\n",
      "Original: Allow backlight brightness adjustment\n",
      "Translated: बैकलाइट चमकीलापन समायोजन अनुमति दें\n",
      "Reference: बैकलाइट ब्राइटनेस एडजस्टमेंट स्वीकारें\n",
      "BERTScore F1: 0.7557\n",
      "\n",
      "Original: But I think you get what I 'm saying.\n",
      "Translated: लेकिन मुझे लगता है कि आप क्या मैं कह रहा हूँ मिलता है।\n",
      "Reference: लेकिन मुझे लगता है कि तुम हो कि मैं क्या कह रहा हूँ। \n",
      "BERTScore F1: 0.9179\n",
      "\n",
      "Original: Socialist leader and ex - M. P., Shishir Kumar, reminisced that J. P. embarked on its full preparation.\n",
      "Translated: समाजवादी नेता और पूर्व सांसद शिशिर कुमार ने यह याद दिलाया कि जे. पी. पूरी तरह से इसकी तैयारी कर रही है।\n",
      "Reference: समाजवादी नेता और पूर्व सांसद श्री शिशिर कुमार ने बताया कि जे. पी. इसके लिए पूरी तैयारी शुरू कर चुके थे। \n",
      "BERTScore F1: 0.9154\n",
      "\n",
      "Original: Paying homage and respect to Pandit Govind Ballabh Pant, the President stated that he was a great visionary leader and a front ranker in India’s national movement.\n",
      "Translated: पंडित गोविंद बलabh पंत को श्रद्धांजलि अर्पित करते हुए राष्ट्रपति ने कहा कि वे एक महान दूरदर्शी नेता थे और भारत के राष्ट्रीय आंदोलन में अग्रणी थे।\n",
      "Reference: पंडित गोविंद बल्लभ पंत को श्रद्धांजलि देते हुए राष्ट्रपति ने कहा कि वह एक महान दूरद्रष्टा नेता तथा भारत के स्वतंत्रता आंदोलन के अग्रणी व्यक्तियों में से थे।\n",
      "BERTScore F1: 0.8955\n",
      "\n",
      "Original: into my car and drive 300 miles on it! \"I mean, it 's all about what you do; none of\n",
      "Translated: मेरे कार में और उस पर 300 मील ड्राइव! \"मैं मतलब है, यह सब के बारे में है कि आप क्या करते हैं, कोई भी\n",
      "Reference: मेरी कार और ड्राइव में मैं उस पर 300 मील की दूरी पर \"! मतलब है, यह सब के बारे में आप क्या करते है, में से कोई भी \n",
      "BERTScore F1: 0.8695\n",
      "\n",
      "Original: they will not play the game again, they don 't know each other,\n",
      "Translated: वे खेल फिर नहीं खेलेंगे, वे एक-दूसरे को नहीं जानते,\n",
      "Reference: वो दुबारा भी साथ कभी नहीं खेलेंगे, वो एक दूसरे को जानते भी नहीं हैं, \n",
      "BERTScore F1: 0.8670\n",
      "\n",
      "Original: Spool mail file% s\n",
      "Translated: स्पूल डाक फ़ाइल% s\n",
      "Reference: % s स्पूल डाक फ़ाइल\n",
      "BERTScore F1: 0.9556\n",
      "\n",
      "Original: But we know we 're not perfect, and if you' re not happy with what Social Services has done, you 've got the right to complain about it.\n",
      "Translated: लेकिन हम जानते हैं कि हम पूर्ण नहीं हैं, और अगर आप सामाजिक सेवाओं ने क्या किया है से खुश नहीं हैं, तो आप इसके बारे में शिकायत करने का अधिकार है.\n",
      "Reference: लेकिन हमें पता है हम परिपक्व नही हैं, और अगर आप सामाजिक सेवाएं (Social Services) के काम से नाराज हैं तो आपको शिकायत करने का अधिकार है। \n",
      "BERTScore F1: 0.8383\n",
      "\n",
      "Original: Then he was a clinging clot, and [Allah] created [his form] and proportioned [him]\n",
      "Translated: फिर वह एक झुकनेवाली क़िस्म का वस्त्र था। उसने उसे पैदा किया और उसे ठीक-ठाक बनाया\n",
      "Reference: फिर लोथड़ा हुआ फिर ख़ुदा ने उसे बनाया\n",
      "BERTScore F1: 0.7039\n",
      "\n",
      "Original: Kya Mast Hai Life\n",
      "Translated: Kya Mast Hai Life\n",
      "Reference: क्या मस्त है लाइफ\n",
      "BERTScore F1: 0.6939\n",
      "\n",
      "Original: the time was much more memorable.\n",
      "Translated: समय बहुत अधिक यादगार था।\n",
      "Reference: वह समय बहुत ज्यादा यादगार था। \n",
      "BERTScore F1: 0.9269\n",
      "\n",
      "Original: Unable to load template% 1\n",
      "Translated: टेम्प्लेट% 1 लोड करने में असमर्थ\n",
      "Reference: प्रारूप% 1 लोड करने में अक्षम\n",
      "BERTScore F1: 0.8648\n",
      "\n",
      "Original: 9. In section 28 of the Income-tax Act, with effect from the 1st day of April, 2019,—\n",
      "Translated: 9. आय-कर अधिनियम की धारा 28 में, 1 अप्रैल, 2019 से,–\n",
      "Reference: 9. आय-कर अधिनियम की धारा 28 में, 1 अप्रैल, 2019 से,-\n",
      "BERTScore F1: 0.9766\n",
      "\n",
      "Original: The intermingling of culinary cultures of India and China has resulted in a new genre of Chinese food, popular in India, called the Indo-Chinese.\n",
      "Translated: भारत और चीन की पाक-कलाओं के मेल-मिलने के परिणामस्वरूप भारत में लोकप्रिय एक नए प्रकार का चीनी खाना हुआ है जिसे इंडो-चीनी कहा जाता है।\n",
      "Reference: भारत और चीन की पाक संस्कृतियों के मिलन से भारत में लोकप्रिय चीनी भोजन की एक नई शैली विकसित हुई है, जिसे भारतीय-चीनी कहा जाता है।\n",
      "BERTScore F1: 0.8805\n",
      "\n",
      "Original: COMMAND The (optional) command to explain\n",
      "Translated: व्याख्या करने के लिए कमांड (वैकल्पिक)\n",
      "Reference: आदेश (वैकल्पिक) की व्याख्या के लिए आदेश\n",
      "BERTScore F1: 0.8400\n",
      "\n",
      "Original: They wish that thou shouldst compromise, then they would compromise.\n",
      "Translated: वे चाहते है कि तुम समझौता करो, फिर वे समझौता करेंगे\n",
      "Reference: वह लोग ये चाहते हैं कि अगर तुम नरमी एख्तेयार करो तो वह भी नरम हो जाएँ\n",
      "BERTScore F1: 0.7735\n",
      "\n",
      "Original: I hope these thoughts will result in speedy action and better cities in the near future.\n",
      "Translated: मुझे उम्मीद है कि इन विचारों के परिणामस्वरूप शीघ्र कार्रवाई तथा निकट भविष्य में बेहतर शहरों का निर्माण हो जाएगा।\n",
      "Reference: मुझे उम्मीद है कि इन विचारों के परिणामस्वरूप,कार्यमें तेजी आएगी तथा निकट भविष्य में बेहतर शहर बनेंगे।\n",
      "BERTScore F1: 0.8783\n",
      "\n",
      "Original: I do not worship what you worship.\n",
      "Translated: मैं उन चीज़ों की बन्दगी नहीं करता जिनकी तुम बन्दगी करते हो\n",
      "Reference: तुम जिन चीज़ों को पूजते हो, मैं उनको नहीं पूजता\n",
      "BERTScore F1: 0.7895\n",
      "\n",
      "Original: This is an instrument seen invariably in kathakali, koodiyattam and related forms of dance.\n",
      "Translated: यह एक ऐसा वाद्य है जो कठकली, कोडiyattam तथा संबंधित नृत्य रूपों में निरंतर देखा जाता है।\n",
      "Reference: यह कथकलि, कोडियाट्टम तथा उनसे मिलते जुलते नृत्यों में हमेशा बजाया जाने वाला वाद्य है। \n",
      "BERTScore F1: 0.8099\n",
      "\n",
      "Original: 1 times 4, so we 're really adding 4 to the left - hand\n",
      "Translated: 1 गुना 4, तो हम वास्तव में 4 देब्रे हाथ में जोड़ रहे हैं\n",
      "Reference: 1 बार 4, तो हम वास्तव में 4 करने के लिए बाएँ हाथ जोड़ रहे हैं\n",
      "BERTScore F1: 0.8724\n",
      "\n",
      "Original: Sister Nivedita 's real difficulty in running the school was financial.\n",
      "Translated: स्कूल चलाने में बहन निवेदिता की वास्तविक कठिनाई आर्थिक थी।\n",
      "Reference: सिस्टर निवेदिता को स्कूल चलाने में वस्तुतया आर्थिक कठिनाई का ही सामना करना पड़ता था। \n",
      "BERTScore F1: 0.8272\n",
      "\n",
      "Original: Soils suitable for rice production are those with a pH of around 6. 0.\n",
      "Translated: चावल उत्पादन के लिए उपयुक्त मिट्टी लगभग 6.0 पी एच वाली होती है।\n",
      "Reference: चावल उत्पादन के लिए उपयुक्त मिट्टी 6.0 प्रतिशत फासफोरस वाली होती है। \n",
      "BERTScore F1: 0.9270\n",
      "\n",
      "Original: Simulation of data DVD copying\n",
      "Translated: डेटा डीवीडी प्रतिलिपि का अनुकरण\n",
      "Reference: आँकड़ा डीवीडी की नक़ल में सिमुलेशन\n",
      "BERTScore F1: 0.7576\n",
      "\n",
      "Original: “You 've achieved nothing, commit. “तुमने\n",
      "Translated: तुमने कुछ भी नहीं हासिल किया है, वचन दें।\n",
      "Reference: कुछ भी हासिल नहीं किया है\n",
      "BERTScore F1: 0.7920\n",
      "\n",
      "Original: Poultry Venture Capital Fund (Subsidy)\n",
      "Translated: मुर्गी उद्यम पूंजी निधि ( सब्सिडी)\n",
      "Reference: पोल्ट्री जोखिम पूंजी निधि (वेंचर कैपिटल फंड) (सब्सिडी) \n",
      "BERTScore F1: 0.8426\n",
      "\n",
      "Original: Number of categories to display at once:\n",
      "Translated: एक ही बार प्रदर्शित करने के लिए श्रेणियों की संख्याः\n",
      "Reference: श्रेणियों की संख्या जिन्हें एक साथ प्रदर्शित करना हैः\n",
      "BERTScore F1: 0.8454\n",
      "\n",
      "Original: Jack was suffering from many ailments.\n",
      "Translated: जैक अनेक बीमारियों से पीड़ित था।\n",
      "Reference: जैक कई व्याधियों से पीड़ित था। \n",
      "BERTScore F1: 0.9358\n",
      "\n",
      "Original: The initiative involves multiple levels of interactions among the overseas experts and Indian counterparts over a month-long series of webinars and video conferences.\n",
      "Translated: इस पहल में विदेशी विशेषज्ञों और भारतीय प्रतिस्पर्धियों के बीच एक महीने की श्रृंखला के विनिटरों और वीडियो कांफ्रेंसों के माध्यम से विभिन्न स्तरों की बातचीत शामिल है।\n",
      "Reference: लगभग एक माह लंबा चलने वाले इस सम्मेलन में वीडियो कांफ्रेंस तथा विभिन्न वेबिनार्स के माध्यम से अप्रवासी और भारतीय नव उद्यमियों के बीच परामर्श का अवसर मिलेगा।\n",
      "BERTScore F1: 0.7763\n",
      "\n",
      "Original: \"The teletype scanner was gronked, so we took the system down”\n",
      "Translated: \"टेली-टाइप स्कैनर को झुका दिया गया था, तो हमने सिस्टम को नीचे ले लिया”\n",
      "Reference: \"टेलिटाइप स्कैनर अवरुद्ध था, इसलिए हमने उसे अचेत कर दिया।\" \n",
      "BERTScore F1: 0.8149\n",
      "\n",
      "Original: No collateral up to Rs. 50, 000 for farm loans and up to Rs. 5 lakhs for setting up agri - clinic and agri - business units.\n",
      "Translated: कृषि ऋणों के लिए रु. 50,000 तक कोई जमानत नहीं और कृषि क्लिनिक और कृषि व्यवसाय इकाइयों की स्थापना के लिए रु. 5 लाख तक कोई जमानत नहीं।\n",
      "Reference: 50 हज़ार रुपये तक कृषि ऋणों के लिए कोई प्रतिभूति नहीं तथा एग्री-क्लीनिक और एग्री बिज़नेस ईकाई की स्थापना हेतु 5 लाख रुपये। \n",
      "BERTScore F1: 0.7903\n",
      "\n",
      "Original: with ambition grabbing at opportunity.\n",
      "Translated: महत्वाकांक्षा के साथ अवसर को पकड़ने के साथ।\n",
      "Reference: महत्वाकांक्षा अवसर पर हथियाने के साथ. \n",
      "BERTScore F1: 0.8983\n",
      "\n",
      "Original: Thus he could become a gopi and he does it chiding Lord Krishna for having deserted her and gone away after the kine.\n",
      "Translated: इस प्रकार वह गोपी बन सकता है और वह भगवान कृष्ण को चिंघाड़ता है कि उसने उसे छोड़ दिया है और जानवर के पीछे चला गया है।\n",
      "Reference: इसी करण, वे गोपी बनकर भगवान कृष्ण की भर्त्सना कर सके जैसा कि उन्होंने किया भी है कि वे उसे छोड़कर ढोर चराने चले गये। \n",
      "BERTScore F1: 0.7696\n",
      "\n",
      "Original: When battery is at warning level\n",
      "Translated: जब बैटरी चेतावनी स्तर पर है\n",
      "Reference: जब बैटरी चेतावनी स्तर पर हो\n",
      "BERTScore F1: 0.9748\n",
      "\n",
      "Original: After infants are weaned from breast milk to a protein - deficient diet of starchy gruels or sugar water.\n",
      "Translated: शिशुओं को स्तन से दूध पिलाकर स्टार्चयुक्त गेरूल्स या चीनी पानी से प्रोटीन-अल्प आहार के रूप में दूध पिलाया जाता है।\n",
      "Reference: उस समय बच्चों को स्तनपान से अलग कर प्रोटीन की कमी वाला पोषण (मांड़ या चीनी-पानी का घोल) दिया जाता है। \n",
      "BERTScore F1: 0.7881\n",
      "\n",
      "Original: One cannot separate his spiritual experience and his poems.\n",
      "Translated: उनके आध्यात्मिक अनुभव और उनकी कविताओं को अलग नहीं कर सकते।\n",
      "Reference: वास्तव में, वह एक अभिज्ञ कवि नहीं थे।\n",
      "BERTScore F1: 0.7039\n",
      "\n",
      "Original: Which, then, of the benefits of your Lord will ye twain belie?\n",
      "Translated: तो तुम दोनों अपने परवरदिगार की किस किस नेअमत को झुठलाओगे\n",
      "Reference: फिर तुम दोनों अपने रब के सामर्थ्यों में से किस-किस को झुठलाओगे? \n",
      "BERTScore F1: 0.8133\n",
      "\n",
      "Original: (Iblis) said: \"O my Lord! give me then respite till the Day the (dead) are raised.\"\n",
      "Translated: उसने कहा, \"ऐ मेरे रब! मुझे उस दिन तक मुहलत दे, जबकि उठाए जाएँगे।\"\n",
      "Reference: शैतान ने कहा ऐ मेरे परवरदिगार ख़ैर तू मुझे उस दिन तक की मोहलत दे जबकि (लोग दोबारा ज़िन्दा करके) उठाए जाएँगें\n",
      "BERTScore F1: 0.7800\n",
      "\n",
      "Original: So you should always think about it in your head, OK,,\n",
      "Translated: तो आप हमेशा अपने दिमाग में इसके बारे में सोचना चाहिए, ठीक है,,\n",
      "Reference: तो यह आप हमेशा दिमाग़ में सोचोगे, ओक,, \n",
      "BERTScore F1: 0.8065\n",
      "\n",
      "Original: There is a shallow domed bowl at the top, which was intended to be filled with burning oil at special occasions.\n",
      "Translated: ऊपर एक पतली नीले बौली है, जो विशेष अवसरों पर जलती हुई तेल से भरी जानी चाहिए थी।\n",
      "Reference: इसके शीर्ष पर उथला गोलाकार बाउलनुमा आकार है जिसे विशेष अवसरों पर जलते हुए तेल से भरने के लिए बनाया गया था। \n",
      "BERTScore F1: 0.8076\n",
      "\n",
      "Original: It is still appropriate, as it involves local material and local skill for its fabrication.\n",
      "Translated: यह अभी भी उपयुक्त है, क्योंकि इसके निर्माण के लिए स्थानीय सामग्री और स्थानीय कौशल शामिल है।\n",
      "Reference: यह अब भी प्रासंगिक है, क्योंकि इसे बनाने के लिए स्थानीय सामग्री तथा स्थानीय कौशल की आवश्यकता होती है। \n",
      "BERTScore F1: 0.9014\n",
      "\n",
      "Original: The widget the menu is attached to\n",
      "Translated: विजेट जिसमें मेनू संलग्न है\n",
      "Reference: विज़ेट जिसमें मेन्यू संलग्न है\n",
      "BERTScore F1: 0.9124\n",
      "\n",
      "Original: The people of India are grateful to our Armed Forces for their exemplary professionalism, commitment and bravery in defending our nation.\n",
      "Translated: भारत की जनता हमारे सशस्त्र बलों को हमारे राष्ट्र की रक्षा में उनकी अनुकरणीय पेशेवरता, प्रतिबद्धता और वीरता के लिए कृतज्ञ है।\n",
      "Reference: भारत की जनता, सशस्त्र बलों द्वारा राष्ट्र की रक्षा करने में उनके अनुकरणीय कार्य-कौशल, प्रतिबद्धता एवं बहादुरी के लिए कृतज्ञ है। \n",
      "BERTScore F1: 0.8923\n",
      "\n",
      "Original: As I see it, it does not matter where the cause of action arises.\n",
      "Translated: मेरे विचार से यह कोई बात नहीं है कि कार्य का कारण कहाँ से उत्पन्न होता है।\n",
      "Reference: मेरे अनुसार, इससे कोई फरक नहीं पड़ता कि कार्रवाई कि वजह कहाँ से आती है\n",
      "BERTScore F1: 0.7866\n",
      "\n",
      "Original: Nay, but when the earth is ground to atoms, grinding, grinding,\n",
      "Translated: नहीं, बल्कि जब धरती को टुकड़े-टुकड़े करके चूर्ण-विचूर्ण कर दिया जाएगा,\n",
      "Reference: सुन रखो कि जब ज़मीन कूट कूट कर रेज़ा रेज़ा कर दी जाएगी\n",
      "BERTScore F1: 0.6978\n",
      "\n",
      "Original: The gender ratio is for 1000 men there are 933 women.\n",
      "Translated: लिंग अनुपात 1000 पुरूषों के लिए 933 स्त्रियों का है।\n",
      "Reference: लिंग अनुपात की दृष्टि से भारत में प्रत्येक १००० पुरुषों के पीछे मात्र ९३३ महिलायें हैं। \n",
      "BERTScore F1: 0.7853\n",
      "\n",
      "Original: Which kind of shadow to draw around the combo box\n",
      "Translated: कम्बो बॉक्स के चारों ओर कौन सा छाया बनाएँ\n",
      "Reference: कोंबो बॉक्स के गिर्द किस प्रकार की छाया खींचनी है\n",
      "BERTScore F1: 0.8197\n",
      "\n",
      "Original: because they have to look after animals -\n",
      "Translated: क्योंकि उन्हें जानवरों की देखभाल करनी होती है-\n",
      "Reference: क्योंकि उन्हें जानवरों की देखभाल करनी होती है-\n",
      "BERTScore F1: 1.0000\n",
      "\n",
      "Original: He expressed hope that these two dharamshalas would be of benefit to the pilgrims from both Nepal and India.\n",
      "Translated: उन्होंने आशा व्यक्त की कि ये दो धर्मशालाएं नेपाल और भारत दोनों देशों के यात्रियों के लिए लाभदायक होगी।\n",
      "Reference: मुझे आशा है कि ये दोनों धर्मशालाएं नेपाल और भारत दोनों देशों के तीर्थ यात्रियों के लिए लाभदायक होंगी।\n",
      "BERTScore F1: 0.9188\n",
      "\n",
      "Original: They said: \"We found our fathers worshipping them.\"\n",
      "Translated: उन्होंने कहा, \"हमने अपने बाप-दादा को उनको पूजते पाया।\"\n",
      "Reference: वे बोले, \"हमने अपने बाप-दादा को इन्हीं की पूजा करते पाया है।\" \n",
      "BERTScore F1: 0.9126\n",
      "\n",
      "Original: What aileth you? How judge ye?\n",
      "Translated: तुम्हें क्या हो गया है? तुम कैसा फ़ैसला करते हो?\n",
      "Reference: तुम्हें क्या हो गया है? तुम कैसा फ़ैसला करते हो? \n",
      "BERTScore F1: 1.0000\n",
      "\n",
      "Original: We never sent a warner to any town but its wealthy ones said: “We disbelieve in the Message you have brought. ”\n",
      "Translated: और (ऐ रसूल) हमने तो कभी किसी बस्ती में कोई डराने वाला पैग़म्बर नहीं भेजा मगर वहाँ के चन्द सरदारों ने कहा था कि जो (अज़ाब) तुमने नाज़िल किया है हम तो उसको नहीं मानते\n",
      "Reference: हमने जिस बस्ती में भी कोई सचेतकर्ता भेजा तो वहाँ के सम्पन्न लोगों ने यही कहा कि \"जो कुछ देकर तुम्हें भेजा गया है, हम तो उसको नहीं मानते।\" \n",
      "BERTScore F1: 0.7717\n",
      "\n",
      "Original: But on two occasions he got involved in specific controversies without really intending to provoke anybody.\n",
      "Translated: लेकिन दो बार वे बिना किसी को उत्तेजित करने के विशेष विवादों में शामिल हुए।\n",
      "Reference: पर दो अवसरों पर वे विवाद में उलझ गये, हालांकि वे किसी को वास्तव में कोई चोट नही पहुंचाना चाहते थे। \n",
      "BERTScore F1: 0.7439\n",
      "\n",
      "Original: Basava had forbidden his followers from going to temples.\n",
      "Translated: बसव ने अपने अनुयायियों को मंदिरों में जाने से मना कर दिया था।\n",
      "Reference: बसव ने अपने शिष्यों को मंदिर जाने से रोक दिया था। \n",
      "BERTScore F1: 0.8996\n",
      "\n",
      "Original: If a Chip Guide Bracket is included with the Conveyor Accessories, install it now\n",
      "Translated: यदि एक चिप गाइड ब्रैकेट कन्वेयर सहायक उपकरणों के साथ शामिल है, अब इसे संस्थापित करें\n",
      "Reference: यदि एक चिप गाइड ब्रैकेट कन्वेयर सामान के साथ शामिल है, तो इसे अब स्थापित \n",
      "BERTScore F1: 0.8966\n",
      "\n",
      "Original: It connected those two people.\n",
      "Translated: यह उन दो लोगों को जोड़ा।\n",
      "Reference: उन दोनों को जोड़ने वाली कड़ी सरकार ही थी। \n",
      "BERTScore F1: 0.7826\n",
      "\n",
      "Original: Sub surface dyke or under - ground dam is a subsurface barrier across stream which retards the base flow and stores water upstream below ground surface\n",
      "Translated: उपसतह दीक या भूमि के नीचे बांध, एक नदी के बीच उपसतह अवरोध होता है, जो आधार प्रवाह को धीमा करता है और भूमि के नीचे ऊपर प्रवाहित जल को भंडारित करता है।\n",
      "Reference: भूमिगत जल बांध या उपसतही डाईक नदी के आर पार एक प्रकार का अवरोधक होता है जो बहाव की गति को कम करता है। \n",
      "BERTScore F1: 0.7904\n",
      "\n",
      "Original: Draws near for mankind their reckoning, while they turn away in heedlessness.\n",
      "Translated: और लोगों के लिए उनका हिसाब निकट आ जाता है, हालाँकि वे ग़फ़लत में कतरा रहे है\n",
      "Reference: निकट आ गया लोगों का हिसाब और वे है कि असावधान कतराते जा रहे है\n",
      "BERTScore F1: 0.7867\n",
      "\n",
      "Original: For the petitioner and the deprived -\n",
      "Translated: माँगनेवाले और मुहताजों के लिए,\n",
      "Reference: माँगनेवालों और वंचित का एक ज्ञात और निश्चित हक़ होता है, \n",
      "BERTScore F1: 0.7819\n",
      "\n",
      "Original: Surely the unbelievers, who have done evil, God would not forgive them, neither guide them on any road\n",
      "Translated: बेशक जिन लोगों ने कुफ्र एख्तेयार किया ख़ुदा उनको न बख्शेगा और न राहे रास्त पर हिदायत करेगा\n",
      "Reference: बेशक जिन लोगों ने कुफ़्र इख्तेयार किया और (उस पर) ज़ुल्म (भी) करते रहे न तो ख़ुदा उनको बख्शेगा ही और न ही उन्हें किसी तरीक़े की हिदायत करेगा\n",
      "BERTScore F1: 0.8685\n",
      "\n",
      "Original: 2003 Monte Carlo Masters - Singles 2004\n",
      "Translated: २००३ मोंटे कार्लो मास्टर्स-पुरुष एकल २००४\n",
      "Reference: मोंटे कार्लो मास्टर्स-पुरुष एकल\n",
      "BERTScore F1: 0.8835\n",
      "\n",
      "Original: A waxy layer which is found in plants which helps them to avoid excess water loss and gives them protection\n",
      "Translated: पौधों में पाया जाने वाला एक मोतीदार परत जो पौधों को अधिक पानी की हानि से बचने में मदद करता है और उन्हें सुरक्षा प्रदान करता है\n",
      "Reference: पत्तियों में पाया जाने वाला एक मोमियां परत जिससे अतिरिक्त जल का वाष्पन कम होता है\n",
      "BERTScore F1: 0.7888\n",
      "\n",
      "Original: Indian government has shown its concern by opening MATSYA SANGH in Greater Rajastan\n",
      "Translated: भारत सरकार ने बृहत राजस्थान में मैत्सीय संघ खोलकर अपनी चिंता प्रकट की है।\n",
      "Reference: पन्द्रह अप्रेल 1949 को मत्स्य संध का विलय ग्रेटर राजस्थान में करने की औपचारिकता भी भारत सरकार ने निभा दी। \n",
      "BERTScore F1: 0.7429\n",
      "\n",
      "Original: She is known to be one of the four pillars of Hindi literature.\n",
      "Translated: वे हिन्दी साहित्य के चार स्तंभों में से एक हैं।\n",
      "Reference: वे हिन्दी साहित्य में छायावादी युग के चार प्रमुख स्तंभों में से एक मानी जाती हैं। \n",
      "BERTScore F1: 0.8969\n",
      "\n",
      "Original: % s has canceled the following shared memo:\n",
      "Translated: % s ने निम्न साझा ज्ञापन रद्द कर दिया हैः\n",
      "Reference: % s ने निम्न साझा ज्ञापन रद्द कर दिया हैः\n",
      "BERTScore F1: 1.0000\n",
      "\n",
      "Original: After worshipping the water - goddess, the buffalo is washed there, decorated and brought to the temple in a procession to the accompaniment of music.\n",
      "Translated: पानी की देवी की पूजा करने के बाद भैंस को वहां स्नान करके सजाकर संगीत के साथ एक जुलूस में मंदिर में लाया जाता है।\n",
      "Reference: वहां पानी की देवी की पूजा करने के बाद भैंसे को नहलाया जाता है और उसे सजाकर बाजों-गाजों के साथ जुलूस में मंदिर लाया जाता है। \n",
      "BERTScore F1: 0.8700\n",
      "\n",
      "Original: The President said although oral health should always be an inseparable companion of general health care, modern dentistry has evolved slowly in India.\n",
      "Translated: राष्ट्रपति ने कहा कि यद्यपि मुख स्वास्थ्य को हमेशा सामान्य स्वास्थ्य देखभाल का अविभाज्य साथी होना चाहिए, परंतु भारत में आधुनिक दंत चिकित्सा में धीरे-धीरे विकास हुआ है।\n",
      "Reference: राष्ट्रपति ने कहा कि यद्यपि दंत स्वास्थ्य को सदैव सामान्य स्वास्थ्य देखभाल का अभिन्न अंग माना जाना चाहिए परंतु भारत में दंतविज्ञान का उद्विकास धीरे-धीरे हुआ है।\n",
      "BERTScore F1: 0.8960\n",
      "\n",
      "Original: A term which means as advised or directed.\n",
      "Translated: एक शब्द जिसका अर्थ होता है, सलाह दी गई या निर्देशित की गई।\n",
      "Reference: शब्द जिसका अर्थ हो सलाह अथवा निर्देश. \n",
      "BERTScore F1: 0.8354\n",
      "\n",
      "Original: I appeal to the youth to take advantage of this excellent opportunity.\n",
      "Translated: मैं युवाओं से इस शानदार अवसर का लाभ उठाने के लिए अपील करता हूं।\n",
      "Reference: मैं युवाओं से अपील करता हूं कि इस बेहतरीन अवसर का लाभ उठाएं। \n",
      "BERTScore F1: 0.9005\n",
      "\n",
      "Original: the VPN service failed to start VPN\n",
      "Translated: सेवा आरंभ करने में विफल\n",
      "Reference: सेवा आरंभ होने में विफल रहा\n",
      "BERTScore F1: 0.8864\n",
      "\n",
      "Original: Faqir Aziao - Din was Akbar 's advisor |\n",
      "Translated: फकीर अज़ीओ दीन अकबर के सलाहकार थे।\n",
      "Reference: फकीर अजिओं-दिन अकबर के सलाहकार थे। \n",
      "BERTScore F1: 0.9077\n",
      "\n",
      "Original: Apart from the cooperative banks, Tamil Nadu Industrial Cooperative Bank (TAICO) has been taken onboard for roll - out of CBS under the project.\n",
      "Translated: सहकारी बैंकों के अलावा, इस परियोजना के तहत सीबीएस को शुरू करने के लिए तमिलनाडु औद्योगिक सहकारी बैंक (टीएआईको) को भी शामिल किया गया है।\n",
      "Reference: सहकारी बैंकों के अलावा, तमिल नाडु औद्योगिक सहकारी बैंक (टैको) को भी इस परियोजना में सीबीएस के क्रियान्वयन के लिए शामिल किया गया है। \n",
      "BERTScore F1: 0.8903\n",
      "\n",
      "Original: The CHARTOASCII () function returns the ASCII code for the given character.\n",
      "Translated: फ़ंक्शन CHARTOASCII () दिए गए अक्षर के लिए ASCII कोड बताता है.\n",
      "Reference: फ़ंक्शन CHARTOASCII () दिए गए अक्षर का ASCII कोड बताता है. \n",
      "BERTScore F1: 0.9856\n",
      "\n",
      "Original: There cometh forth from both of them the pearl and coral - stone.\n",
      "Translated: और उन दोनों से मोती और मूँगा निकलता है\n",
      "Reference: उन (समुद्रों) से मोती और मूँगा निकलता है। \n",
      "BERTScore F1: 0.8696\n",
      "\n",
      "Original: Then indeed hell only is his destination.\n",
      "Translated: फिर उसका ठिकाना तो बस जहन्नुम है\n",
      "Reference: उसका ठिकाना तो यक़ीनन दोज़ख़ है\n",
      "BERTScore F1: 0.7817\n",
      "\n",
      "Original: The cortical area within the brain responsible for muscle movements.\n",
      "Translated: मांसपेशियों के गति के लिए उत्तरदायी मस्तिष्क के भीतर कोर्ट्रिक क्षेत्र.\n",
      "Reference: माँसपेशियों की हलचल के लिये जिम्मेदार मस्तिष्क की प्रांतस्था का क्षेत्र. \n",
      "BERTScore F1: 0.8263\n",
      "\n",
      "Original: Was he the one of all of us to have been given the exposition? He is surely an impudent liar. \"\n",
      "Translated: क्या वह हममें से था जिसको (अज़ाब की) दलील दी गई थी बेशक वह बड़ा झूठा है\n",
      "Reference: क्या हम सबमें बस उसी पर वही नाज़िल हुई है (नहीं) बल्कि ये तो बड़ा झूठा तअल्ली करने वाला है\n",
      "BERTScore F1: 0.7660\n",
      "\n",
      "Original: Re - crea _ te folders\n",
      "Translated: फिर से फ़ोल्डर बनाएँ (_ t)\n",
      "Reference: फ़ोल्डर फिर बनाएँ (_ t) \n",
      "BERTScore F1: 0.9575\n",
      "\n",
      "Original: Soon after the death of Aurangzeb (1707), Mughal Empire dispersed (got loosen).\n",
      "Translated: Aurangzeb (1707) की मृत्यु के तुरंत बाद मुगल साम्राज्य वितरित हो गया।\n",
      "Reference: औरंग़ज़ेब के मरते ही (१७०७) मुगल साम्राज्य बिखर गया। \n",
      "BERTScore F1: 0.8128\n",
      "\n",
      "Original: We 're told that we went into Afghanistan\n",
      "Translated: हमें बताया गया है कि हम अफगानिस्तान में गये थे\n",
      "Reference: हमें कहा गया की हम अफगानिस्तान गए\n",
      "BERTScore F1: 0.8601\n",
      "\n",
      "Original: What is my position?\n",
      "Translated: मेरी स्थिति क्या है?\n",
      "Reference: मेरी क्या स्थिती है? \n",
      "BERTScore F1: 0.9029\n",
      "\n",
      "Original: In the past, Switzerland has also provided mixed credit comprising 40% grant and 60% loan for power sector projects.\n",
      "Translated: पूर्व में, स्विट्जरलैंड ने विद्युत क्षेत्र परियोजनाओं के लिए 40 प्रतिशत अनुदान और 60 प्रतिशत ऋण सहित मिश्रित ऋण भी प्रदान किया है।\n",
      "Reference: विगत में, स्वि ट्जरलैंड ने विद्युत क्षेत्र परियोजनाओं के लिए 40 प्रतिशत अनुदान और 60 प्रतिशत ऋण समाहित मिश्रित ऋण भी प्रदान किया है। \n",
      "BERTScore F1: 0.9432\n",
      "\n",
      "Original: And there shall come every soul therewith shall be a driver and a witness.\n",
      "Translated: और हर शख़्श जो उसके साथ आएगा वह यक़ीनन एक अगुज़ार करने वाला और गवाह होगा\n",
      "Reference: हर व्यक्ति इस दशा में आ गया कि उसके साथ एक लानेवाला है और एक गवाही देनेवाला\n",
      "BERTScore F1: 0.7237\n",
      "\n",
      "Original: Nana was sitting near them, by the fire.\n",
      "Translated: नाना आग के पास बैठा था।\n",
      "Reference: नाना उनके पास ही बैठे आग ताप रहे थे। \n",
      "BERTScore F1: 0.8596\n",
      "\n",
      "Original: All this is certainly true - - the inhabitants of the Fire will blame one another in this way.\n",
      "Translated: निस्संदेह यह सब सत्य है। आगवाले एक-दूसरे को इस प्रकार दोष देंगे\n",
      "Reference: निस्संदेह आग में पड़नेवालों का यह आपस का झगड़ा तो अवश्य होना है\n",
      "BERTScore F1: 0.7558\n",
      "\n",
      "Original: Athough like Laksmldhara, Appaya Diksita and Bhattoji DIksita too have condemned the Kaula tradition, the celebrated Bhaskara Raya has offered a defence.\n",
      "Translated: यद्यपि लक्ष्मण, अप्पैया दीक्षित और भट्टोजी दीक्षित ने भी कौल परंपरा की निंदा की है, पर विख्यात भास्कर राय ने इसका बचाव किया है।\n",
      "Reference: की भर्त्सना की है, सुविख्यात भास्कर राय ने इसका समर्थन भी किया है। \n",
      "BERTScore F1: 0.7804\n",
      "\n",
      "Original: 44. In section 139A of the Income-tax Act,—\n",
      "Translated: 44. आय-कर अधिनियम की धारा 139क में,–\n",
      "Reference: 44. आय-कर अधिनियम की धारा 139क की उपधारा (1) में,-\n",
      "BERTScore F1: 0.9299\n",
      "\n",
      "Original: The right face is slightly smaller than the left and even the construction of the heads differ.\n",
      "Translated: दाहिने हाथ बाएं हाथ से थोड़ा छोटा होता है और सिरों का निर्माण भी भिन्न होता है।\n",
      "Reference: दायां मुख बायें की अपेक्षा कुछ छोटा होता है और उसके मुखों की संरचना भी कुछ भिन्न होती है। \n",
      "BERTScore F1: 0.8078\n",
      "\n",
      "Original: The video presents Bhoota Aradhana (Spirit Worship), a film by the noted filmmaker and theatre personality, B.V. Karanth.\n",
      "Translated: इस वीडियो में प्रसिद्ध फिल्म निर्माता और रंगमंच व्यक्तित्व बी. वी. करंत की फिल्म भोटा अराधना (स्वप्न पूजा) प्रस्तुत की गई है।\n",
      "Reference: फ़िल्म के पहले भाग में प्रथा का इतिहास दर्शाया गया है।\n",
      "BERTScore F1: 0.7127\n",
      "\n",
      "Original: Verily it is thine that thou shalt not hunger therein nor go naked.\n",
      "Translated: इसमें तो शक ही नहीं कि इसमें तुम न भूख खाओगे और न नांगे ही होगे\n",
      "Reference: तुम्हारे लिए तो ऐसा है कि न तुम यहाँ भूखे रहोगे और न नंगे\n",
      "BERTScore F1: 0.7772\n",
      "\n",
      "Original: The President of India, Shri Pranab Mukherjee attended the 160th Annual Day Celebrations of Central Public Works Department (CPWD) today (July 12, 2014) at Vigyan Bhawan, New Delhi.\n",
      "Translated: भारत के राष्ट्रपति, श्री प्रणब मुखर्जी ने आज (12 जुलाई 2014) विज्ञान भवन, नई दिल्ली में केंद्रीय लोक निर्माण विभाग के 160वें वार्षिक दिवस समारोह में भाग लिया।\n",
      "Reference: भारत के राष्ट्रपति, श्री प्रणब मुखर्जी ने आज(12 जुलाई2014) विज्ञान भवन, नई दिल्ली में केंद्रीय लोक निर्माण विभाग के 160वें वार्षिक दिवस समारोह में भाग लिया।\n",
      "BERTScore F1: 0.9917\n",
      "\n",
      "Original: Long distance running was not only good for my well - being\n",
      "Translated: लम्बे दूरी पर दौड़ना न केवल मेरे स्वास्थ्य के लिए अच्छा था,\n",
      "Reference: लंबी दौड़ केवल मेरी सेहत के लिए ही अच्छा नहीं था\n",
      "BERTScore F1: 0.7754\n",
      "\n",
      "Original: A total of 2251.25 MHz is being offered with total valuation of Rs. 3,92,332.70 crore (at reserve price).\n",
      "Translated: कुल 2251.25 MHz का प्रस्ताव किया जा रहा है जिसका कुल मूल्य रु. 3,92,332.70 करोड़ (रिजर्व मूल्य पर) है।\n",
      "Reference: कुल 2251.25 मेगाहर्ट्ज की कुल वैल्यूएशन 3,92,332.70 करोड़ रुपये (आरक्षित मूल्य पर) के साथ दी जा रही है।\n",
      "BERTScore F1: 0.8114\n",
      "\n",
      "Original: Nor did We make them bodies that ate no food, nor were they immortal.\n",
      "Translated: और न हमने उन्हें कोई ऐसा शरीर बनाया कि न वे खाते थे और न वे सदैव रहनेवाले थे\n",
      "Reference: उनको हमने कोई ऐसा शरीर नहीं दिया था कि वे भोजन न करते हों और न वे सदैव रहनेवाले ही थे\n",
      "BERTScore F1: 0.8856\n",
      "\n",
      "Original: There is only one drawbackit mustn 't get wet!\n",
      "Translated: केवल एक ही त्रुटि है-यह न सूखना चाहिए।\n",
      "Reference: बस, एक ही खराबी है इस हार्न में जी, कि इसे भीगना नहीं चाहिए। \n",
      "BERTScore F1: 0.7494\n",
      "\n",
      "Original: Not enough space available on the disc\n",
      "Translated: डिस्क पर पर्याप्त जगह उपलब्ध नहीं है\n",
      "Reference: डिस्क पर पर्याप्त स्थान नहीं\n",
      "BERTScore F1: 0.9032\n",
      "\n",
      "Original: Could not create pipe:% s\n",
      "Translated: पाइप नहीं बना सकाः% s\n",
      "Reference: पाइप नहीं बना सकाः% s\n",
      "BERTScore F1: 1.0000\n",
      "\n",
      "Original: Here, we just used y as the independent variable, or\n",
      "Translated: यहाँ, हम सिर्फ y को स्वतंत्र चल के रूप में उपयोग किया, या\n",
      "Reference: यहाँ, हम सिर्फ आत्मनिर्भर चर के रूप में, y उपयोग या\n",
      "BERTScore F1: 0.8183\n",
      "\n",
      "Original: The President of India, Shri Ram Nath Kovind, will open the annual \"Udyanotsav” of Rashtrapati Bhavan on February 04, 2020.\n",
      "Translated: भारत के राष्ट्रपति, श्री रामनाथ कोविंद 04 फरवरी, 2020 को राष्ट्रपति भवन के वार्षिक ‘उद्यानोत्सव’ का उद्घाटन करेंगे।\n",
      "Reference: भारत के राष्ट्रपति, श्री राम नाथ कोविन्द 04 फरवरी, 2020 को राष्ट्रपति भवन के वार्षिक \"उद्यानोत्सव\" का उद्घाटन करेंगे।\n",
      "BERTScore F1: 0.9568\n",
      "\n",
      "Original: Has He chosen daughters in preference to sons?\n",
      "Translated: क्या उसने बेटियों को बेटियों के मुक़ाबले में चुन लिया है?\n",
      "Reference: क्या उसने बेटों की अपेक्षा बेटियाँ चुन ली है? \n",
      "BERTScore F1: 0.8629\n",
      "\n",
      "Original: But you have to pay me a rupee for each injection, I am telling you.\n",
      "Translated: लेकिन मैं आपको बताता हूं कि हर इंजेक्शन के लिए आपको एक रुपया देना होगा।\n",
      "Reference: हां, सुई देने की फीस एक रुपया लगेगी, कहे देता हूं। \n",
      "BERTScore F1: 0.7188\n",
      "\n",
      "Original: As friends, you are interested in India 's endeavour.\n",
      "Translated: मित्रों के रूप में आप भारत के प्रयासों में दिलचस्पी रखते हैं।\n",
      "Reference: मित्र के रूप में आपको भारत की कोशिशों में दिलचस्पी है। \n",
      "BERTScore F1: 0.8952\n",
      "\n",
      "Original: Mark as default memo list\n",
      "Translated: तयशुदा ज्ञापन सूची के रूप में चिह्नित करें\n",
      "Reference: तयशुदा ज्ञापन सूची के रूप में चिह्नित करें\n",
      "BERTScore F1: 1.0000\n",
      "\n",
      "Original: To clarify for them what they differed about, and for the faithless to know that they were liars.\n",
      "Translated: ताकि उनके लिए स्पष्ट कर दे कि उनके बीच क्या मतभेद है और इसलिए कि इनकार करनेवाले जान लें कि वे झूठे है\n",
      "Reference: ताकि वह उनपर उसको स्पष्ट। कर दे, जिसके विषय में वे विभेद करते है और इसलिए भी कि इनकार करनेवाले जान लें कि वे झूठे थे\n",
      "BERTScore F1: 0.8685\n",
      "\n",
      "Original: The mind of ignorance lives, not in the indivisible continuity of time, but successively in each moment.\n",
      "Translated: अज्ञान का मन समय की अविभाज्य निरंतरता में नहीं, बल्कि क्रमशः प्रत्येक क्षण में निवास करता है।\n",
      "Reference: अज्ञानमय मन काल की अविभाज्य, अविच्छिन्न धारा में नहीं, बल्कि क्रमशः एक-एक क्षण में निवास करता है। \n",
      "BERTScore F1: 0.8842\n",
      "\n",
      "Original: we 've covered all of our bases.\n",
      "Translated: हम अपने सभी आधारों को छीन लिया है।\n",
      "Reference: हम सब हमारे ठिकानों के शामिल है। \n",
      "BERTScore F1: 0.7834\n",
      "\n",
      "Original: Strengthening the responsibilities of audit committees;\n",
      "Translated: लेखापरीक्षा समितियों की जिम्मेदारियों को सुदृढ़ करना;\n",
      "Reference: लेखापरीक्षा समितियों के उत्तरदायित्वोंष को सुदृढ करना; \n",
      "BERTScore F1: 0.9153\n",
      "\n",
      "Original: For a state disfigured by a decade of violence, rights violation in Kashmir is beginning to approach the manic radicalism of the Taliban.\n",
      "Translated: एक दशक के हिंसा से विकृत राज्य के लिए कश्मीर में अधिकारों का उल्लंघन तालिबान के उन्मादवादी कट्टरवाद की ओर बढ़ रहा है।\n",
      "Reference: एक दशक से भी अधिक समय से हिंसा से विकृत हो चुके राज्य में मानवाधिकारों का हनन अब तालिबानी उन्माद की रंगत ऐतयार कर रहा है. \n",
      "BERTScore F1: 0.7906\n",
      "\n",
      "Original: The final mysteries still remain far beyond the reach of the human mind and are likely to continue to remain so.\n",
      "Translated: अंतिम रहस्य अभी भी मानव मस्तिष्क की पहुंच से परे हैं और ऐसा होना भी संभव है।\n",
      "Reference: अब भी आखिरी रहस्य इंसान के दिमाग की पहुंच से बाहर है और शायद यह इसी तरह आगे भी रहेगा। \n",
      "BERTScore F1: 0.8124\n",
      "\n",
      "Original: [They will be told], \"Do not cry this Day for one destruction but cry for much destruction.\"\n",
      "Translated: \"आज एक विनाश के लिए न पुकारो, बल्कि बहुत विनाश के लिए पुकारो।\"\n",
      "Reference: (उस वक्त उनसे कहा जाएगा कि) आज एक मौत को न पुकारो बल्कि बहुतेरी मौतों को पुकारो (मगर इससे भी कुछ होने वाला नहीं) \n",
      "BERTScore F1: 0.7679\n",
      "\n",
      "Original: Two major Rajput family, Sansodiya and ranthanbhor of Mewar 's Hada family always remained away from these matters.\n",
      "Translated: दो बड़े राजपूत परिवार, मवार के हदा परिवार के संसोदिया और रंथानफोर इन बातों से हमेशा दूर रहते थे।\n",
      "Reference: दो प्रमुख राजपूत वंश & #44; मेवाढ़ के शिशोदिया और रणथंभोर के हाढ़ा वंश इन संबंधों से सदा ही हटते रहे। \n",
      "BERTScore F1: 0.8006\n",
      "\n",
      "Original: People who are more than 20 per cent overweight have three times the risk of those slightly underweight.\n",
      "Translated: 20 प्रतिशत से अधिक वजन वाले व्यक्तियों में कुछ कम वजन वाले व्यक्तियों की तीन गुना जोखिम है।\n",
      "Reference: मोटापा जिन लोगों का भार सामान्य से 20 प्रतिशत अधिक होता है, उन्हें कम भार वाले व्यक़्तियों की तुलना में हृदय रोग का 3 गुना खतरा अधिक होता है. \n",
      "BERTScore F1: 0.7653\n",
      "\n",
      "Original: And what 's an improper fraction?\n",
      "Translated: और क्या एक अनुचित भिन्न है?\n",
      "Reference: और एक इंपरोपर फ्रॅक्षन क्या है. \n",
      "BERTScore F1: 0.7485\n",
      "\n",
      "Original: Many Many books in Sankrit, in Devanagari\n",
      "Translated: अनेक अनेक संस्कृत, देवनागरी में पुस्तकें\n",
      "Reference: संस्कृत के अनेकानेक ग्रन्थ देवनागरी में\n",
      "BERTScore F1: 0.8026\n",
      "\n",
      "Original: Is it not often the parent of both?\n",
      "Translated: क्या यह प्रायः दोनों के माता-पिता नहीं है?\n",
      "Reference: क्या वह अकसर इन दोनों बुराइयों की जननी नहीं होती। \n",
      "BERTScore F1: 0.7417\n",
      "\n",
      "Original: to listen to it well\n",
      "Translated: उसे अच्छी तरह सुनने के लिए\n",
      "Reference: यह अच्छी तरह से बात करने के लिए \n",
      "BERTScore F1: 0.8879\n",
      "\n",
      "Original: Today she stood like a tigress in defence of her own prerogatives.\n",
      "Translated: आज वह अपने अधिकारों की रक्षा करने के लिए एक चींट की तरह खड़ा थी।\n",
      "Reference: आज वह अपने अधिकार की रक्षा के लिए बाधिन-सी उठ खड़ी हुई थीं। \n",
      "BERTScore F1: 0.8528\n",
      "\n",
      "Original: The individual was sensitized by administering a drug into the tissue.\n",
      "Translated: व्यक्ति को ऊतकों में एक दवा डालकर संवेदनशील बनाया गया.\n",
      "Reference: व्यक्ति को उसके ऊतक में एक दवा डाल कर सुग्राहीकृत किया गया. \n",
      "BERTScore F1: 0.8867\n",
      "\n",
      "Original: The demand became more insistent when the news of the presence of a Bolshevik emissary in the city as the guest of the General Secretary leaked out.\n",
      "Translated: इस मांग को और अधिक जोर दिया गया जब एक बोल्शविक राजदूत की जो जनरल सेक्रेटरी की मेहमान थी शहर में उपस्थित होने का समाचार छप गया।\n",
      "Reference: मांग ने और भी जोर पकड़ा जब यह खबर फैल गई कि बोलशेविक दूत महासचिव के अतिथि के रूप में शहर में मौजूद है। \n",
      "BERTScore F1: 0.7589\n",
      "\n",
      "Original: Since the People of the Forest were unjust,\n",
      "Translated: क्योंकि जंगली लोग ज़ालिम थे,\n",
      "Reference: और निश्चय ही ऐसा वाले भी अत्याचारी थे, \n",
      "BERTScore F1: 0.7212\n",
      "\n",
      "Original: How would you know?\n",
      "Translated: तुम कैसे जान सकते हो?\n",
      "Reference: तुम यह कैसे जानते हो? \n",
      "BERTScore F1: 0.9397\n",
      "\n",
      "Original: In drama, children get an opportunity to act out different roles with the help of speech and physical movement and gesture.\n",
      "Translated: नाटक में बच्चों को विभिन्न भूमिकाएं निभाने का अवसर होता है।\n",
      "Reference: नाटक में बच्चों को विभिन्न भूमिकाओं को बातचीत, हाव-भाव और शरीर के जरिए प्रस्तुत करने का मौका मिलता है। \n",
      "BERTScore F1: 0.8246\n",
      "\n",
      "Original: Those uprisings were a continuous process.\n",
      "Translated: ये विद्रोह एक निरंतर प्रक्रिया थी।\n",
      "Reference: वे लगातार चलते रहै। \n",
      "BERTScore F1: 0.7235\n",
      "\n",
      "Original: Besides the legislative measures, the National Conservation Strategy and Policy Statement on Environment and Development, 1992\n",
      "Translated: विधायी उपायों के अलावा, पर्यावरण और विकास पर राष्ट्रीय संरक्षण नीति और नीति वक्तव्य, 1992\n",
      "Reference: विधायी उपायों के अलावा, पर्यावरण और विकास पर राष्ट्रीय संरक्षण कार्य और नीति कथन, 1992\n",
      "BERTScore F1: 0.9508\n",
      "\n",
      "Original: Allah has certainly made lawful for you the dissolution of your oaths, and Allah is your master and He is the All - knowing, the All - wise.\n",
      "Translated: अल्लाह ने तुम्हारे लिए तुम्हारे क़समों को तोड़ डालना हलाल कर दिया है। अल्लाह ही तुम्हारा स्वामी है और वह सब कुछ जाननेवाला, तत्वदर्शी है\n",
      "Reference: अल्लाह ने तुम लोगों के लिए तुम्हारी अपनी क़समों की पाबंदी से निकलने का उपाय निश्चित कर दिया है। अल्लाह तुम्हारा संरक्षक है और वही सर्वज्ञ, अत्यन्त तत्वदर्शी है\n",
      "BERTScore F1: 0.8585\n",
      "\n",
      "Original: Even a non - director can be liable under Section 141 of the Act.\n",
      "Translated: अधिनियम की धारा 141 के अधीन गैर निदेशक भी उत्तरदायी हो सकता है।\n",
      "Reference: यहां तक कि एक गैर निदेशक अधिनियम की धारा 141 जिम्मेदार हो सकता है. \n",
      "BERTScore F1: 0.8512\n",
      "\n",
      "Original: Have you considered: if We let them enjoy themselves for some years.\n",
      "Translated: क्या तुमने विचार किया कि यदि हम उन्हें कुछ वर्ष तक सुख-सामग्री प्रदान करें?\n",
      "Reference: तो क्या तुमने ग़ौर किया कि अगर हम उनको सालो साल चैन करने दे\n",
      "BERTScore F1: 0.7702\n",
      "\n",
      "Original: where there is the most electromagnetic radiation.\n",
      "Translated: जहाँ सबसे अधिक विद्युत चुंबकीय विकिरण है।\n",
      "Reference: वहाँ है, जहां सबसे अधिक विद्युत चुम्बकीय विकिरण। \n",
      "BERTScore F1: 0.9161\n",
      "\n",
      "Original: Remove completed, canceled and failed file transfers from the list\n",
      "Translated: सूची से पूरा, रद्द और असफल फ़ाइल हस्तांतरण हटाएँ\n",
      "Reference: सूची से हटाए गए, रद्द, और विफल फ़ाइल हस्तांतरण संपन्न\n",
      "BERTScore F1: 0.8926\n",
      "\n",
      "Original: I also pay homage to the late K. P. Kesava Menon, the grand old man of both Kerala and Indian journalism.\n",
      "Translated: मैं स्वर्गीय के. पी. केशव मेनन को भी श्रद्धांजलि अर्पित करता हूं, केरल और भारतीय पत्रकारिता के महान वृद्ध व्यक्ति।\n",
      "Reference: मैं स्वर्गीय के. पी. केशव मेनन को श्रद्धांजलि भी देता हूं जोकि केरल तथा भारतीय पत्रकारिता के एक स्तंभ थे। \n",
      "BERTScore F1: 0.9069\n",
      "\n",
      "Original: A contract has been signed for supply of Boot Anti Mines for use by Infantry.\n",
      "Translated: सेना द्वारा उपयोग के लिए बूट एन्टी माइन की आपूर्ति के लिए एक संविदा पर हस्ताक्षर किए गए हैं।\n",
      "Reference: पैदल सेना के उपयोग हेतु बूट एंटी माइन की आपूर्ति के लिये एक अनुबंध पर हस्ताक्षर किये गये हैं। \n",
      "BERTScore F1: 0.9091\n",
      "\n",
      "Original: No checksum file could be found on the disc\n",
      "Translated: कोई चेकसम फ़ाइल डिस्क पर नहीं मिला\n",
      "Reference: डिस्क पर कोई चेकसम फाइल नहीं मिली\n",
      "BERTScore F1: 0.9010\n",
      "\n",
      "Original: He popularised it and, willingly or not, gave it a commercial orientation.\n",
      "Translated: उन्होंने इसे लोकप्रिय बनाया और स्वेच्छा से या न स्वेच्छा से उसे वाणिज्यिक दिशा प्रदान की।\n",
      "Reference: उन्होंने उसे लोकप्रिय बनाया और इच्छा से या अनिच्छा से उसे वाणिज्याभिमुख किया। \n",
      "BERTScore F1: 0.8550\n",
      "\n",
      "Original: Set this key to the command used to create thumbnails for installed themes.\n",
      "Translated: संस्थापित प्रसंगों के लिए थम्बनेल बनाने के लिए प्रयुक्त कमांड में इस कुंजी को सेट करें.\n",
      "Reference: संस्थापित प्रसंगों हेतु लघु छवि सृजित करने में उपयोग हेतु कमांड के लिए इस कुंजी को नियत करें. \n",
      "BERTScore F1: 0.8690\n",
      "\n",
      "Original: (ii)  whose main object is carrying on the business of providing long-term finance for construction or purchase of houses in India for residential purposes; and\n",
      "Translated: (ii) जिसका मुख्य उद्देश्य भारत में आवासीय प्रयोजनों के लिए मकानों के निर्माण या खरीद के लिए दीर्घकालिक वित्त उपलब्ध कराने का कारबार चलाना है; और\n",
      "Reference: (ii) जिसका मुख्य उद्देश्य, भारत में आवासीय प्रयोजनों के लिए गृहों के सन्निर्माण या क्रय के लिए दीर्घकालिक वित्त उपलब्ध कराने के कारबार को चलाना है; और\n",
      "BERTScore F1: 0.9511\n",
      "\n",
      "Original: - any consent to the issue of the prospectus required from any person as an expert;\n",
      "Translated: - किसी विशेषज्ञ के रूप में किसी व्यक्ति से अपेक्षित प्राक्कलन जारी करने के लिए कोर्इ सहमति;\n",
      "Reference: - विवरण पत्रिका के किसी मुद्दे पर इसकी जरूरत के अनुसार किसी व्यक्ति की विशेषज्ञ के तौर पर स्वीकृति\n",
      "BERTScore F1: 0.7420\n",
      "\n",
      "Original: Gora said, Ma, I feel very hurt when you speak like this.\n",
      "Translated: >> गोरा ने कहा, माँ, जब तुम इस तरह बोलते हो तो मुझे बहुत दुख होता है।\n",
      "Reference: >> गोरा ने कहा, माँ, तुम्हारी इसी बात से मुझे सबसे ज्यादा तकलीफ होती है। \n",
      "BERTScore F1: 0.8598\n",
      "\n",
      "Original: A color palette called \"% 1\" already exists. Do you want to overwrite it?\n",
      "Translated: \"% 1\" नामित रंग पैलेट पहले से ही मौजूद है. क्या आप इसे अधिलेखन करना चाहते हैं?\n",
      "Reference: \"% 1\" नाम रंग पैलेट पहले से ही मौजूद है. क्या आप इसके ऊपर लिखना चाहते हैं? \n",
      "BERTScore F1: 0.9369\n",
      "\n",
      "Original: Development of Pochampad Region (1972).\n",
      "Translated: पोचम्पाद क्षेत्र का विकास (1972).\n",
      "Reference: पोचमपाड क्षेत्र का विकास (1972) \n",
      "BERTScore F1: 0.9006\n",
      "\n",
      "Original: the path of those whom You have blessed — such as have not incurred Your wrath, nor are astray.\n",
      "Translated: और (ऐ रसूल) जिन लोगों को तूने बरकत अता की है वह ऐसे हैं जो न तेरे ग़ज़ब में पड़ गए और न गुमराह हुए\n",
      "Reference: उन लोगों का रास्ता जिन पर तूने इनाम फ़रमाया, जो माअतूब नहीं हुए, जो भटके हुए नहीं है। \n",
      "BERTScore F1: 0.7414\n",
      "\n",
      "Original: He was then paraded in the streets of the Imperial capital atop a female elephant, chained and disgraced.\n",
      "Translated: बाद में उन्हें शाही राजधानी के सड़कों पर एक नारंगी हाथी के ऊपर लादित और अपमानित किया गया।\n",
      "Reference: इसके बाद उन्हें ज़ंजीरों से बाँध कर और कलंकित करके शाही राजधानी की गलियों में एक मादा हाथी के ऊपर बिठा कर उनका जुलूस निकाला गया।\n",
      "BERTScore F1: 0.7978\n",
      "\n",
      "Original: Look! The book is burning.\n",
      "Translated: देखो, किताब जल रही है।\n",
      "Reference: देखो! किताब को आग लग गई है। \n",
      "BERTScore F1: 0.8655\n",
      "\n",
      "Original: Dr. Sinha told me that it was at Swain 's instance that he had called me to discuss the arrival of the Simon Commission the next day.\n",
      "Translated: डा. सिन्हा ने मुझे बताया कि साइमन कमीशन के आने पर अगले दिन चर्चा करने के लिए उन्होंने मुझे स्वीन के मामले में बुलाया था।\n",
      "Reference: उन्होंने कहा कि उन्ही के कहने से श्री सिंह ने मुझे वहां बुलाया है और वह मुझसे साइमन कमीशन के संबंध में बाते कारना चाहते है। \n",
      "BERTScore F1: 0.7706\n",
      "\n",
      "Original: We have a minus sign here.\n",
      "Translated: हम यहाँ एक शून्य चिह्न है।\n",
      "Reference: हम एक शून्य से हस्ताक्षर यहाँ है। \n",
      "BERTScore F1: 0.8264\n",
      "\n",
      "Original: Reloading document from% s\n",
      "Translated: % s से दस्तावेज़ पुनः लोड कर रहा है\n",
      "Reference: दस्तावेज% s से फिर लोड कर रहा है\n",
      "BERTScore F1: 0.8941\n",
      "\n",
      "Original: In the circumstances, balance of convenience is in favour of the plaintiff.\n",
      "Translated: इन परिस्थितियों में, सुविधा का संतुलन वादी के पक्ष में है.\n",
      "Reference: इन परिस्थितियों में, सुविधा का संतुलन वादी के पक्ष में है\n",
      "BERTScore F1: 0.9689\n",
      "\n",
      "Original: They shall laugh but little and shed many tears. So shall they be recompensed for their earnings.\n",
      "Translated: वे थोड़े ही हँसते है और बहुत-से रोते है। इसी प्रकार उन्हें उनके कर्मों का बदला दिया जाएगा\n",
      "Reference: अगर वह कुछ समझें जो कुछ वह किया करते थे उसके बदले उन्हें चाहिए कि वह बहुत कम हॅसें और बहुत रोएँ\n",
      "BERTScore F1: 0.7111\n",
      "\n",
      "Original: But Bal Gandharva remains easily the brightest star in this galaxy!\n",
      "Translated: लेकिन बाल गंधर्व सरलता से इस आकाशगंगा में सबसे चमकदार तारा बना रहता है।\n",
      "Reference: कितुं बाल गधंर्व सदैव इस आकाश गंगां का सबसे अधिक चमकने वाला सितारा रहे है। \n",
      "BERTScore F1: 0.7848\n",
      "\n",
      "Original: Special provision for computation of capital gains in case of depreciable assets.\n",
      "Translated: अवक्षयणीय आस्तियों की दशा में पूंजी अभिलाभ की संगणना करने के लिए विशेष उपबंध।\n",
      "Reference: अवक्षयणीय आस्तियों की दशा में पूंजी अभिलाभों की संगणना करने के लिए विशेष उपबंध\n",
      "BERTScore F1: 0.9566\n",
      "\n",
      "Original: The title of any windows that this process is showing.\n",
      "Translated: किसी विंडो का शीर्षक जो इस प्रक्रिया द्वारा दिखाया जा रहा है.\n",
      "Reference: विंडो का शीर्षक जो यह प्रक्रिया दर्शा रहा है\n",
      "BERTScore F1: 0.8518\n",
      "\n",
      "Original: A payment which is not final but of intermediate nautre.\n",
      "Translated: ऐसा भुगतान जो अंतिम न हो बल्कि मध्यवर्ती न हो।\n",
      "Reference: भुगतान जो अंतिम नहीं हो उससे पूर्व का हो। \n",
      "BERTScore F1: 0.8277\n",
      "\n",
      "Original: A lot of people are going crazy for the Daiya cheese... I still like Follow Your Heart,\n",
      "Translated: बहुत से लोग दाईया के पनीर के लिए पागल हो रहे हैं... मैं अभी भी अपने हृदय का अनुसरण करना पसंद करता हूँ,\n",
      "Reference: बहुत सारे लोग दईया पनीर के लिए पागल हो रहे हैं... मैं अभी भी Follow Your Heart नामक पनीर को पसंद करता हूँ, \n",
      "BERTScore F1: 0.8807\n",
      "\n",
      "Original: And then you put in some randomness,\n",
      "Translated: और फिर आप कुछ अनियमितता में डाल देते हैं,\n",
      "Reference: अब इस प्रारूप में कुछ बेतरतीबियां सम्मिलित कीजिए, \n",
      "BERTScore F1: 0.7053\n",
      "\n",
      "Original: Last night at 9 o 'clock the doctors touched my hands with an electric battery and I felt great discomfort.\n",
      "Translated: पिछले रात 9 बजे डाक्टरों ने मेरे हाथों को बिजली के बैटरी से छू लिया और मुझे बहुत असुविधा हुई।\n",
      "Reference: पिछली रात नौ बजे डाँक्टरों ने मेरे हाथों में बिजली का स्पर्श कराया और मुझे बहुत कष्ट का अनुभव हुआ। \n",
      "BERTScore F1: 0.8780\n",
      "\n",
      "Original: Are you sure you want to delete the '% s' tool?\n",
      "Translated: क्या आप निश्चित हैं कि आप '% s' उपकरण को मिटाना चाहते हैं?\n",
      "Reference: कया आप सचमुच लागाउट करना चाहेंगे? \n",
      "BERTScore F1: 0.7480\n",
      "\n",
      "Original: Freedom and power bring responsibility.\n",
      "Translated: स्वतंत्रता और शक्ति उत्तरदायित्व लाती है।\n",
      "Reference: आजादी और ताकत मिलने से जिम्मेदारी आती है। \n",
      "BERTScore F1: 0.7761\n",
      "\n",
      "Original: Verily the Day of Decision is a time appointed.\n",
      "Translated: निश्चय ही फ़ैसला करने का दिन एक नियत समय है\n",
      "Reference: बेशक फैसले का दिन मुक़र्रर है\n",
      "BERTScore F1: 0.7675\n",
      "\n",
      "Original: Drag and resize widgets in the workspace\n",
      "Translated: कार्यस्थान में विजेटों को खींचें और आकार बदलें\n",
      "Reference: खीचें और आकार बदलें इंच\n",
      "BERTScore F1: 0.7739\n",
      "\n",
      "Original: So that times 3 minus x.\n",
      "Translated: तो 3 शून्य से एक्स बार।\n",
      "Reference: इतना कि एक्स शून्य से 3 बार। \n",
      "BERTScore F1: 0.8732\n",
      "\n",
      "Original: God said, \"Your prayer is granted, so continue, then, both of you, steadfastly on the right path, and do not follow the path of those who have no knowledge.\"\n",
      "Translated: ख़ुदा ने फरमाया तुम्हारी दुआ क़ुबूल की है तो तुम दोनों ने साबित क़दम रहो और नादानों की राह पर न चलो\n",
      "Reference: कहा, \"तुम दोनों की प्रार्थना स्वीकृत हो चुकी। अतः तुम दोनों जमें रहो और उन लोगों के मार्ग पर कदापि न चलना, जो जानते नहीं।\" \n",
      "BERTScore F1: 0.7033\n",
      "\n",
      "Original: Of the wild species, some are striped and some spotted.\n",
      "Translated: जंगली प्रजातियों में से कुछ पट्टीदार और कुछ चिपके हुए होते हैं।\n",
      "Reference: जंगलों में तो धारीदार और बूटेवाली बिल्लियाँ भी पाई जाती हैं। \n",
      "BERTScore F1: 0.7631\n",
      "\n",
      "Original: Are you sure you want to delete all conditions set in this scenario?\n",
      "Translated: क्या आप सुनिश्चित हैं कि आप इस परिदृश्य में सेट सभी शर्तों को मिटाना चाहते हैं?\n",
      "Reference: आप सुनिश्चित हैं कि आप सभी इस परिदृश्य में निर्धारित शर्तों हटाना चाहते हैं? \n",
      "BERTScore F1: 0.8991\n",
      "\n",
      "Original: In the course of their conversation Anandamoyi asked, Did you take Gora to Poresh Babu 's house yesterday?\n",
      "Translated: >> आनन्दमयी ने बातचीत के दौरान पूछा, तुम कल गोरा को परेश बाबू के घर ले गये थे?\n",
      "Reference: >> आनन्दमयी ने बातों-बातों में पूछा, कल शायद तुम गोरा को साथ लेकर परेश बाबू के घर गये थे? \n",
      "BERTScore F1: 0.9042\n",
      "\n",
      "Original: Medicines were prepared by a specified Norma.\n",
      "Translated: दवाएं एक निर्दिष्ट नर्मा द्वारा तैयार की जाती थीं।\n",
      "Reference: विनिश्चित नियमों द्वारा औषधियां तैयार की गई\n",
      "BERTScore F1: 0.7376\n",
      "\n",
      "Original: Thus were turned away those who denied the communications of Allah.\n",
      "Translated: इस प्रकार अल्लाह की आयतों को झुठलानेवाले मुँह फेर दिए गए\n",
      "Reference: जो लोग ख़ुदा की आयतों से इन्कार रखते थे वह इसी तरह भटक रहे थे\n",
      "BERTScore F1: 0.7555\n",
      "\n",
      "Original: Which of your Lord 's wonders would you deny?\n",
      "Translated: तो तुम दोनों अपने परवरदिगार की किस किस नेअमत से इन्कार करोगे\n",
      "Reference: अतः तुम दोनों अपने रब की अनुकम्पाओं में से किस-किस को झुठलाओगे? \n",
      "BERTScore F1: 0.7548\n",
      "\n",
      "Average BERTScore F1: 0.8406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Testing original untuned model\n",
    "test_data, tokenized_test_data = prepare_test_data(small_data_set, original_tokenizer)\n",
    "\n",
    "translated_test_data_untuned = perform_translation_testing(original_model, original_tokenizer, test_data, tokenized_test_data)\n",
    "\n",
    "evaluate_translations_bertscore(test_data, translated_test_data_untuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/ice1/1/2/spadmanabha3/satkp/BigData/LLM/conda/LLM_test/lib/python3.9/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "/tmp/ipykernel_3882697/417664829.py:21: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    }
   ],
   "source": [
    "trainer = prepare_model_for_training(original_model, original_tokenizer, tokenized_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='10935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   74/10935 02:11 < 5:29:53, 0.55 it/s, Epoch 0.03/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfine_tune_and_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal_tokenizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m, in \u001b[0;36mfine_tune_and_save\u001b[0;34m(trainer, model, tokenizer, output_dir)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfine_tune_and_save\u001b[39m(trainer, model, tokenizer, output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./trained_model\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Save the trained model and tokenizer\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     model\u001b[38;5;241m.\u001b[39msave_pretrained(output_dir)\n",
      "File \u001b[0;32m/storage/ice1/1/2/spadmanabha3/satkp/BigData/LLM/conda/LLM_test/lib/python3.9/site-packages/transformers/trainer.py:2123\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2121\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2124\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/storage/ice1/1/2/spadmanabha3/satkp/BigData/LLM/conda/LLM_test/lib/python3.9/site-packages/transformers/trainer.py:2483\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m   2481\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs, num_items_in_batch)\n\u001b[0;32m-> 2483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2484\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2485\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2486\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2487\u001b[0m ):\n\u001b[1;32m   2488\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2489\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   2490\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fine_tune_and_save(trainer, original_model, original_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = load_fine_tuned_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "input_text = \"Stop in the name of the law\"\n",
    "translated_text = translate_text(model, tokenizer, input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_data, tokenized_test_data = prepare_test_data(small_data_set, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_test_data = perform_translation_testing(model, tokenizer, test_data, tokenized_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_translations_bertscore(test_data, translated_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#original_tokenizer, original_model = get_pretrained_mbart_large_50_many_to_many_mmt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#translated_test_data_untuned = perform_translation_testing(original_model, original_tokenizer, test_data, tokenized_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate_translations_bertscore(test_data, translated_test_data_untuned)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM_test",
   "language": "python",
   "name": "llm_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
