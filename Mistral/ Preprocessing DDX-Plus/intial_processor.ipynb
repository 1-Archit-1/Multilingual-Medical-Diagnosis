{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hice1/asengupta74/.local/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('or_dataset/release_evidences.json', 'r') as f:\n",
    "    evidence_dict = json.load(f)\n",
    "\n",
    "with open('or_dataset/release_conditions.json', 'r') as f:\n",
    "    condition_dict = json.load(f)\n",
    "\n",
    "# Load patients data\n",
    "def load_patients(file_path):\n",
    "    with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "        with zip_ref.open(zip_ref.namelist()[0]) as f:\n",
    "            return pd.read_csv(f)\n",
    "\n",
    "# train_patients = load_patients('or_dataset/release_train_patients.zip')\n",
    "# val_patients = load_patients('or_dataset/release_validate_patients.zip')\n",
    "# test_patients = load_patients('or_dataset/release_test_patients.zip')\n",
    "\n",
    "train_patients = pd.read_csv('sampled_combined_data.csv')\n",
    "val_patients = pd.read_csv('sampled_validate_combined_data.csv')\n",
    "test_patients = pd.read_csv('sampled_test_combined_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "def create_text_representation(row, output_path):\n",
    "    # Gather patient information\n",
    "    age = row['AGE']\n",
    "    sex = row['SEX']\n",
    "    pathology = row['PATHOLOGY']\n",
    "    initial_evidence = row['INITIAL_EVIDENCE']\n",
    "    evidences = eval(row['EVIDENCES'])\n",
    "    evidences = [initial_evidence] + evidences\n",
    "    # For differential diagnosis \n",
    "    # data = eval(row['DIFFERENTIAL_DIAGNOSIS'])\n",
    "    # diseases = [item[0] for item in data]\n",
    "    # diseases = ', '.join(diseases)\n",
    "\n",
    "    description = f\"Age: {age}, Sex: {sex}. \"\n",
    "    # Add detailed symptoms and antecedents\n",
    "    symptom_texts = []\n",
    "    antecedents = []\n",
    "    for evidence_code in evidences:\n",
    "        # Separate multi-choice evidence by value\n",
    "        if \"_@_\" in evidence_code:\n",
    "            evidence, value = evidence_code.split('_@_')\n",
    "            evidence_text = evidence_dict[evidence]['question_en']\n",
    "            value_text = evidence_dict[evidence]['value_meaning'].get(value)\n",
    "            value_text = value_text['en'] if value_text is not None else value\n",
    "            if evidence_dict[evidence]['is_antecedent']:\n",
    "                antecedents.append(f\"{evidence_text}: {value_text}\")\n",
    "            else:\n",
    "                symptom_texts.append(f\"{evidence_text}: {value_text}\")\n",
    "        else:\n",
    "            if evidence_dict[evidence_code]['is_antecedent']:\n",
    "                antecedents.append(evidence_dict[evidence_code]['question_en']+'Y')\n",
    "            else:\n",
    "                symptom_texts.append(evidence_dict[evidence_code]['question_en']+'Y')\n",
    "\n",
    "    description += \"History:\" + \"; \".join(antecedents) + \". Symptoms: \" + \"; \".join(symptom_texts) + \".\"\n",
    "    label = pathology\n",
    "    system_message = \"You are an expert and experienced from the healthcare and biomedical domain with extensive medical knowledge and practical experience. Your name is OpenBioLLM, and you are willing to help answer the user's query which will include symptoms and history with a diagnosis. In your explanation, leverage your deep medical expertise such as relevant anatomical structures, physiological processes, diagnostic criteria, or other pertinent medical concepts. \"\n",
    "\n",
    "    with open(output_path, 'a', encoding='utf-8') as f:\n",
    "        chat_format = {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": str(description)\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": str(label)\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        json.dump(chat_format, f, ensure_ascii=False)\n",
    "        f.write('\\n')\n",
    "    \n",
    "\n",
    "def create_json_representation(output_path, df):\n",
    "    system_message = \"You are an expert and experienced from the healthcare and biomedical domain with extensive medical knowledge and practical experience. Your name is OpenBioLLM, and you are willing to help answer the user's query which will include symptoms and history with a diagnosis. In your explanation, leverage your deep medical expertise such as relevant anatomical structures, physiological processes, diagnostic criteria, or other pertinent medical concepts. \"\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        for _, row in df.iterrows():\n",
    "            chat_format = {\n",
    "                \"messages\": [\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": str(row['text'])\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"assistant\",\n",
    "                        \"content\": str(row['label'])\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "            json.dump(chat_format, f, ensure_ascii=False)\n",
    "            f.write('\\n')\n",
    "\n",
    "# Apply to datasets\n",
    "\n",
    "#train_results = pd.DataFrame(train_patients.apply(create_text_representation, axis=1).toList(), columns=['text', 'label'])\n",
    "val_patients = val_patients\n",
    "val_results = val_patients.apply(create_text_representation, output_path ='val_results.jsonl', axis=1 )\n",
    "#val_results = pd.DataFrame(val_results.tolist(), columns=['text', 'label'])\n",
    "\n",
    "test_patients = test_patients\n",
    "test_results = test_patients.apply(create_text_representation,output_path ='test_results.jsonl', axis=1)\n",
    "#test_results = pd.DataFrame(test_results.tolist(), columns=['text', 'label'])\n",
    "\n",
    "train_patients = train_patients\n",
    "train_results = train_patients.apply(create_text_representation,output_path ='train_results.jsonl', axis=1)\n",
    "#train_results = pd.DataFrame(train_results.tolist(), columns=['text', 'label'])\n",
    "#train_results.to_csv('train.csv', index=False)\n",
    "\n",
    "#val_results = pd.DataFrame(val_patients,columns=['text', 'label'])\n",
    "#test_results = pd.DataFrame(test_patients.apply(create_text_representation, axis=1).toList(), columns=['text', 'label'])\n",
    "\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_results.to_csv('val_patients_with_text.csv', index=False)\n",
    "test_results.to_csv('test_patients_with_text.csv', index=False)\n",
    "train_results.to_csv('train_patients_with_text.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = pd.concat([train_patients['PATHOLOGY'], val_patients['PATHOLOGY'], test_patients['PATHOLOGY']])\n",
    "\n",
    "# Fit Label Encoder\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(all_labels)\n",
    "\n",
    "# Transform pathologies to numerical labels\n",
    "train_patients_label = label_encoder.transform(train_patients['PATHOLOGY'])\n",
    "val_patients_label = label_encoder.transform(val_patients['PATHOLOGY'])\n",
    "test_patients_label = label_encoder.transform(test_patients['PATHOLOGY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_path = 'train_patients_with_text.csv'\n",
    "val_file_path = 'val_patients_with_text.csv'\n",
    "test_file_path = 'test_patients_with_text.csv'\n",
    "\n",
    "# Save each DataFrame to a CSV file\n",
    "train_patients.to_csv(train_file_path, index=False)\n",
    "val_patients.to_csv(val_file_path, index=False)\n",
    "test_patients.to_csv(test_file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-bdproj]",
   "language": "python",
   "name": "conda-env-.conda-bdproj-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
