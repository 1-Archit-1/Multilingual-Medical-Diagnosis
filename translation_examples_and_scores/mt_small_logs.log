Running the mbart_eng_hindi() function
Running the mbart_hindi_eng() function
Running the mt5_eng_hindi() function
DatasetDict({
    train: Dataset({
        features: ['translation'],
        num_rows: 1659083
    })
    validation: Dataset({
        features: ['translation'],
        num_rows: 520
    })
    test: Dataset({
        features: ['translation'],
        num_rows: 2507
    })
})
Dataset({
    features: ['translation'],
    num_rows: 839876
})
DatasetDict({
    train: Dataset({
        features: ['translation'],
        num_rows: 112000
    })
    validation: Dataset({
        features: ['translation'],
        num_rows: 16000
    })
    test: Dataset({
        features: ['translation'],
        num_rows: 32000
    })
})
New train set size: 112000
New validation set size: 16000
New test set size: 32000
TIME_data_preparation_3: 0.96 seconds
/storage/ice1/1/2/spadmanabha3/satkp/BigData/LLM/conda/LLM_test/lib/python3.9/site-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(
/storage/ice1/1/2/spadmanabha3/satkp/BigData/LLM/conda/LLM_test/lib/python3.9/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
  0%|          | 0/7000 [00:00<?, ?it/s]
Epoch: 1 | Step: 50 | Avg. loss: 27.523 | lr: 4.464285714285714e-05
Epoch: 1 | Step: 100 | Avg. loss: 14.673 | lr: 8.928571428571429e-05
Epoch: 1 | Step: 150 | Avg. loss: 8.754 | lr: 0.00013392857142857144
Epoch: 1 | Step: 200 | Avg. loss: 6.452 | lr: 0.00017857142857142857
Epoch: 1 | Step: 250 | Avg. loss: 5.536 | lr: 0.00022321428571428573
Epoch: 1 | Step: 300 | Avg. loss: 4.658 | lr: 0.00026785714285714287
Epoch: 1 | Step: 350 | Avg. loss: 3.937 | lr: 0.0003125
Epoch: 1 | Step: 400 | Avg. loss: 3.507 | lr: 0.00035714285714285714
Epoch: 1 | Step: 450 | Avg. loss: 3.253 | lr: 0.00040178571428571433
Epoch: 1 | Step: 500 | Avg. loss: 3.112 | lr: 0.00044642857142857147
Epoch: 1 | Step: 550 | Avg. loss: 2.944 | lr: 0.0004910714285714286
Epoch: 1 | Step: 600 | Avg. loss: 2.777 | lr: 0.0004996392496392497
Epoch: 1 | Step: 650 | Avg. loss: 2.709 | lr: 0.0004991883116883117
Epoch: 1 | Step: 700 | Avg. loss: 2.642 | lr: 0.0004987373737373738
Epoch: 1 | Step: 750 | Avg. loss: 2.577 | lr: 0.0004982864357864358
Epoch: 1 | Step: 800 | Avg. loss: 2.532 | lr: 0.0004978354978354978
Epoch: 1 | Step: 850 | Avg. loss: 2.545 | lr: 0.0004973845598845599
Epoch: 1 | Step: 900 | Avg. loss: 2.472 | lr: 0.000496933621933622
Epoch: 1 | Step: 950 | Avg. loss: 2.451 | lr: 0.000496482683982684
Epoch: 1 | Step: 1000 | Avg. loss: 2.396 | lr: 0.000496031746031746
Saving model with test loss of 2.420
Epoch: 1 | Step: 1050 | Avg. loss: 2.397 | lr: 0.0004955808080808081
Epoch: 1 | Step: 1100 | Avg. loss: 2.348 | lr: 0.0004951298701298701
Epoch: 1 | Step: 1150 | Avg. loss: 2.413 | lr: 0.0004946789321789322
Epoch: 1 | Step: 1200 | Avg. loss: 2.322 | lr: 0.0004942279942279943
Epoch: 1 | Step: 1250 | Avg. loss: 2.330 | lr: 0.0004937770562770563
Epoch: 1 | Step: 1300 | Avg. loss: 2.274 | lr: 0.0004933261183261183
Epoch: 1 | Step: 1350 | Avg. loss: 2.288 | lr: 0.0004928751803751803
Epoch: 1 | Step: 1400 | Avg. loss: 2.263 | lr: 0.0004924242424242425
Epoch: 1 | Step: 1450 | Avg. loss: 2.284 | lr: 0.0004919733044733045
Epoch: 1 | Step: 1500 | Avg. loss: 2.270 | lr: 0.0004915223665223666
Epoch: 1 | Step: 1550 | Avg. loss: 2.279 | lr: 0.0004910714285714286
Epoch: 1 | Step: 1600 | Avg. loss: 2.238 | lr: 0.0004906204906204906
Epoch: 1 | Step: 1650 | Avg. loss: 2.222 | lr: 0.0004901695526695526
Epoch: 1 | Step: 1700 | Avg. loss: 2.269 | lr: 0.0004897186147186148
Epoch: 1 | Step: 1750 | Avg. loss: 2.220 | lr: 0.0004892676767676768
Epoch: 1 | Step: 1800 | Avg. loss: 2.213 | lr: 0.0004888167388167388
Epoch: 1 | Step: 1850 | Avg. loss: 2.189 | lr: 0.0004883658008658009
Epoch: 1 | Step: 1900 | Avg. loss: 2.218 | lr: 0.00048791486291486293
Epoch: 1 | Step: 1950 | Avg. loss: 2.203 | lr: 0.000487463924963925
Epoch: 1 | Step: 2000 | Avg. loss: 2.163 | lr: 0.000487012987012987
Saving model with test loss of 2.137
Epoch: 1 | Step: 2050 | Avg. loss: 2.137 | lr: 0.0004865620490620491
Epoch: 1 | Step: 2100 | Avg. loss: 2.150 | lr: 0.0004861111111111111
Epoch: 1 | Step: 2150 | Avg. loss: 2.127 | lr: 0.00048566017316017317
Epoch: 1 | Step: 2200 | Avg. loss: 2.133 | lr: 0.00048520923520923524
Epoch: 1 | Step: 2250 | Avg. loss: 2.182 | lr: 0.0004847582972582973
Epoch: 1 | Step: 2300 | Avg. loss: 2.119 | lr: 0.0004843073593073593
Epoch: 1 | Step: 2350 | Avg. loss: 2.088 | lr: 0.0004838564213564214
Epoch: 1 | Step: 2400 | Avg. loss: 2.101 | lr: 0.0004834054834054834
Epoch: 1 | Step: 2450 | Avg. loss: 2.070 | lr: 0.0004829545454545455
Epoch: 1 | Step: 2500 | Avg. loss: 2.074 | lr: 0.0004825036075036075
Epoch: 1 | Step: 2550 | Avg. loss: 2.062 | lr: 0.00048205266955266956
Epoch: 1 | Step: 2600 | Avg. loss: 2.059 | lr: 0.0004816017316017316
Epoch: 1 | Step: 2650 | Avg. loss: 2.108 | lr: 0.0004811507936507937
Epoch: 1 | Step: 2700 | Avg. loss: 2.001 | lr: 0.0004806998556998557
Epoch: 1 | Step: 2750 | Avg. loss: 2.031 | lr: 0.0004802489177489178
Epoch: 1 | Step: 2800 | Avg. loss: 2.014 | lr: 0.0004797979797979798
Epoch: 1 | Step: 2850 | Avg. loss: 2.078 | lr: 0.00047934704184704187
Epoch: 1 | Step: 2900 | Avg. loss: 2.027 | lr: 0.0004788961038961039
Epoch: 1 | Step: 2950 | Avg. loss: 2.065 | lr: 0.00047844516594516595
Epoch: 1 | Step: 3000 | Avg. loss: 1.983 | lr: 0.00047799422799422797
Saving model with test loss of 2.007
Epoch: 1 | Step: 3050 | Avg. loss: 2.048 | lr: 0.00047754329004329004
Epoch: 1 | Step: 3100 | Avg. loss: 2.022 | lr: 0.00047709235209235205
Epoch: 1 | Step: 3150 | Avg. loss: 2.055 | lr: 0.0004766414141414142
Epoch: 1 | Step: 3200 | Avg. loss: 2.051 | lr: 0.0004761904761904762
Epoch: 1 | Step: 3250 | Avg. loss: 2.000 | lr: 0.00047573953823953826
Epoch: 1 | Step: 3300 | Avg. loss: 1.999 | lr: 0.00047528860028860033
Epoch: 1 | Step: 3350 | Avg. loss: 1.999 | lr: 0.00047483766233766234
Epoch: 1 | Step: 3400 | Avg. loss: 1.984 | lr: 0.0004743867243867244
Epoch: 1 | Step: 3450 | Avg. loss: 1.992 | lr: 0.00047393578643578643
Epoch: 1 | Step: 3500 | Avg. loss: 1.966 | lr: 0.0004734848484848485
Epoch: 1 | Step: 3550 | Avg. loss: 1.967 | lr: 0.0004730339105339105
Epoch: 1 | Step: 3600 | Avg. loss: 2.007 | lr: 0.00047258297258297264
Epoch: 1 | Step: 3650 | Avg. loss: 1.960 | lr: 0.00047213203463203465
Epoch: 1 | Step: 3700 | Avg. loss: 1.959 | lr: 0.0004716810966810967
Epoch: 1 | Step: 3750 | Avg. loss: 1.921 | lr: 0.00047123015873015874
Epoch: 1 | Step: 3800 | Avg. loss: 1.933 | lr: 0.0004707792207792208
Epoch: 1 | Step: 3850 | Avg. loss: 1.908 | lr: 0.0004703282828282828
Epoch: 1 | Step: 3900 | Avg. loss: 1.961 | lr: 0.0004698773448773449
Epoch: 1 | Step: 3950 | Avg. loss: 1.959 | lr: 0.0004694264069264069
Epoch: 1 | Step: 4000 | Avg. loss: 1.982 | lr: 0.000468975468975469
Saving model with test loss of 1.911
Epoch: 1 | Step: 4050 | Avg. loss: 1.961 | lr: 0.00046852453102453104
Epoch: 1 | Step: 4100 | Avg. loss: 1.931 | lr: 0.0004680735930735931
Epoch: 1 | Step: 4150 | Avg. loss: 1.975 | lr: 0.00046762265512265513
Epoch: 1 | Step: 4200 | Avg. loss: 1.894 | lr: 0.0004671717171717172
Epoch: 1 | Step: 4250 | Avg. loss: 1.920 | lr: 0.0004667207792207792
Epoch: 1 | Step: 4300 | Avg. loss: 1.934 | lr: 0.0004662698412698413
Epoch: 1 | Step: 4350 | Avg. loss: 1.920 | lr: 0.0004658189033189033
Epoch: 1 | Step: 4400 | Avg. loss: 1.885 | lr: 0.00046536796536796537
Epoch: 1 | Step: 4450 | Avg. loss: 1.948 | lr: 0.0004649170274170274
Epoch: 1 | Step: 4500 | Avg. loss: 1.869 | lr: 0.0004644660894660895
Epoch: 1 | Step: 4550 | Avg. loss: 1.947 | lr: 0.0004640151515151515
Epoch: 1 | Step: 4600 | Avg. loss: 1.906 | lr: 0.0004635642135642136
Epoch: 1 | Step: 4650 | Avg. loss: 1.916 | lr: 0.0004631132756132756
Epoch: 1 | Step: 4700 | Avg. loss: 1.975 | lr: 0.0004626623376623377
Epoch: 1 | Step: 4750 | Avg. loss: 1.904 | lr: 0.0004622113997113997
Epoch: 1 | Step: 4800 | Avg. loss: 1.922 | lr: 0.00046176046176046176
Epoch: 1 | Step: 4850 | Avg. loss: 1.896 | lr: 0.00046130952380952383
Epoch: 1 | Step: 4900 | Avg. loss: 1.814 | lr: 0.00046085858585858584
Epoch: 1 | Step: 4950 | Avg. loss: 1.855 | lr: 0.00046040764790764797
Epoch: 1 | Step: 5000 | Avg. loss: 1.810 | lr: 0.00045995670995671
Saving model with test loss of 1.819
Epoch: 1 | Step: 5050 | Avg. loss: 1.819 | lr: 0.00045950577200577205
Epoch: 1 | Step: 5100 | Avg. loss: 1.884 | lr: 0.00045905483405483407
Epoch: 1 | Step: 5150 | Avg. loss: 1.843 | lr: 0.00045860389610389614
Epoch: 1 | Step: 5200 | Avg. loss: 1.876 | lr: 0.00045815295815295815
Epoch: 1 | Step: 5250 | Avg. loss: 1.848 | lr: 0.0004577020202020202
Epoch: 1 | Step: 5300 | Avg. loss: 1.839 | lr: 0.00045725108225108224
Epoch: 1 | Step: 5350 | Avg. loss: 1.823 | lr: 0.0004568001443001443
Epoch: 1 | Step: 5400 | Avg. loss: 1.850 | lr: 0.0004563492063492063
Epoch: 1 | Step: 5450 | Avg. loss: 1.825 | lr: 0.00045589826839826845
Epoch: 1 | Step: 5500 | Avg. loss: 1.843 | lr: 0.00045544733044733046
Epoch: 1 | Step: 5550 | Avg. loss: 1.875 | lr: 0.00045499639249639253
Epoch: 1 | Step: 5600 | Avg. loss: 1.806 | lr: 0.00045454545454545455
Epoch: 1 | Step: 5650 | Avg. loss: 1.827 | lr: 0.0004540945165945166
Epoch: 1 | Step: 5700 | Avg. loss: 1.821 | lr: 0.00045364357864357863
Epoch: 1 | Step: 5750 | Avg. loss: 1.838 | lr: 0.0004531926406926407
Epoch: 1 | Step: 5800 | Avg. loss: 1.832 | lr: 0.0004527417027417027
Epoch: 1 | Step: 5850 | Avg. loss: 1.801 | lr: 0.0004522907647907648
Epoch: 1 | Step: 5900 | Avg. loss: 1.826 | lr: 0.00045183982683982685
Epoch: 1 | Step: 5950 | Avg. loss: 1.794 | lr: 0.0004513888888888889
Epoch: 1 | Step: 6000 | Avg. loss: 1.785 | lr: 0.00045093795093795094
Saving model with test loss of 1.793
Epoch: 1 | Step: 6050 | Avg. loss: 1.794 | lr: 0.000450487012987013
Epoch: 1 | Step: 6100 | Avg. loss: 1.855 | lr: 0.000450036075036075
Epoch: 1 | Step: 6150 | Avg. loss: 1.826 | lr: 0.0004495851370851371
Epoch: 1 | Step: 6200 | Avg. loss: 1.808 | lr: 0.0004491341991341991
Epoch: 1 | Step: 6250 | Avg. loss: 1.814 | lr: 0.0004486832611832612
Epoch: 1 | Step: 6300 | Avg. loss: 1.782 | lr: 0.00044823232323232325
Epoch: 1 | Step: 6350 | Avg. loss: 1.816 | lr: 0.0004477813852813853
Epoch: 1 | Step: 6400 | Avg. loss: 1.773 | lr: 0.0004473304473304474
Epoch: 1 | Step: 6450 | Avg. loss: 1.776 | lr: 0.0004468795093795094
Epoch: 1 | Step: 6500 | Avg. loss: 1.810 | lr: 0.00044642857142857147
Epoch: 1 | Step: 6550 | Avg. loss: 1.800 | lr: 0.0004459776334776335
Epoch: 1 | Step: 6600 | Avg. loss: 1.782 | lr: 0.00044552669552669555
Epoch: 1 | Step: 6650 | Avg. loss: 1.807 | lr: 0.00044507575757575757
Epoch: 1 | Step: 6700 | Avg. loss: 1.772 | lr: 0.00044462481962481964
Epoch: 1 | Step: 6750 | Avg. loss: 1.786 | lr: 0.00044417388167388165
Epoch: 1 | Step: 6800 | Avg. loss: 1.769 | lr: 0.0004437229437229438
Epoch: 1 | Step: 6850 | Avg. loss: 1.692 | lr: 0.0004432720057720058
Epoch: 1 | Step: 6900 | Avg. loss: 1.764 | lr: 0.00044282106782106786
Epoch: 1 | Step: 6950 | Avg. loss: 1.796 | lr: 0.0004423701298701299
Epoch: 1 | Step: 7000 | Avg. loss: 1.830 | lr: 0.00044191919191919195
Saving model with test loss of 1.741
  0%|          | 0/7000 [00:00<?, ?it/s]
Epoch: 2 | Step: 50 | Avg. loss: 1.784 | lr: 0.00044146825396825396
Epoch: 2 | Step: 100 | Avg. loss: 1.782 | lr: 0.00044101731601731603
Epoch: 2 | Step: 150 | Avg. loss: 1.750 | lr: 0.00044056637806637805
Epoch: 2 | Step: 200 | Avg. loss: 1.771 | lr: 0.0004401154401154401
Epoch: 2 | Step: 250 | Avg. loss: 1.754 | lr: 0.00043966450216450213
Epoch: 2 | Step: 300 | Avg. loss: 1.823 | lr: 0.00043921356421356425
Epoch: 2 | Step: 350 | Avg. loss: 1.882 | lr: 0.00043876262626262627
Epoch: 2 | Step: 400 | Avg. loss: 1.823 | lr: 0.00043831168831168834
Epoch: 2 | Step: 450 | Avg. loss: 1.795 | lr: 0.00043786075036075035
Epoch: 2 | Step: 500 | Avg. loss: 1.803 | lr: 0.0004374098124098124
Epoch: 2 | Step: 550 | Avg. loss: 1.752 | lr: 0.00043695887445887444
Epoch: 2 | Step: 600 | Avg. loss: 1.750 | lr: 0.0004365079365079365
Epoch: 2 | Step: 650 | Avg. loss: 1.744 | lr: 0.0004360569985569985
Epoch: 2 | Step: 700 | Avg. loss: 1.746 | lr: 0.0004356060606060606
Epoch: 2 | Step: 750 | Avg. loss: 1.735 | lr: 0.00043515512265512266
Epoch: 2 | Step: 800 | Avg. loss: 1.707 | lr: 0.00043470418470418473
Epoch: 2 | Step: 850 | Avg. loss: 1.720 | lr: 0.0004342532467532468
Epoch: 2 | Step: 900 | Avg. loss: 1.703 | lr: 0.0004338023088023088
Epoch: 2 | Step: 950 | Avg. loss: 1.696 | lr: 0.0004333513708513709
Epoch: 2 | Step: 1000 | Avg. loss: 1.688 | lr: 0.0004329004329004329
Saving model with test loss of 1.723
Epoch: 2 | Step: 1050 | Avg. loss: 1.682 | lr: 0.00043244949494949497
Epoch: 2 | Step: 1100 | Avg. loss: 1.679 | lr: 0.000431998556998557
Epoch: 2 | Step: 1150 | Avg. loss: 1.758 | lr: 0.00043154761904761905
Epoch: 2 | Step: 1200 | Avg. loss: 1.705 | lr: 0.0004310966810966811
Epoch: 2 | Step: 1250 | Avg. loss: 1.692 | lr: 0.0004306457431457432
Epoch: 2 | Step: 1300 | Avg. loss: 1.642 | lr: 0.0004301948051948052
Epoch: 2 | Step: 1350 | Avg. loss: 1.683 | lr: 0.0004297438672438673
Epoch: 2 | Step: 1400 | Avg. loss: 1.676 | lr: 0.0004292929292929293
Epoch: 2 | Step: 1450 | Avg. loss: 1.680 | lr: 0.00042884199134199136
Epoch: 2 | Step: 1500 | Avg. loss: 1.690 | lr: 0.0004283910533910534
Epoch: 2 | Step: 1550 | Avg. loss: 1.711 | lr: 0.00042794011544011545
Epoch: 2 | Step: 1600 | Avg. loss: 1.676 | lr: 0.00042748917748917746
Epoch: 2 | Step: 1650 | Avg. loss: 1.668 | lr: 0.0004270382395382396
Epoch: 2 | Step: 1700 | Avg. loss: 1.729 | lr: 0.0004265873015873016
Epoch: 2 | Step: 1750 | Avg. loss: 1.674 | lr: 0.00042613636363636367
Epoch: 2 | Step: 1800 | Avg. loss: 1.691 | lr: 0.0004256854256854257
Epoch: 2 | Step: 1850 | Avg. loss: 1.656 | lr: 0.00042523448773448775
Epoch: 2 | Step: 1900 | Avg. loss: 1.674 | lr: 0.00042478354978354977
Epoch: 2 | Step: 1950 | Avg. loss: 1.687 | lr: 0.00042433261183261184
Epoch: 2 | Step: 2000 | Avg. loss: 1.634 | lr: 0.00042388167388167385
Saving model with test loss of 1.707
Epoch: 2 | Step: 2050 | Avg. loss: 1.637 | lr: 0.0004234307359307359
Epoch: 2 | Step: 2100 | Avg. loss: 1.629 | lr: 0.00042297979797979794
Epoch: 2 | Step: 2150 | Avg. loss: 1.618 | lr: 0.00042252886002886006
Epoch: 2 | Step: 2200 | Avg. loss: 1.654 | lr: 0.0004220779220779221
Epoch: 2 | Step: 2250 | Avg. loss: 1.692 | lr: 0.00042162698412698415
Epoch: 2 | Step: 2300 | Avg. loss: 1.649 | lr: 0.0004211760461760462
Epoch: 2 | Step: 2350 | Avg. loss: 1.624 | lr: 0.00042072510822510823
Epoch: 2 | Step: 2400 | Avg. loss: 1.635 | lr: 0.0004202741702741703
Epoch: 2 | Step: 2450 | Avg. loss: 1.612 | lr: 0.0004198232323232323
Epoch: 2 | Step: 2500 | Avg. loss: 1.614 | lr: 0.0004193722943722944
Epoch: 2 | Step: 2550 | Avg. loss: 1.599 | lr: 0.0004189213564213564
Epoch: 2 | Step: 2600 | Avg. loss: 1.600 | lr: 0.0004184704184704185
Epoch: 2 | Step: 2650 | Avg. loss: 1.671 | lr: 0.00041801948051948054
Epoch: 2 | Step: 2700 | Avg. loss: 1.577 | lr: 0.0004175685425685426
Epoch: 2 | Step: 2750 | Avg. loss: 1.590 | lr: 0.0004171176046176046
Epoch: 2 | Step: 2800 | Avg. loss: 1.589 | lr: 0.0004166666666666667
Epoch: 2 | Step: 2850 | Avg. loss: 1.661 | lr: 0.0004162157287157287
Epoch: 2 | Step: 2900 | Avg. loss: 1.598 | lr: 0.0004157647907647908
Epoch: 2 | Step: 2950 | Avg. loss: 1.646 | lr: 0.0004153138528138528
Epoch: 2 | Step: 3000 | Avg. loss: 1.580 | lr: 0.00041486291486291486
Saving model with test loss of 1.683
Epoch: 2 | Step: 3050 | Avg. loss: 1.645 | lr: 0.00041441197691197693
Epoch: 2 | Step: 3100 | Avg. loss: 1.605 | lr: 0.000413961038961039
Epoch: 2 | Step: 3150 | Avg. loss: 1.645 | lr: 0.000413510101010101
Epoch: 2 | Step: 3200 | Avg. loss: 1.644 | lr: 0.0004130591630591631
Epoch: 2 | Step: 3250 | Avg. loss: 1.598 | lr: 0.0004126082251082251
Epoch: 2 | Step: 3300 | Avg. loss: 1.591 | lr: 0.00041215728715728717
Epoch: 2 | Step: 3350 | Avg. loss: 1.596 | lr: 0.0004117063492063492
Epoch: 2 | Step: 3400 | Avg. loss: 1.609 | lr: 0.00041125541125541126
Epoch: 2 | Step: 3450 | Avg. loss: 1.578 | lr: 0.00041080447330447327
Epoch: 2 | Step: 3500 | Avg. loss: 1.586 | lr: 0.0004103535353535354
Epoch: 2 | Step: 3550 | Avg. loss: 1.583 | lr: 0.0004099025974025974
Epoch: 2 | Step: 3600 | Avg. loss: 1.624 | lr: 0.0004094516594516595
Epoch: 2 | Step: 3650 | Avg. loss: 1.582 | lr: 0.0004090007215007215
Epoch: 2 | Step: 3700 | Avg. loss: 1.579 | lr: 0.00040854978354978356
Epoch: 2 | Step: 3750 | Avg. loss: 1.553 | lr: 0.0004080988455988456
Epoch: 2 | Step: 3800 | Avg. loss: 1.554 | lr: 0.00040764790764790765
Epoch: 2 | Step: 3850 | Avg. loss: 1.540 | lr: 0.0004071969696969697
Epoch: 2 | Step: 3900 | Avg. loss: 1.589 | lr: 0.00040674603174603173
Epoch: 2 | Step: 3950 | Avg. loss: 1.602 | lr: 0.00040629509379509386
Epoch: 2 | Step: 4000 | Avg. loss: 1.609 | lr: 0.00040584415584415587
Saving model with test loss of 1.642
Epoch: 2 | Step: 4050 | Avg. loss: 1.591 | lr: 0.00040539321789321794
Epoch: 2 | Step: 4100 | Avg. loss: 1.563 | lr: 0.00040494227994227996
Epoch: 2 | Step: 4150 | Avg. loss: 1.620 | lr: 0.000404491341991342
Epoch: 2 | Step: 4200 | Avg. loss: 1.556 | lr: 0.00040404040404040404
Epoch: 2 | Step: 4250 | Avg. loss: 1.561 | lr: 0.0004035894660894661
Epoch: 2 | Step: 4300 | Avg. loss: 1.574 | lr: 0.0004031385281385281
Epoch: 2 | Step: 4350 | Avg. loss: 1.563 | lr: 0.0004026875901875902
Epoch: 2 | Step: 4400 | Avg. loss: 1.528 | lr: 0.0004022366522366522
Epoch: 2 | Step: 4450 | Avg. loss: 1.583 | lr: 0.00040178571428571433
Epoch: 2 | Step: 4500 | Avg. loss: 1.518 | lr: 0.00040133477633477635
Epoch: 2 | Step: 4550 | Avg. loss: 1.580 | lr: 0.0004008838383838384
Epoch: 2 | Step: 4600 | Avg. loss: 1.552 | lr: 0.00040043290043290043
Epoch: 2 | Step: 4650 | Avg. loss: 1.586 | lr: 0.0003999819624819625
Epoch: 2 | Step: 4700 | Avg. loss: 1.621 | lr: 0.0003995310245310245
Epoch: 2 | Step: 4750 | Avg. loss: 1.554 | lr: 0.0003990800865800866
Epoch: 2 | Step: 4800 | Avg. loss: 1.568 | lr: 0.0003986291486291486
Epoch: 2 | Step: 4850 | Avg. loss: 1.548 | lr: 0.00039817821067821067
Epoch: 2 | Step: 4900 | Avg. loss: 1.470 | lr: 0.00039772727272727274
Epoch: 2 | Step: 4950 | Avg. loss: 1.511 | lr: 0.0003972763347763348
Epoch: 2 | Step: 5000 | Avg. loss: 1.476 | lr: 0.0003968253968253968
Saving model with test loss of 1.601
Epoch: 2 | Step: 5050 | Avg. loss: 1.477 | lr: 0.0003963744588744589
Epoch: 2 | Step: 5100 | Avg. loss: 1.536 | lr: 0.0003959235209235209
Epoch: 2 | Step: 5150 | Avg. loss: 1.502 | lr: 0.000395472582972583
Epoch: 2 | Step: 5200 | Avg. loss: 1.518 | lr: 0.000395021645021645
Epoch: 2 | Step: 5250 | Avg. loss: 1.503 | lr: 0.00039457070707070706
Epoch: 2 | Step: 5300 | Avg. loss: 1.501 | lr: 0.0003941197691197691
Epoch: 2 | Step: 5350 | Avg. loss: 1.492 | lr: 0.0003936688311688312
Epoch: 2 | Step: 5400 | Avg. loss: 1.507 | lr: 0.00039321789321789327
Epoch: 2 | Step: 5450 | Avg. loss: 1.499 | lr: 0.0003927669552669553
Epoch: 2 | Step: 5500 | Avg. loss: 1.512 | lr: 0.00039231601731601736
Epoch: 2 | Step: 5550 | Avg. loss: 1.530 | lr: 0.00039186507936507937
Epoch: 2 | Step: 5600 | Avg. loss: 1.481 | lr: 0.00039141414141414144
Epoch: 2 | Step: 5650 | Avg. loss: 1.493 | lr: 0.00039096320346320346
Epoch: 2 | Step: 5700 | Avg. loss: 1.482 | lr: 0.0003905122655122655
Epoch: 2 | Step: 5750 | Avg. loss: 1.520 | lr: 0.00039006132756132754
Epoch: 2 | Step: 5800 | Avg. loss: 1.495 | lr: 0.00038961038961038966
Epoch: 2 | Step: 5850 | Avg. loss: 1.472 | lr: 0.0003891594516594517
Epoch: 2 | Step: 5900 | Avg. loss: 1.500 | lr: 0.00038870851370851375
Epoch: 2 | Step: 5950 | Avg. loss: 1.457 | lr: 0.00038825757575757576
Epoch: 2 | Step: 6000 | Avg. loss: 1.456 | lr: 0.00038780663780663783
Saving model with test loss of 1.597
Epoch: 2 | Step: 6050 | Avg. loss: 1.472 | lr: 0.00038735569985569985
Epoch: 2 | Step: 6100 | Avg. loss: 1.515 | lr: 0.0003869047619047619
Epoch: 2 | Step: 6150 | Avg. loss: 1.500 | lr: 0.00038645382395382393
Epoch: 2 | Step: 6200 | Avg. loss: 1.476 | lr: 0.000386002886002886
Epoch: 2 | Step: 6250 | Avg. loss: 1.495 | lr: 0.000385551948051948
Epoch: 2 | Step: 6300 | Avg. loss: 1.453 | lr: 0.00038510101010101014
Epoch: 2 | Step: 6350 | Avg. loss: 1.476 | lr: 0.00038465007215007216
Epoch: 2 | Step: 6400 | Avg. loss: 1.434 | lr: 0.0003841991341991342
Epoch: 2 | Step: 6450 | Avg. loss: 1.442 | lr: 0.00038374819624819624
Epoch: 2 | Step: 6500 | Avg. loss: 1.493 | lr: 0.0003832972582972583
Epoch: 2 | Step: 6550 | Avg. loss: 1.481 | lr: 0.0003828463203463203
Epoch: 2 | Step: 6600 | Avg. loss: 1.439 | lr: 0.0003823953823953824
Epoch: 2 | Step: 6650 | Avg. loss: 1.476 | lr: 0.0003819444444444444
Epoch: 2 | Step: 6700 | Avg. loss: 1.461 | lr: 0.0003814935064935065
Epoch: 2 | Step: 6750 | Avg. loss: 1.463 | lr: 0.00038104256854256855
Epoch: 2 | Step: 6800 | Avg. loss: 1.444 | lr: 0.0003805916305916306
Epoch: 2 | Step: 6850 | Avg. loss: 1.381 | lr: 0.0003801406926406927
Epoch: 2 | Step: 6900 | Avg. loss: 1.439 | lr: 0.0003796897546897547
Epoch: 2 | Step: 6950 | Avg. loss: 1.462 | lr: 0.00037923881673881677
Epoch: 2 | Step: 7000 | Avg. loss: 1.509 | lr: 0.0003787878787878788
Saving model with test loss of 1.590
  0%|          | 0/7000 [00:00<?, ?it/s]
Epoch: 3 | Step: 50 | Avg. loss: 1.445 | lr: 0.00037833694083694086
Epoch: 3 | Step: 100 | Avg. loss: 1.460 | lr: 0.00037788600288600287
Epoch: 3 | Step: 150 | Avg. loss: 1.411 | lr: 0.00037743506493506494
Epoch: 3 | Step: 200 | Avg. loss: 1.448 | lr: 0.000376984126984127
Epoch: 3 | Step: 250 | Avg. loss: 1.418 | lr: 0.0003765331890331891
Epoch: 3 | Step: 300 | Avg. loss: 1.483 | lr: 0.0003760822510822511
Epoch: 3 | Step: 350 | Avg. loss: 1.419 | lr: 0.00037563131313131316
Epoch: 3 | Step: 400 | Avg. loss: 1.450 | lr: 0.0003751803751803752
Epoch: 3 | Step: 450 | Avg. loss: 1.431 | lr: 0.00037472943722943725
Epoch: 3 | Step: 500 | Avg. loss: 1.462 | lr: 0.00037427849927849926
Epoch: 3 | Step: 550 | Avg. loss: 1.413 | lr: 0.00037382756132756133
Epoch: 3 | Step: 600 | Avg. loss: 1.426 | lr: 0.00037337662337662335
Epoch: 3 | Step: 650 | Avg. loss: 1.419 | lr: 0.00037292568542568547
Epoch: 3 | Step: 700 | Avg. loss: 1.411 | lr: 0.0003724747474747475
Epoch: 3 | Step: 750 | Avg. loss: 1.426 | lr: 0.00037202380952380956
Epoch: 3 | Step: 800 | Avg. loss: 1.385 | lr: 0.00037157287157287157
Epoch: 3 | Step: 850 | Avg. loss: 1.396 | lr: 0.00037112193362193364
Epoch: 3 | Step: 900 | Avg. loss: 1.380 | lr: 0.00037067099567099566
Epoch: 3 | Step: 950 | Avg. loss: 1.372 | lr: 0.0003702200577200577
Epoch: 3 | Step: 1000 | Avg. loss: 1.381 | lr: 0.00036976911976911974
Saving model with test loss of 1.585
Epoch: 3 | Step: 1050 | Avg. loss: 1.349 | lr: 0.0003693181818181818
Epoch: 3 | Step: 1100 | Avg. loss: 1.362 | lr: 0.0003688672438672438
Epoch: 3 | Step: 1150 | Avg. loss: 1.421 | lr: 0.00036841630591630595
Epoch: 3 | Step: 1200 | Avg. loss: 1.392 | lr: 0.00036796536796536797
Epoch: 3 | Step: 1250 | Avg. loss: 1.383 | lr: 0.00036751443001443003
Epoch: 3 | Step: 1300 | Avg. loss: 1.325 | lr: 0.00036706349206349205
Epoch: 3 | Step: 1350 | Avg. loss: 1.360 | lr: 0.0003666125541125541
Epoch: 3 | Step: 1400 | Avg. loss: 1.360 | lr: 0.0003661616161616162
Epoch: 3 | Step: 1450 | Avg. loss: 1.356 | lr: 0.0003657106782106782
Epoch: 3 | Step: 1500 | Avg. loss: 1.358 | lr: 0.0003652597402597403
Epoch: 3 | Step: 1550 | Avg. loss: 1.399 | lr: 0.0003648088023088023
Epoch: 3 | Step: 1600 | Avg. loss: 1.353 | lr: 0.0003643578643578644
Epoch: 3 | Step: 1650 | Avg. loss: 1.352 | lr: 0.0003639069264069264
Epoch: 3 | Step: 1700 | Avg. loss: 1.405 | lr: 0.0003634559884559885
Epoch: 3 | Step: 1750 | Avg. loss: 1.354 | lr: 0.0003630050505050505
Epoch: 3 | Step: 1800 | Avg. loss: 1.363 | lr: 0.0003625541125541126
Epoch: 3 | Step: 1850 | Avg. loss: 1.338 | lr: 0.0003621031746031746
Epoch: 3 | Step: 1900 | Avg. loss: 1.347 | lr: 0.00036165223665223667
Epoch: 3 | Step: 1950 | Avg. loss: 1.358 | lr: 0.0003612012987012987
Epoch: 3 | Step: 2000 | Avg. loss: 1.322 | lr: 0.00036075036075036075
Saving model with test loss of 1.573
Epoch: 3 | Step: 2050 | Avg. loss: 1.323 | lr: 0.0003602994227994228
Epoch: 3 | Step: 2100 | Avg. loss: 1.316 | lr: 0.0003598484848484849
Epoch: 3 | Step: 2150 | Avg. loss: 1.294 | lr: 0.0003593975468975469
Epoch: 3 | Step: 2200 | Avg. loss: 1.345 | lr: 0.000358946608946609
Epoch: 3 | Step: 2250 | Avg. loss: 1.370 | lr: 0.000358495670995671
Epoch: 3 | Step: 2300 | Avg. loss: 1.334 | lr: 0.00035804473304473306
Epoch: 3 | Step: 2350 | Avg. loss: 1.312 | lr: 0.0003575937950937951
Epoch: 3 | Step: 2400 | Avg. loss: 1.305 | lr: 0.00035714285714285714
Epoch: 3 | Step: 2450 | Avg. loss: 1.291 | lr: 0.00035669191919191916
Epoch: 3 | Step: 2500 | Avg. loss: 1.304 | lr: 0.0003562409812409813
Epoch: 3 | Step: 2550 | Avg. loss: 1.276 | lr: 0.0003557900432900433
Epoch: 3 | Step: 2600 | Avg. loss: 1.286 | lr: 0.00035533910533910537
Epoch: 3 | Step: 2650 | Avg. loss: 1.357 | lr: 0.0003548881673881674
Epoch: 3 | Step: 2700 | Avg. loss: 1.263 | lr: 0.00035443722943722945
Epoch: 3 | Step: 2750 | Avg. loss: 1.271 | lr: 0.00035398629148629147
Epoch: 3 | Step: 2800 | Avg. loss: 1.259 | lr: 0.00035353535353535354
Epoch: 3 | Step: 2850 | Avg. loss: 1.345 | lr: 0.0003530844155844156
Epoch: 3 | Step: 2900 | Avg. loss: 1.268 | lr: 0.0003526334776334776
Epoch: 3 | Step: 2950 | Avg. loss: 1.337 | lr: 0.0003521825396825397
Epoch: 3 | Step: 3000 | Avg. loss: 1.263 | lr: 0.00035173160173160176
Saving model with test loss of 1.564
Epoch: 3 | Step: 3050 | Avg. loss: 1.321 | lr: 0.00035128066378066383
Epoch: 3 | Step: 3100 | Avg. loss: 1.282 | lr: 0.00035082972582972584
Epoch: 3 | Step: 3150 | Avg. loss: 1.319 | lr: 0.0003503787878787879
Epoch: 3 | Step: 3200 | Avg. loss: 1.321 | lr: 0.00034992784992784993
Epoch: 3 | Step: 3250 | Avg. loss: 1.281 | lr: 0.000349476911976912
Epoch: 3 | Step: 3300 | Avg. loss: 1.260 | lr: 0.000349025974025974
Epoch: 3 | Step: 3350 | Avg. loss: 1.268 | lr: 0.0003485750360750361
Epoch: 3 | Step: 3400 | Avg. loss: 1.299 | lr: 0.0003481240981240981
Epoch: 3 | Step: 3450 | Avg. loss: 1.247 | lr: 0.0003476731601731602
Epoch: 3 | Step: 3500 | Avg. loss: 1.272 | lr: 0.00034722222222222224
Epoch: 3 | Step: 3550 | Avg. loss: 1.273 | lr: 0.0003467712842712843
Epoch: 3 | Step: 3600 | Avg. loss: 1.300 | lr: 0.0003463203463203463
Epoch: 3 | Step: 3650 | Avg. loss: 1.256 | lr: 0.0003458694083694084
Epoch: 3 | Step: 3700 | Avg. loss: 1.254 | lr: 0.0003454184704184704
Epoch: 3 | Step: 3750 | Avg. loss: 1.227 | lr: 0.0003449675324675325
Epoch: 3 | Step: 3800 | Avg. loss: 1.230 | lr: 0.0003445165945165945
Epoch: 3 | Step: 3850 | Avg. loss: 1.229 | lr: 0.00034406565656565656
Epoch: 3 | Step: 3900 | Avg. loss: 1.272 | lr: 0.00034361471861471863
Epoch: 3 | Step: 3950 | Avg. loss: 1.297 | lr: 0.0003431637806637807
Epoch: 3 | Step: 4000 | Avg. loss: 1.277 | lr: 0.0003427128427128427
Saving model with test loss of 1.564
Epoch: 3 | Step: 4050 | Avg. loss: 1.271 | lr: 0.0003422619047619048
Epoch: 3 | Step: 4100 | Avg. loss: 1.233 | lr: 0.0003418109668109668
Epoch: 3 | Step: 4150 | Avg. loss: 1.303 | lr: 0.00034136002886002887
Epoch: 3 | Step: 4200 | Avg. loss: 1.256 | lr: 0.0003409090909090909
Epoch: 3 | Step: 4250 | Avg. loss: 1.236 | lr: 0.00034045815295815295
Epoch: 3 | Step: 4300 | Avg. loss: 1.240 | lr: 0.00034000721500721497
Epoch: 3 | Step: 4350 | Avg. loss: 1.247 | lr: 0.0003395562770562771
Epoch: 3 | Step: 4400 | Avg. loss: 1.217 | lr: 0.00033910533910533916
Epoch: 3 | Step: 4450 | Avg. loss: 1.257 | lr: 0.0003386544011544012
Epoch: 3 | Step: 4500 | Avg. loss: 1.211 | lr: 0.00033820346320346324
Epoch: 3 | Step: 4550 | Avg. loss: 1.264 | lr: 0.00033775252525252526
Epoch: 3 | Step: 4600 | Avg. loss: 1.227 | lr: 0.00033730158730158733
Epoch: 3 | Step: 4650 | Avg. loss: 1.275 | lr: 0.00033685064935064934
Epoch: 3 | Step: 4700 | Avg. loss: 1.297 | lr: 0.0003363997113997114
Epoch: 3 | Step: 4750 | Avg. loss: 1.229 | lr: 0.00033594877344877343
Epoch: 3 | Step: 4800 | Avg. loss: 1.252 | lr: 0.0003354978354978355
Epoch: 3 | Step: 4850 | Avg. loss: 1.234 | lr: 0.00033504689754689757
Epoch: 3 | Step: 4900 | Avg. loss: 1.156 | lr: 0.00033459595959595964
Epoch: 3 | Step: 4950 | Avg. loss: 1.197 | lr: 0.00033414502164502165
Epoch: 3 | Step: 5000 | Avg. loss: 1.162 | lr: 0.0003336940836940837
Saving model with test loss of 1.560
Epoch: 3 | Step: 5050 | Avg. loss: 1.169 | lr: 0.00033324314574314574
Epoch: 3 | Step: 5100 | Avg. loss: 1.225 | lr: 0.0003327922077922078
Epoch: 3 | Step: 5150 | Avg. loss: 1.195 | lr: 0.0003323412698412698
Epoch: 3 | Step: 5200 | Avg. loss: 1.192 | lr: 0.0003318903318903319
Epoch: 3 | Step: 5250 | Avg. loss: 1.201 | lr: 0.0003314393939393939
Epoch: 3 | Step: 5300 | Avg. loss: 1.191 | lr: 0.00033098845598845603
Epoch: 3 | Step: 5350 | Avg. loss: 1.187 | lr: 0.00033053751803751804
Epoch: 3 | Step: 5400 | Avg. loss: 1.194 | lr: 0.0003300865800865801
Epoch: 3 | Step: 5450 | Avg. loss: 1.187 | lr: 0.00032963564213564213
Epoch: 3 | Step: 5500 | Avg. loss: 1.197 | lr: 0.0003291847041847042
Epoch: 3 | Step: 5550 | Avg. loss: 1.223 | lr: 0.0003287337662337662
Epoch: 3 | Step: 5600 | Avg. loss: 1.178 | lr: 0.0003282828282828283
Epoch: 3 | Step: 5650 | Avg. loss: 1.183 | lr: 0.0003278318903318903
Epoch: 3 | Step: 5700 | Avg. loss: 1.175 | lr: 0.00032738095238095237
Epoch: 3 | Step: 5750 | Avg. loss: 1.209 | lr: 0.00032693001443001444
Epoch: 3 | Step: 5800 | Avg. loss: 1.167 | lr: 0.0003264790764790765
Epoch: 3 | Step: 5850 | Avg. loss: 1.174 | lr: 0.0003260281385281386
Epoch: 3 | Step: 5900 | Avg. loss: 1.200 | lr: 0.0003255772005772006
Epoch: 3 | Step: 5950 | Avg. loss: 1.157 | lr: 0.00032512626262626266
Epoch: 3 | Step: 6000 | Avg. loss: 1.161 | lr: 0.0003246753246753247
Saving model with test loss of 1.512
Epoch: 3 | Step: 6050 | Avg. loss: 1.164 | lr: 0.00032422438672438674
Epoch: 3 | Step: 6100 | Avg. loss: 1.206 | lr: 0.00032377344877344876
Epoch: 3 | Step: 6150 | Avg. loss: 1.211 | lr: 0.00032332251082251083
Epoch: 3 | Step: 6200 | Avg. loss: 1.180 | lr: 0.0003228715728715729
Epoch: 3 | Step: 6250 | Avg. loss: 1.202 | lr: 0.00032242063492063497
Epoch: 3 | Step: 6300 | Avg. loss: 1.159 | lr: 0.000321969696969697
Epoch: 3 | Step: 6350 | Avg. loss: 1.149 | lr: 0.00032151875901875905
Epoch: 3 | Step: 6400 | Avg. loss: 1.126 | lr: 0.00032106782106782107
Epoch: 3 | Step: 6450 | Avg. loss: 1.145 | lr: 0.00032061688311688314
Epoch: 3 | Step: 6500 | Avg. loss: 1.185 | lr: 0.00032016594516594515
Epoch: 3 | Step: 6550 | Avg. loss: 1.182 | lr: 0.0003197150072150072
Epoch: 3 | Step: 6600 | Avg. loss: 1.136 | lr: 0.00031926406926406924
Epoch: 3 | Step: 6650 | Avg. loss: 1.173 | lr: 0.0003188131313131313
Epoch: 3 | Step: 6700 | Avg. loss: 1.162 | lr: 0.0003183621933621934
Epoch: 3 | Step: 6750 | Avg. loss: 1.164 | lr: 0.00031791125541125544
Epoch: 3 | Step: 6800 | Avg. loss: 1.153 | lr: 0.00031746031746031746
Epoch: 3 | Step: 6850 | Avg. loss: 1.084 | lr: 0.00031700937950937953
Epoch: 3 | Step: 6900 | Avg. loss: 1.128 | lr: 0.00031655844155844154
Epoch: 3 | Step: 6950 | Avg. loss: 1.167 | lr: 0.0003161075036075036
Epoch: 3 | Step: 7000 | Avg. loss: 1.189 | lr: 0.00031565656565656563
Saving model with test loss of 1.536
  0%|          | 0/7000 [00:00<?, ?it/s]
Epoch: 4 | Step: 50 | Avg. loss: 1.141 | lr: 0.0003152056277056277
Epoch: 4 | Step: 100 | Avg. loss: 1.167 | lr: 0.0003147546897546897
Epoch: 4 | Step: 150 | Avg. loss: 1.114 | lr: 0.00031430375180375184
Epoch: 4 | Step: 200 | Avg. loss: 1.150 | lr: 0.00031385281385281385
Epoch: 4 | Step: 250 | Avg. loss: 1.132 | lr: 0.0003134018759018759
Epoch: 4 | Step: 300 | Avg. loss: 1.193 | lr: 0.00031295093795093794
Epoch: 4 | Step: 350 | Avg. loss: 1.118 | lr: 0.0003125
Epoch: 4 | Step: 400 | Avg. loss: 1.151 | lr: 0.0003120490620490621
Epoch: 4 | Step: 450 | Avg. loss: 1.132 | lr: 0.0003115981240981241
Epoch: 4 | Step: 500 | Avg. loss: 1.164 | lr: 0.00031114718614718616
Epoch: 4 | Step: 550 | Avg. loss: 1.110 | lr: 0.0003106962481962482
Epoch: 4 | Step: 600 | Avg. loss: 1.153 | lr: 0.0003102453102453103
Epoch: 4 | Step: 650 | Avg. loss: 1.131 | lr: 0.0003097943722943723
Epoch: 4 | Step: 700 | Avg. loss: 1.121 | lr: 0.0003093434343434344
Epoch: 4 | Step: 750 | Avg. loss: 1.144 | lr: 0.0003088924963924964
Epoch: 4 | Step: 800 | Avg. loss: 1.094 | lr: 0.00030844155844155847
Epoch: 4 | Step: 850 | Avg. loss: 1.104 | lr: 0.0003079906204906205
Epoch: 4 | Step: 900 | Avg. loss: 1.098 | lr: 0.00030753968253968255
Epoch: 4 | Step: 950 | Avg. loss: 1.097 | lr: 0.00030708874458874457
Epoch: 4 | Step: 1000 | Avg. loss: 1.097 | lr: 0.00030663780663780664
Saving model with test loss of 1.563
Epoch: 4 | Step: 1050 | Avg. loss: 1.061 | lr: 0.0003061868686868687
Epoch: 4 | Step: 1100 | Avg. loss: 1.072 | lr: 0.0003057359307359308
Epoch: 4 | Step: 1150 | Avg. loss: 1.124 | lr: 0.0003052849927849928
Epoch: 4 | Step: 1200 | Avg. loss: 1.113 | lr: 0.00030483405483405486
Epoch: 4 | Step: 1250 | Avg. loss: 1.101 | lr: 0.0003043831168831169
Epoch: 4 | Step: 1300 | Avg. loss: 1.054 | lr: 0.00030393217893217895
Epoch: 4 | Step: 1350 | Avg. loss: 1.074 | lr: 0.00030348124098124096
Epoch: 4 | Step: 1400 | Avg. loss: 1.087 | lr: 0.00030303030303030303
Epoch: 4 | Step: 1450 | Avg. loss: 1.071 | lr: 0.00030257936507936505
Epoch: 4 | Step: 1500 | Avg. loss: 1.069 | lr: 0.0003021284271284271
Epoch: 4 | Step: 1550 | Avg. loss: 1.106 | lr: 0.0003016774891774892
Epoch: 4 | Step: 1600 | Avg. loss: 1.063 | lr: 0.00030122655122655125
Epoch: 4 | Step: 1650 | Avg. loss: 1.081 | lr: 0.00030077561327561327
Epoch: 4 | Step: 1700 | Avg. loss: 1.106 | lr: 0.00030032467532467534
Epoch: 4 | Step: 1750 | Avg. loss: 1.064 | lr: 0.00029987373737373735
Epoch: 4 | Step: 1800 | Avg. loss: 1.077 | lr: 0.0002994227994227994
Epoch: 4 | Step: 1850 | Avg. loss: 1.056 | lr: 0.00029897186147186144
Epoch: 4 | Step: 1900 | Avg. loss: 1.060 | lr: 0.0002985209235209235
Epoch: 4 | Step: 1950 | Avg. loss: 1.065 | lr: 0.0002980699855699856
Epoch: 4 | Step: 2000 | Avg. loss: 1.030 | lr: 0.00029761904761904765
Saving model with test loss of 1.569
Epoch: 4 | Step: 2050 | Avg. loss: 1.047 | lr: 0.0002971681096681097
Epoch: 4 | Step: 2100 | Avg. loss: 1.038 | lr: 0.00029671717171717173
Epoch: 4 | Step: 2150 | Avg. loss: 1.016 | lr: 0.0002962662337662338
Epoch: 4 | Step: 2200 | Avg. loss: 1.072 | lr: 0.0002958152958152958
Epoch: 4 | Step: 2250 | Avg. loss: 1.078 | lr: 0.0002953643578643579
Epoch: 4 | Step: 2300 | Avg. loss: 1.055 | lr: 0.0002949134199134199
Epoch: 4 | Step: 2350 | Avg. loss: 1.030 | lr: 0.00029446248196248197
Epoch: 4 | Step: 2400 | Avg. loss: 1.032 | lr: 0.000294011544011544
Epoch: 4 | Step: 2450 | Avg. loss: 1.015 | lr: 0.0002935606060606061
Epoch: 4 | Step: 2500 | Avg. loss: 1.037 | lr: 0.0002931096681096681
Epoch: 4 | Step: 2550 | Avg. loss: 1.009 | lr: 0.0002926587301587302
Epoch: 4 | Step: 2600 | Avg. loss: 1.021 | lr: 0.0002922077922077922
Epoch: 4 | Step: 2650 | Avg. loss: 1.079 | lr: 0.0002917568542568543
Epoch: 4 | Step: 2700 | Avg. loss: 0.990 | lr: 0.0002913059163059163
Epoch: 4 | Step: 2750 | Avg. loss: 0.997 | lr: 0.00029085497835497836
Epoch: 4 | Step: 2800 | Avg. loss: 0.977 | lr: 0.0002904040404040404
Epoch: 4 | Step: 2850 | Avg. loss: 1.064 | lr: 0.00028995310245310245
Epoch: 4 | Step: 2900 | Avg. loss: 0.993 | lr: 0.0002895021645021645
Epoch: 4 | Step: 2950 | Avg. loss: 1.072 | lr: 0.0002890512265512266
Epoch: 4 | Step: 3000 | Avg. loss: 0.993 | lr: 0.0002886002886002886
Saving model with test loss of 1.556
Epoch: 4 | Step: 3050 | Avg. loss: 1.049 | lr: 0.00028814935064935067
Epoch: 4 | Step: 3100 | Avg. loss: 0.994 | lr: 0.0002876984126984127
Epoch: 4 | Step: 3150 | Avg. loss: 1.036 | lr: 0.00028724747474747475
Epoch: 4 | Step: 3200 | Avg. loss: 1.044 | lr: 0.00028679653679653677
Epoch: 4 | Step: 3250 | Avg. loss: 1.007 | lr: 0.00028634559884559884
Epoch: 4 | Step: 3300 | Avg. loss: 0.991 | lr: 0.00028589466089466085
Epoch: 4 | Step: 3350 | Avg. loss: 1.003 | lr: 0.0002854437229437229
Epoch: 4 | Step: 3400 | Avg. loss: 1.027 | lr: 0.00028499278499278505
Epoch: 4 | Step: 3450 | Avg. loss: 0.973 | lr: 0.00028454184704184706
Epoch: 4 | Step: 3500 | Avg. loss: 1.003 | lr: 0.00028409090909090913
Epoch: 4 | Step: 3550 | Avg. loss: 1.002 | lr: 0.00028363997113997115
Epoch: 4 | Step: 3600 | Avg. loss: 1.020 | lr: 0.0002831890331890332
Epoch: 4 | Step: 3650 | Avg. loss: 0.999 | lr: 0.00028273809523809523
Epoch: 4 | Step: 3700 | Avg. loss: 0.988 | lr: 0.0002822871572871573
Epoch: 4 | Step: 3750 | Avg. loss: 0.959 | lr: 0.0002818362193362193
Epoch: 4 | Step: 3800 | Avg. loss: 0.962 | lr: 0.0002813852813852814
Epoch: 4 | Step: 3850 | Avg. loss: 0.970 | lr: 0.00028093434343434345
Epoch: 4 | Step: 3900 | Avg. loss: 1.008 | lr: 0.0002804834054834055
Epoch: 4 | Step: 3950 | Avg. loss: 1.027 | lr: 0.00028003246753246754
Epoch: 4 | Step: 4000 | Avg. loss: 0.996 | lr: 0.0002795815295815296
Saving model with test loss of 1.586
Epoch: 4 | Step: 4050 | Avg. loss: 1.001 | lr: 0.0002791305916305916
Epoch: 4 | Step: 4100 | Avg. loss: 0.955 | lr: 0.0002786796536796537
Epoch: 4 | Step: 4150 | Avg. loss: 1.040 | lr: 0.0002782287157287157
Epoch: 4 | Step: 4200 | Avg. loss: 1.003 | lr: 0.0002777777777777778
Epoch: 4 | Step: 4250 | Avg. loss: 0.976 | lr: 0.0002773268398268398
Epoch: 4 | Step: 4300 | Avg. loss: 0.959 | lr: 0.0002768759018759019
Epoch: 4 | Step: 4350 | Avg. loss: 0.969 | lr: 0.00027642496392496393
Epoch: 4 | Step: 4400 | Avg. loss: 0.959 | lr: 0.000275974025974026
Epoch: 4 | Step: 4450 | Avg. loss: 0.977 | lr: 0.000275523088023088
Epoch: 4 | Step: 4500 | Avg. loss: 0.961 | lr: 0.0002750721500721501
Epoch: 4 | Step: 4550 | Avg. loss: 1.007 | lr: 0.0002746212121212121
Epoch: 4 | Step: 4600 | Avg. loss: 0.957 | lr: 0.00027417027417027417
Epoch: 4 | Step: 4650 | Avg. loss: 1.016 | lr: 0.0002737193362193362
Epoch: 4 | Step: 4700 | Avg. loss: 1.022 | lr: 0.00027326839826839825
Epoch: 4 | Step: 4750 | Avg. loss: 0.967 | lr: 0.0002728174603174603
Epoch: 4 | Step: 4800 | Avg. loss: 0.988 | lr: 0.0002723665223665224
Epoch: 4 | Step: 4850 | Avg. loss: 0.980 | lr: 0.0002719155844155844
Epoch: 4 | Step: 4900 | Avg. loss: 0.900 | lr: 0.0002714646464646465
Epoch: 4 | Step: 4950 | Avg. loss: 0.935 | lr: 0.00027101370851370855
Epoch: 4 | Step: 5000 | Avg. loss: 0.916 | lr: 0.00027056277056277056
Saving model with test loss of 1.588
Epoch: 4 | Step: 5050 | Avg. loss: 0.916 | lr: 0.00027011183261183263
Epoch: 4 | Step: 5100 | Avg. loss: 0.964 | lr: 0.00026966089466089465
Epoch: 4 | Step: 5150 | Avg. loss: 0.940 | lr: 0.0002692099567099567
Epoch: 4 | Step: 5200 | Avg. loss: 0.934 | lr: 0.00026875901875901873
Epoch: 4 | Step: 5250 | Avg. loss: 0.938 | lr: 0.00026830808080808086
Epoch: 4 | Step: 5300 | Avg. loss: 0.923 | lr: 0.00026785714285714287
Epoch: 4 | Step: 5350 | Avg. loss: 0.931 | lr: 0.00026740620490620494
Epoch: 4 | Step: 5400 | Avg. loss: 0.931 | lr: 0.00026695526695526696
Epoch: 4 | Step: 5450 | Avg. loss: 0.928 | lr: 0.000266504329004329
Epoch: 4 | Step: 5500 | Avg. loss: 0.934 | lr: 0.00026605339105339104
Epoch: 4 | Step: 5550 | Avg. loss: 0.956 | lr: 0.0002656024531024531
Epoch: 4 | Step: 5600 | Avg. loss: 0.919 | lr: 0.0002651515151515151
Epoch: 4 | Step: 5650 | Avg. loss: 0.928 | lr: 0.0002647005772005772
Epoch: 4 | Step: 5700 | Avg. loss: 0.920 | lr: 0.00026424963924963926
Epoch: 4 | Step: 5750 | Avg. loss: 0.946 | lr: 0.00026379870129870133
Epoch: 4 | Step: 5800 | Avg. loss: 0.908 | lr: 0.00026334776334776335
Epoch: 4 | Step: 5850 | Avg. loss: 0.914 | lr: 0.0002628968253968254
Epoch: 4 | Step: 5900 | Avg. loss: 0.943 | lr: 0.00026244588744588743
Epoch: 4 | Step: 5950 | Avg. loss: 0.898 | lr: 0.0002619949494949495
Epoch: 4 | Step: 6000 | Avg. loss: 0.907 | lr: 0.0002615440115440115
Saving model with test loss of 1.572
Epoch: 4 | Step: 6050 | Avg. loss: 0.904 | lr: 0.0002610930735930736
Epoch: 4 | Step: 6100 | Avg. loss: 0.942 | lr: 0.0002606421356421356
Epoch: 4 | Step: 6150 | Avg. loss: 0.950 | lr: 0.0002601911976911977
Epoch: 4 | Step: 6200 | Avg. loss: 0.922 | lr: 0.00025974025974025974
Epoch: 4 | Step: 6250 | Avg. loss: 0.957 | lr: 0.0002592893217893218
Epoch: 4 | Step: 6300 | Avg. loss: 0.905 | lr: 0.0002588383838383838
Epoch: 4 | Step: 6350 | Avg. loss: 0.886 | lr: 0.0002583874458874459
Epoch: 4 | Step: 6400 | Avg. loss: 0.880 | lr: 0.00025793650793650796
Epoch: 4 | Step: 6450 | Avg. loss: 0.895 | lr: 0.00025748556998557
Epoch: 4 | Step: 6500 | Avg. loss: 0.932 | lr: 0.00025703463203463205
Epoch: 4 | Step: 6550 | Avg. loss: 0.928 | lr: 0.00025658369408369406
Epoch: 4 | Step: 6600 | Avg. loss: 0.893 | lr: 0.0002561327561327562
Epoch: 4 | Step: 6650 | Avg. loss: 0.914 | lr: 0.0002556818181818182
Epoch: 4 | Step: 6700 | Avg. loss: 0.907 | lr: 0.00025523088023088027
Epoch: 4 | Step: 6750 | Avg. loss: 0.918 | lr: 0.0002547799422799423
Epoch: 4 | Step: 6800 | Avg. loss: 0.901 | lr: 0.00025432900432900436
Epoch: 4 | Step: 6850 | Avg. loss: 0.843 | lr: 0.00025387806637806637
Epoch: 4 | Step: 6900 | Avg. loss: 0.880 | lr: 0.00025342712842712844
Epoch: 4 | Step: 6950 | Avg. loss: 0.910 | lr: 0.00025297619047619046
Epoch: 4 | Step: 7000 | Avg. loss: 0.924 | lr: 0.0002525252525252525
Saving model with test loss of 1.585
  0%|          | 0/7000 [00:00<?, ?it/s]
Epoch: 5 | Step: 50 | Avg. loss: 0.882 | lr: 0.00025207431457431454
Epoch: 5 | Step: 100 | Avg. loss: 0.922 | lr: 0.00025162337662337666
Epoch: 5 | Step: 150 | Avg. loss: 0.863 | lr: 0.0002511724386724387
Epoch: 5 | Step: 200 | Avg. loss: 0.893 | lr: 0.00025072150072150075
Epoch: 5 | Step: 250 | Avg. loss: 0.874 | lr: 0.00025027056277056276
Epoch: 5 | Step: 300 | Avg. loss: 0.936 | lr: 0.00024981962481962483
Epoch: 5 | Step: 350 | Avg. loss: 0.867 | lr: 0.0002493686868686869
Epoch: 5 | Step: 400 | Avg. loss: 0.894 | lr: 0.0002489177489177489
Epoch: 5 | Step: 450 | Avg. loss: 0.876 | lr: 0.000248466810966811
Epoch: 5 | Step: 500 | Avg. loss: 0.910 | lr: 0.000248015873015873
Epoch: 5 | Step: 550 | Avg. loss: 0.850 | lr: 0.00024756493506493507
Epoch: 5 | Step: 600 | Avg. loss: 0.910 | lr: 0.00024711399711399714
Epoch: 5 | Step: 650 | Avg. loss: 0.877 | lr: 0.00024666305916305916
Epoch: 5 | Step: 700 | Avg. loss: 0.875 | lr: 0.0002462121212121212
Epoch: 5 | Step: 750 | Avg. loss: 0.892 | lr: 0.0002457611832611833
Epoch: 5 | Step: 800 | Avg. loss: 0.847 | lr: 0.0002453102453102453
Epoch: 5 | Step: 850 | Avg. loss: 0.852 | lr: 0.0002448593073593074
Epoch: 5 | Step: 900 | Avg. loss: 0.855 | lr: 0.0002444083694083694
Epoch: 5 | Step: 950 | Avg. loss: 0.855 | lr: 0.00024395743145743146
Epoch: 5 | Step: 1000 | Avg. loss: 0.855 | lr: 0.0002435064935064935
Saving model with test loss of 1.637
Epoch: 5 | Step: 1050 | Avg. loss: 0.818 | lr: 0.00024305555555555555
Epoch: 5 | Step: 1100 | Avg. loss: 0.825 | lr: 0.00024260461760461762
Epoch: 5 | Step: 1150 | Avg. loss: 0.864 | lr: 0.00024215367965367966
Epoch: 5 | Step: 1200 | Avg. loss: 0.866 | lr: 0.0002417027417027417
Epoch: 5 | Step: 1250 | Avg. loss: 0.860 | lr: 0.00024125180375180374
Epoch: 5 | Step: 1300 | Avg. loss: 0.817 | lr: 0.0002408008658008658
Epoch: 5 | Step: 1350 | Avg. loss: 0.829 | lr: 0.00024034992784992786
Epoch: 5 | Step: 1400 | Avg. loss: 0.848 | lr: 0.0002398989898989899
Epoch: 5 | Step: 1450 | Avg. loss: 0.822 | lr: 0.00023944805194805194
Epoch: 5 | Step: 1500 | Avg. loss: 0.822 | lr: 0.00023899711399711398
Epoch: 5 | Step: 1550 | Avg. loss: 0.865 | lr: 0.00023854617604617603
Epoch: 5 | Step: 1600 | Avg. loss: 0.822 | lr: 0.0002380952380952381
Epoch: 5 | Step: 1650 | Avg. loss: 0.837 | lr: 0.00023764430014430016
Epoch: 5 | Step: 1700 | Avg. loss: 0.856 | lr: 0.0002371933621933622
Epoch: 5 | Step: 1750 | Avg. loss: 0.821 | lr: 0.00023674242424242425
Epoch: 5 | Step: 1800 | Avg. loss: 0.822 | lr: 0.00023629148629148632
Epoch: 5 | Step: 1850 | Avg. loss: 0.818 | lr: 0.00023584054834054836
Epoch: 5 | Step: 1900 | Avg. loss: 0.812 | lr: 0.0002353896103896104
Epoch: 5 | Step: 1950 | Avg. loss: 0.824 | lr: 0.00023493867243867245
Epoch: 5 | Step: 2000 | Avg. loss: 0.791 | lr: 0.0002344877344877345
Saving model with test loss of 1.655
Epoch: 5 | Step: 2050 | Avg. loss: 0.814 | lr: 0.00023403679653679656
Epoch: 5 | Step: 2100 | Avg. loss: 0.796 | lr: 0.0002335858585858586
Epoch: 5 | Step: 2150 | Avg. loss: 0.781 | lr: 0.00023313492063492064
Epoch: 5 | Step: 2200 | Avg. loss: 0.828 | lr: 0.00023268398268398268
Epoch: 5 | Step: 2250 | Avg. loss: 0.835 | lr: 0.00023223304473304475
Epoch: 5 | Step: 2300 | Avg. loss: 0.809 | lr: 0.0002317821067821068
Epoch: 5 | Step: 2350 | Avg. loss: 0.792 | lr: 0.00023133116883116884
Epoch: 5 | Step: 2400 | Avg. loss: 0.799 | lr: 0.00023088023088023088
Epoch: 5 | Step: 2450 | Avg. loss: 0.775 | lr: 0.00023042929292929292
Epoch: 5 | Step: 2500 | Avg. loss: 0.797 | lr: 0.000229978354978355
Epoch: 5 | Step: 2550 | Avg. loss: 0.774 | lr: 0.00022952741702741703
Epoch: 5 | Step: 2600 | Avg. loss: 0.788 | lr: 0.00022907647907647908
Epoch: 5 | Step: 2650 | Avg. loss: 0.838 | lr: 0.00022862554112554112
Epoch: 5 | Step: 2700 | Avg. loss: 0.764 | lr: 0.00022817460317460316
Epoch: 5 | Step: 2750 | Avg. loss: 0.769 | lr: 0.00022772366522366523
Epoch: 5 | Step: 2800 | Avg. loss: 0.751 | lr: 0.00022727272727272727
Epoch: 5 | Step: 2850 | Avg. loss: 0.826 | lr: 0.00022682178932178931
Epoch: 5 | Step: 2900 | Avg. loss: 0.760 | lr: 0.00022637085137085136
Epoch: 5 | Step: 2950 | Avg. loss: 0.832 | lr: 0.00022591991341991343
Epoch: 5 | Step: 3000 | Avg. loss: 0.759 | lr: 0.00022546897546897547
Saving model with test loss of 1.688
Epoch: 5 | Step: 3050 | Avg. loss: 0.819 | lr: 0.0002250180375180375
Epoch: 5 | Step: 3100 | Avg. loss: 0.766 | lr: 0.00022456709956709955
Epoch: 5 | Step: 3150 | Avg. loss: 0.797 | lr: 0.00022411616161616162
Epoch: 5 | Step: 3200 | Avg. loss: 0.801 | lr: 0.0002236652236652237
Epoch: 5 | Step: 3250 | Avg. loss: 0.775 | lr: 0.00022321428571428573
Epoch: 5 | Step: 3300 | Avg. loss: 0.765 | lr: 0.00022276334776334778
Epoch: 5 | Step: 3350 | Avg. loss: 0.771 | lr: 0.00022231240981240982
Epoch: 5 | Step: 3400 | Avg. loss: 0.792 | lr: 0.0002218614718614719
Epoch: 5 | Step: 3450 | Avg. loss: 0.748 | lr: 0.00022141053391053393
Epoch: 5 | Step: 3500 | Avg. loss: 0.773 | lr: 0.00022095959595959597
Epoch: 5 | Step: 3550 | Avg. loss: 0.762 | lr: 0.00022050865800865802
Epoch: 5 | Step: 3600 | Avg. loss: 0.777 | lr: 0.00022005772005772006
Epoch: 5 | Step: 3650 | Avg. loss: 0.770 | lr: 0.00021960678210678213
Epoch: 5 | Step: 3700 | Avg. loss: 0.754 | lr: 0.00021915584415584417
Epoch: 5 | Step: 3750 | Avg. loss: 0.736 | lr: 0.0002187049062049062
Epoch: 5 | Step: 3800 | Avg. loss: 0.728 | lr: 0.00021825396825396825
Epoch: 5 | Step: 3850 | Avg. loss: 0.745 | lr: 0.0002178030303030303
Epoch: 5 | Step: 3900 | Avg. loss: 0.773 | lr: 0.00021735209235209237
Epoch: 5 | Step: 3950 | Avg. loss: 0.797 | lr: 0.0002169011544011544
Epoch: 5 | Step: 4000 | Avg. loss: 0.761 | lr: 0.00021645021645021645
Saving model with test loss of 1.669
Epoch: 5 | Step: 4050 | Avg. loss: 0.768 | lr: 0.0002159992784992785
Epoch: 5 | Step: 4100 | Avg. loss: 0.730 | lr: 0.00021554834054834056
Epoch: 5 | Step: 4150 | Avg. loss: 0.802 | lr: 0.0002150974025974026
Epoch: 5 | Step: 4200 | Avg. loss: 0.777 | lr: 0.00021464646464646465
Epoch: 5 | Step: 4250 | Avg. loss: 0.757 | lr: 0.0002141955266955267
Epoch: 5 | Step: 4300 | Avg. loss: 0.728 | lr: 0.00021374458874458873
Epoch: 5 | Step: 4350 | Avg. loss: 0.737 | lr: 0.0002132936507936508
Epoch: 5 | Step: 4400 | Avg. loss: 0.727 | lr: 0.00021284271284271284
Epoch: 5 | Step: 4450 | Avg. loss: 0.745 | lr: 0.00021239177489177488
Epoch: 5 | Step: 4500 | Avg. loss: 0.737 | lr: 0.00021194083694083693
Epoch: 5 | Step: 4550 | Avg. loss: 0.776 | lr: 0.00021148989898989897
Epoch: 5 | Step: 4600 | Avg. loss: 0.737 | lr: 0.00021103896103896104
Epoch: 5 | Step: 4650 | Avg. loss: 0.788 | lr: 0.0002105880230880231
Epoch: 5 | Step: 4700 | Avg. loss: 0.786 | lr: 0.00021013708513708515
Epoch: 5 | Step: 4750 | Avg. loss: 0.745 | lr: 0.0002096861471861472
Epoch: 5 | Step: 4800 | Avg. loss: 0.752 | lr: 0.00020923520923520926
Epoch: 5 | Step: 4850 | Avg. loss: 0.758 | lr: 0.0002087842712842713
Epoch: 5 | Step: 4900 | Avg. loss: 0.683 | lr: 0.00020833333333333335
Epoch: 5 | Step: 4950 | Avg. loss: 0.713 | lr: 0.0002078823953823954
Epoch: 5 | Step: 5000 | Avg. loss: 0.693 | lr: 0.00020743145743145743
Saving model with test loss of 1.697
Epoch: 5 | Step: 5050 | Avg. loss: 0.695 | lr: 0.0002069805194805195
Epoch: 5 | Step: 5100 | Avg. loss: 0.740 | lr: 0.00020652958152958154
Epoch: 5 | Step: 5150 | Avg. loss: 0.711 | lr: 0.00020607864357864359
Epoch: 5 | Step: 5200 | Avg. loss: 0.707 | lr: 0.00020562770562770563
Epoch: 5 | Step: 5250 | Avg. loss: 0.716 | lr: 0.0002051767676767677
Epoch: 5 | Step: 5300 | Avg. loss: 0.709 | lr: 0.00020472582972582974
Epoch: 5 | Step: 5350 | Avg. loss: 0.711 | lr: 0.00020427489177489178
Epoch: 5 | Step: 5400 | Avg. loss: 0.712 | lr: 0.00020382395382395382
Epoch: 5 | Step: 5450 | Avg. loss: 0.707 | lr: 0.00020337301587301587
Epoch: 5 | Step: 5500 | Avg. loss: 0.701 | lr: 0.00020292207792207794
Epoch: 5 | Step: 5550 | Avg. loss: 0.729 | lr: 0.00020247113997113998
Epoch: 5 | Step: 5600 | Avg. loss: 0.700 | lr: 0.00020202020202020202
Epoch: 5 | Step: 5650 | Avg. loss: 0.692 | lr: 0.00020156926406926406
Epoch: 5 | Step: 5700 | Avg. loss: 0.707 | lr: 0.0002011183261183261
Epoch: 5 | Step: 5750 | Avg. loss: 0.722 | lr: 0.00020066738816738817
Epoch: 5 | Step: 5800 | Avg. loss: 0.684 | lr: 0.00020021645021645022
Epoch: 5 | Step: 5850 | Avg. loss: 0.693 | lr: 0.00019976551226551226
Epoch: 5 | Step: 5900 | Avg. loss: 0.718 | lr: 0.0001993145743145743
Epoch: 5 | Step: 5950 | Avg. loss: 0.677 | lr: 0.00019886363636363637
Epoch: 5 | Step: 6000 | Avg. loss: 0.691 | lr: 0.0001984126984126984
Saving model with test loss of 1.726
Epoch: 5 | Step: 6050 | Avg. loss: 0.676 | lr: 0.00019796176046176045
Epoch: 5 | Step: 6100 | Avg. loss: 0.718 | lr: 0.0001975108225108225
Epoch: 5 | Step: 6150 | Avg. loss: 0.728 | lr: 0.00019705988455988454
Epoch: 5 | Step: 6200 | Avg. loss: 0.705 | lr: 0.00019660894660894664
Epoch: 5 | Step: 6250 | Avg. loss: 0.735 | lr: 0.00019615800865800868
Epoch: 5 | Step: 6300 | Avg. loss: 0.690 | lr: 0.00019570707070707072
Epoch: 5 | Step: 6350 | Avg. loss: 0.665 | lr: 0.00019525613275613276
Epoch: 5 | Step: 6400 | Avg. loss: 0.661 | lr: 0.00019480519480519483
Epoch: 5 | Step: 6450 | Avg. loss: 0.682 | lr: 0.00019435425685425687
Epoch: 5 | Step: 6500 | Avg. loss: 0.708 | lr: 0.00019390331890331892
Epoch: 5 | Step: 6550 | Avg. loss: 0.698 | lr: 0.00019345238095238096
Epoch: 5 | Step: 6600 | Avg. loss: 0.684 | lr: 0.000193001443001443
Epoch: 5 | Step: 6650 | Avg. loss: 0.692 | lr: 0.00019255050505050507
Epoch: 5 | Step: 6700 | Avg. loss: 0.688 | lr: 0.0001920995670995671
Epoch: 5 | Step: 6750 | Avg. loss: 0.700 | lr: 0.00019164862914862916
Epoch: 5 | Step: 6800 | Avg. loss: 0.683 | lr: 0.0001911976911976912
Epoch: 5 | Step: 6850 | Avg. loss: 0.636 | lr: 0.00019074675324675324
Epoch: 5 | Step: 6900 | Avg. loss: 0.675 | lr: 0.0001902958152958153
Epoch: 5 | Step: 6950 | Avg. loss: 0.691 | lr: 0.00018984487734487735
Epoch: 5 | Step: 7000 | Avg. loss: 0.692 | lr: 0.0001893939393939394
Saving model with test loss of 1.730
  0%|          | 0/7000 [00:00<?, ?it/s]
Epoch: 6 | Step: 50 | Avg. loss: 0.666 | lr: 0.00018894300144300144
Epoch: 6 | Step: 100 | Avg. loss: 0.694 | lr: 0.0001884920634920635
Epoch: 6 | Step: 150 | Avg. loss: 0.652 | lr: 0.00018804112554112555
Epoch: 6 | Step: 200 | Avg. loss: 0.675 | lr: 0.0001875901875901876
Epoch: 6 | Step: 250 | Avg. loss: 0.663 | lr: 0.00018713924963924963
Epoch: 6 | Step: 300 | Avg. loss: 0.704 | lr: 0.00018668831168831167
Epoch: 6 | Step: 350 | Avg. loss: 0.652 | lr: 0.00018623737373737374
Epoch: 6 | Step: 400 | Avg. loss: 0.673 | lr: 0.00018578643578643579
Epoch: 6 | Step: 450 | Avg. loss: 0.661 | lr: 0.00018533549783549783
Epoch: 6 | Step: 500 | Avg. loss: 0.687 | lr: 0.00018488455988455987
Epoch: 6 | Step: 550 | Avg. loss: 0.635 | lr: 0.0001844336219336219
Epoch: 6 | Step: 600 | Avg. loss: 0.701 | lr: 0.00018398268398268398
Epoch: 6 | Step: 650 | Avg. loss: 0.661 | lr: 0.00018353174603174602
Epoch: 6 | Step: 700 | Avg. loss: 0.659 | lr: 0.0001830808080808081
Epoch: 6 | Step: 750 | Avg. loss: 0.676 | lr: 0.00018262987012987014
Epoch: 6 | Step: 800 | Avg. loss: 0.631 | lr: 0.0001821789321789322
Epoch: 6 | Step: 850 | Avg. loss: 0.630 | lr: 0.00018172799422799425
Epoch: 6 | Step: 900 | Avg. loss: 0.652 | lr: 0.0001812770562770563
Epoch: 6 | Step: 950 | Avg. loss: 0.647 | lr: 0.00018082611832611833
Epoch: 6 | Step: 1000 | Avg. loss: 0.641 | lr: 0.00018037518037518038
Saving model with test loss of 1.809
Epoch: 6 | Step: 1050 | Avg. loss: 0.606 | lr: 0.00017992424242424244
Epoch: 6 | Step: 1100 | Avg. loss: 0.612 | lr: 0.0001794733044733045
Epoch: 6 | Step: 1150 | Avg. loss: 0.651 | lr: 0.00017902236652236653
Epoch: 6 | Step: 1200 | Avg. loss: 0.643 | lr: 0.00017857142857142857
Epoch: 6 | Step: 1250 | Avg. loss: 0.648 | lr: 0.00017812049062049064
Epoch: 6 | Step: 1300 | Avg. loss: 0.610 | lr: 0.00017766955266955268
Epoch: 6 | Step: 1350 | Avg. loss: 0.618 | lr: 0.00017721861471861473
Epoch: 6 | Step: 1400 | Avg. loss: 0.638 | lr: 0.00017676767676767677
Epoch: 6 | Step: 1450 | Avg. loss: 0.606 | lr: 0.0001763167388167388
Epoch: 6 | Step: 1500 | Avg. loss: 0.623 | lr: 0.00017586580086580088
Epoch: 6 | Step: 1550 | Avg. loss: 0.658 | lr: 0.00017541486291486292
Epoch: 6 | Step: 1600 | Avg. loss: 0.606 | lr: 0.00017496392496392496
Epoch: 6 | Step: 1650 | Avg. loss: 0.634 | lr: 0.000174512987012987
Epoch: 6 | Step: 1700 | Avg. loss: 0.642 | lr: 0.00017406204906204905
Epoch: 6 | Step: 1750 | Avg. loss: 0.616 | lr: 0.00017361111111111112
Epoch: 6 | Step: 1800 | Avg. loss: 0.604 | lr: 0.00017316017316017316
Epoch: 6 | Step: 1850 | Avg. loss: 0.608 | lr: 0.0001727092352092352
Epoch: 6 | Step: 1900 | Avg. loss: 0.600 | lr: 0.00017225829725829724
Epoch: 6 | Step: 1950 | Avg. loss: 0.616 | lr: 0.00017180735930735931
Epoch: 6 | Step: 2000 | Avg. loss: 0.593 | lr: 0.00017135642135642136
Saving model with test loss of 1.841
Epoch: 6 | Step: 2050 | Avg. loss: 0.605 | lr: 0.0001709054834054834
Epoch: 6 | Step: 2100 | Avg. loss: 0.593 | lr: 0.00017045454545454544
Epoch: 6 | Step: 2150 | Avg. loss: 0.585 | lr: 0.00017000360750360748
Epoch: 6 | Step: 2200 | Avg. loss: 0.623 | lr: 0.00016955266955266958
Epoch: 6 | Step: 2250 | Avg. loss: 0.622 | lr: 0.00016910173160173162
Epoch: 6 | Step: 2300 | Avg. loss: 0.602 | lr: 0.00016865079365079366
Epoch: 6 | Step: 2350 | Avg. loss: 0.589 | lr: 0.0001681998556998557
Epoch: 6 | Step: 2400 | Avg. loss: 0.583 | lr: 0.00016774891774891775
Epoch: 6 | Step: 2450 | Avg. loss: 0.571 | lr: 0.00016729797979797982
Epoch: 6 | Step: 2500 | Avg. loss: 0.595 | lr: 0.00016684704184704186
Epoch: 6 | Step: 2550 | Avg. loss: 0.575 | lr: 0.0001663961038961039
Epoch: 6 | Step: 2600 | Avg. loss: 0.586 | lr: 0.00016594516594516595
Epoch: 6 | Step: 2650 | Avg. loss: 0.628 | lr: 0.00016549422799422801
Epoch: 6 | Step: 2700 | Avg. loss: 0.562 | lr: 0.00016504329004329006
Epoch: 6 | Step: 2750 | Avg. loss: 0.565 | lr: 0.0001645923520923521
Epoch: 6 | Step: 2800 | Avg. loss: 0.553 | lr: 0.00016414141414141414
Epoch: 6 | Step: 2850 | Avg. loss: 0.618 | lr: 0.00016369047619047618
Epoch: 6 | Step: 2900 | Avg. loss: 0.563 | lr: 0.00016323953823953825
Epoch: 6 | Step: 2950 | Avg. loss: 0.633 | lr: 0.0001627886002886003
Epoch: 6 | Step: 3000 | Avg. loss: 0.563 | lr: 0.00016233766233766234
Saving model with test loss of 1.872
Epoch: 6 | Step: 3050 | Avg. loss: 0.612 | lr: 0.00016188672438672438
Epoch: 6 | Step: 3100 | Avg. loss: 0.575 | lr: 0.00016143578643578645
Epoch: 6 | Step: 3150 | Avg. loss: 0.601 | lr: 0.0001609848484848485
Epoch: 6 | Step: 3200 | Avg. loss: 0.592 | lr: 0.00016053391053391053
Epoch: 6 | Step: 3250 | Avg. loss: 0.575 | lr: 0.00016008297258297258
Epoch: 6 | Step: 3300 | Avg. loss: 0.568 | lr: 0.00015963203463203462
Epoch: 6 | Step: 3350 | Avg. loss: 0.573 | lr: 0.0001591810966810967
Epoch: 6 | Step: 3400 | Avg. loss: 0.595 | lr: 0.00015873015873015873
Epoch: 6 | Step: 3450 | Avg. loss: 0.556 | lr: 0.00015827922077922077
Epoch: 6 | Step: 3500 | Avg. loss: 0.567 | lr: 0.00015782828282828281
Epoch: 6 | Step: 3550 | Avg. loss: 0.555 | lr: 0.00015737734487734486
Epoch: 6 | Step: 3600 | Avg. loss: 0.570 | lr: 0.00015692640692640693
Epoch: 6 | Step: 3650 | Avg. loss: 0.571 | lr: 0.00015647546897546897
Epoch: 6 | Step: 3700 | Avg. loss: 0.559 | lr: 0.00015602453102453104
Epoch: 6 | Step: 3750 | Avg. loss: 0.537 | lr: 0.00015557359307359308
Epoch: 6 | Step: 3800 | Avg. loss: 0.536 | lr: 0.00015512265512265515
Epoch: 6 | Step: 3850 | Avg. loss: 0.557 | lr: 0.0001546717171717172
Epoch: 6 | Step: 3900 | Avg. loss: 0.566 | lr: 0.00015422077922077923
Epoch: 6 | Step: 3950 | Avg. loss: 0.593 | lr: 0.00015376984126984128
Epoch: 6 | Step: 4000 | Avg. loss: 0.561 | lr: 0.00015331890331890332
Saving model with test loss of 1.896
Epoch: 6 | Step: 4050 | Avg. loss: 0.567 | lr: 0.0001528679653679654
Epoch: 6 | Step: 4100 | Avg. loss: 0.533 | lr: 0.00015241702741702743
Epoch: 6 | Step: 4150 | Avg. loss: 0.592 | lr: 0.00015196608946608947
Epoch: 6 | Step: 4200 | Avg. loss: 0.576 | lr: 0.00015151515151515152
Epoch: 6 | Step: 4250 | Avg. loss: 0.559 | lr: 0.00015106421356421356
Epoch: 6 | Step: 4300 | Avg. loss: 0.526 | lr: 0.00015061327561327563
Epoch: 6 | Step: 4350 | Avg. loss: 0.543 | lr: 0.00015016233766233767
Epoch: 6 | Step: 4400 | Avg. loss: 0.529 | lr: 0.0001497113997113997
Epoch: 6 | Step: 4450 | Avg. loss: 0.548 | lr: 0.00014926046176046175
Epoch: 6 | Step: 4500 | Avg. loss: 0.539 | lr: 0.00014880952380952382
Epoch: 6 | Step: 4550 | Avg. loss: 0.589 | lr: 0.00014835858585858587
Epoch: 6 | Step: 4600 | Avg. loss: 0.544 | lr: 0.0001479076479076479
Epoch: 6 | Step: 4650 | Avg. loss: 0.594 | lr: 0.00014745670995670995
Epoch: 6 | Step: 4700 | Avg. loss: 0.581 | lr: 0.000147005772005772
Epoch: 6 | Step: 4750 | Avg. loss: 0.551 | lr: 0.00014655483405483406
Epoch: 6 | Step: 4800 | Avg. loss: 0.561 | lr: 0.0001461038961038961
Epoch: 6 | Step: 4850 | Avg. loss: 0.562 | lr: 0.00014565295815295815
Epoch: 6 | Step: 4900 | Avg. loss: 0.495 | lr: 0.0001452020202020202
Epoch: 6 | Step: 4950 | Avg. loss: 0.523 | lr: 0.00014475108225108226
Epoch: 6 | Step: 5000 | Avg. loss: 0.512 | lr: 0.0001443001443001443
Saving model with test loss of 1.912
Epoch: 6 | Step: 5050 | Avg. loss: 0.502 | lr: 0.00014384920634920634
Epoch: 6 | Step: 5100 | Avg. loss: 0.547 | lr: 0.00014339826839826838
Epoch: 6 | Step: 5150 | Avg. loss: 0.511 | lr: 0.00014294733044733043
Epoch: 6 | Step: 5200 | Avg. loss: 0.524 | lr: 0.00014249639249639252
Epoch: 6 | Step: 5250 | Avg. loss: 0.521 | lr: 0.00014204545454545457
Epoch: 6 | Step: 5300 | Avg. loss: 0.510 | lr: 0.0001415945165945166
Epoch: 6 | Step: 5350 | Avg. loss: 0.517 | lr: 0.00014114357864357865
Epoch: 6 | Step: 5400 | Avg. loss: 0.526 | lr: 0.0001406926406926407
Epoch: 6 | Step: 5450 | Avg. loss: 0.524 | lr: 0.00014024170274170276
Epoch: 6 | Step: 5500 | Avg. loss: 0.516 | lr: 0.0001397907647907648
Epoch: 6 | Step: 5550 | Avg. loss: 0.534 | lr: 0.00013933982683982685
Epoch: 6 | Step: 5600 | Avg. loss: 0.512 | lr: 0.0001388888888888889
Epoch: 6 | Step: 5650 | Avg. loss: 0.512 | lr: 0.00013843795093795096
Epoch: 6 | Step: 5700 | Avg. loss: 0.511 | lr: 0.000137987012987013
Epoch: 6 | Step: 5750 | Avg. loss: 0.525 | lr: 0.00013753607503607504
Epoch: 6 | Step: 5800 | Avg. loss: 0.494 | lr: 0.00013708513708513709
Epoch: 6 | Step: 5850 | Avg. loss: 0.505 | lr: 0.00013663419913419913
Epoch: 6 | Step: 5900 | Avg. loss: 0.524 | lr: 0.0001361832611832612
Epoch: 6 | Step: 5950 | Avg. loss: 0.487 | lr: 0.00013573232323232324
Epoch: 6 | Step: 6000 | Avg. loss: 0.505 | lr: 0.00013528138528138528
Saving model with test loss of 1.955
Epoch: 6 | Step: 6050 | Avg. loss: 0.487 | lr: 0.00013483044733044732
Epoch: 6 | Step: 6100 | Avg. loss: 0.524 | lr: 0.00013437950937950937
Epoch: 6 | Step: 6150 | Avg. loss: 0.536 | lr: 0.00013392857142857144
Epoch: 6 | Step: 6200 | Avg. loss: 0.520 | lr: 0.00013347763347763348
Epoch: 6 | Step: 6250 | Avg. loss: 0.543 | lr: 0.00013302669552669552
Epoch: 6 | Step: 6300 | Avg. loss: 0.506 | lr: 0.00013257575757575756
Epoch: 6 | Step: 6350 | Avg. loss: 0.477 | lr: 0.00013212481962481963
Epoch: 6 | Step: 6400 | Avg. loss: 0.477 | lr: 0.00013167388167388167
Epoch: 6 | Step: 6450 | Avg. loss: 0.505 | lr: 0.00013122294372294372
Epoch: 6 | Step: 6500 | Avg. loss: 0.518 | lr: 0.00013077200577200576
Epoch: 6 | Step: 6550 | Avg. loss: 0.513 | lr: 0.0001303210678210678
Epoch: 6 | Step: 6600 | Avg. loss: 0.501 | lr: 0.00012987012987012987
Epoch: 6 | Step: 6650 | Avg. loss: 0.498 | lr: 0.0001294191919191919
Epoch: 6 | Step: 6700 | Avg. loss: 0.500 | lr: 0.00012896825396825398
Epoch: 6 | Step: 6750 | Avg. loss: 0.507 | lr: 0.00012851731601731602
Epoch: 6 | Step: 6800 | Avg. loss: 0.499 | lr: 0.0001280663780663781
Epoch: 6 | Step: 6850 | Avg. loss: 0.462 | lr: 0.00012761544011544014
Epoch: 6 | Step: 6900 | Avg. loss: 0.501 | lr: 0.00012716450216450218
Epoch: 6 | Step: 6950 | Avg. loss: 0.503 | lr: 0.00012671356421356422
Epoch: 6 | Step: 7000 | Avg. loss: 0.501 | lr: 0.00012626262626262626
Saving model with test loss of 1.991
  0%|          | 0/7000 [00:00<?, ?it/s]
Epoch: 7 | Step: 50 | Avg. loss: 0.483 | lr: 0.00012581168831168833
Epoch: 7 | Step: 100 | Avg. loss: 0.509 | lr: 0.00012536075036075037
Epoch: 7 | Step: 150 | Avg. loss: 0.469 | lr: 0.00012490981240981242
Epoch: 7 | Step: 200 | Avg. loss: 0.489 | lr: 0.00012445887445887446
Epoch: 7 | Step: 250 | Avg. loss: 0.478 | lr: 0.0001240079365079365
Epoch: 7 | Step: 300 | Avg. loss: 0.512 | lr: 0.00012355699855699857
Epoch: 7 | Step: 350 | Avg. loss: 0.466 | lr: 0.0001231060606060606
Epoch: 7 | Step: 400 | Avg. loss: 0.486 | lr: 0.00012265512265512266
Epoch: 7 | Step: 450 | Avg. loss: 0.487 | lr: 0.0001222041847041847
Epoch: 7 | Step: 500 | Avg. loss: 0.489 | lr: 0.00012175324675324675
Epoch: 7 | Step: 550 | Avg. loss: 0.459 | lr: 0.00012130230880230881
Epoch: 7 | Step: 600 | Avg. loss: 0.516 | lr: 0.00012085137085137085
Epoch: 7 | Step: 650 | Avg. loss: 0.477 | lr: 0.0001204004329004329
Epoch: 7 | Step: 700 | Avg. loss: 0.472 | lr: 0.00011994949494949495
Epoch: 7 | Step: 750 | Avg. loss: 0.479 | lr: 0.00011949855699855699
Epoch: 7 | Step: 800 | Avg. loss: 0.446 | lr: 0.00011904761904761905
Epoch: 7 | Step: 850 | Avg. loss: 0.451 | lr: 0.0001185966810966811
Epoch: 7 | Step: 900 | Avg. loss: 0.471 | lr: 0.00011814574314574316
Epoch: 7 | Step: 950 | Avg. loss: 0.469 | lr: 0.0001176948051948052
Epoch: 7 | Step: 1000 | Avg. loss: 0.462 | lr: 0.00011724386724386724
Saving model with test loss of 2.082
Epoch: 7 | Step: 1050 | Avg. loss: 0.432 | lr: 0.0001167929292929293
Epoch: 7 | Step: 1100 | Avg. loss: 0.435 | lr: 0.00011634199134199134
Epoch: 7 | Step: 1150 | Avg. loss: 0.462 | lr: 0.0001158910533910534
Epoch: 7 | Step: 1200 | Avg. loss: 0.458 | lr: 0.00011544011544011544
Epoch: 7 | Step: 1250 | Avg. loss: 0.459 | lr: 0.0001149891774891775
Epoch: 7 | Step: 1300 | Avg. loss: 0.435 | lr: 0.00011453823953823954
Epoch: 7 | Step: 1350 | Avg. loss: 0.447 | lr: 0.00011408730158730158
Epoch: 7 | Step: 1400 | Avg. loss: 0.465 | lr: 0.00011363636363636364
Epoch: 7 | Step: 1450 | Avg. loss: 0.436 | lr: 0.00011318542568542568
Epoch: 7 | Step: 1500 | Avg. loss: 0.440 | lr: 0.00011273448773448773
Epoch: 7 | Step: 1550 | Avg. loss: 0.462 | lr: 0.00011228354978354978
Epoch: 7 | Step: 1600 | Avg. loss: 0.436 | lr: 0.00011183261183261185
Epoch: 7 | Step: 1650 | Avg. loss: 0.455 | lr: 0.00011138167388167389
Epoch: 7 | Step: 1700 | Avg. loss: 0.463 | lr: 0.00011093073593073594
Epoch: 7 | Step: 1750 | Avg. loss: 0.440 | lr: 0.00011047979797979799
Epoch: 7 | Step: 1800 | Avg. loss: 0.426 | lr: 0.00011002886002886003
Epoch: 7 | Step: 1850 | Avg. loss: 0.431 | lr: 0.00010957792207792208
Epoch: 7 | Step: 1900 | Avg. loss: 0.429 | lr: 0.00010912698412698413
Epoch: 7 | Step: 1950 | Avg. loss: 0.444 | lr: 0.00010867604617604618
Epoch: 7 | Step: 2000 | Avg. loss: 0.424 | lr: 0.00010822510822510823
Saving model with test loss of 2.130
Epoch: 7 | Step: 2050 | Avg. loss: 0.436 | lr: 0.00010777417027417028
Epoch: 7 | Step: 2100 | Avg. loss: 0.426 | lr: 0.00010732323232323232
Epoch: 7 | Step: 2150 | Avg. loss: 0.410 | lr: 0.00010687229437229437
Epoch: 7 | Step: 2200 | Avg. loss: 0.450 | lr: 0.00010642135642135642
Epoch: 7 | Step: 2250 | Avg. loss: 0.454 | lr: 0.00010597041847041846
Epoch: 7 | Step: 2300 | Avg. loss: 0.431 | lr: 0.00010551948051948052
Epoch: 7 | Step: 2350 | Avg. loss: 0.424 | lr: 0.00010506854256854258
Epoch: 7 | Step: 2400 | Avg. loss: 0.410 | lr: 0.00010461760461760463
Epoch: 7 | Step: 2450 | Avg. loss: 0.403 | lr: 0.00010416666666666667
Epoch: 7 | Step: 2500 | Avg. loss: 0.424 | lr: 0.00010371572871572872
Epoch: 7 | Step: 2550 | Avg. loss: 0.406 | lr: 0.00010326479076479077
Epoch: 7 | Step: 2600 | Avg. loss: 0.428 | lr: 0.00010281385281385281
Epoch: 7 | Step: 2650 | Avg. loss: 0.450 | lr: 0.00010236291486291487
Epoch: 7 | Step: 2700 | Avg. loss: 0.394 | lr: 0.00010191197691197691
Epoch: 7 | Step: 2750 | Avg. loss: 0.397 | lr: 0.00010146103896103897
Epoch: 7 | Step: 2800 | Avg. loss: 0.384 | lr: 0.00010101010101010101
Epoch: 7 | Step: 2850 | Avg. loss: 0.443 | lr: 0.00010055916305916305
Epoch: 7 | Step: 2900 | Avg. loss: 0.399 | lr: 0.00010010822510822511
Epoch: 7 | Step: 2950 | Avg. loss: 0.457 | lr: 9.965728715728715e-05
Epoch: 7 | Step: 3000 | Avg. loss: 0.407 | lr: 9.92063492063492e-05
Saving model with test loss of 2.205
Epoch: 7 | Step: 3050 | Avg. loss: 0.432 | lr: 9.875541125541125e-05
Epoch: 7 | Step: 3100 | Avg. loss: 0.405 | lr: 9.830447330447332e-05
Epoch: 7 | Step: 3150 | Avg. loss: 0.428 | lr: 9.785353535353536e-05
Epoch: 7 | Step: 3200 | Avg. loss: 0.424 | lr: 9.740259740259742e-05
Epoch: 7 | Step: 3250 | Avg. loss: 0.408 | lr: 9.695165945165946e-05
Epoch: 7 | Step: 3300 | Avg. loss: 0.403 | lr: 9.65007215007215e-05
Epoch: 7 | Step: 3350 | Avg. loss: 0.407 | lr: 9.604978354978356e-05
Epoch: 7 | Step: 3400 | Avg. loss: 0.414 | lr: 9.55988455988456e-05
Epoch: 7 | Step: 3450 | Avg. loss: 0.397 | lr: 9.514790764790765e-05
Epoch: 7 | Step: 3500 | Avg. loss: 0.401 | lr: 9.46969696969697e-05
Epoch: 7 | Step: 3550 | Avg. loss: 0.388 | lr: 9.424603174603175e-05
Epoch: 7 | Step: 3600 | Avg. loss: 0.398 | lr: 9.37950937950938e-05
Epoch: 7 | Step: 3650 | Avg. loss: 0.404 | lr: 9.334415584415584e-05
Epoch: 7 | Step: 3700 | Avg. loss: 0.397 | lr: 9.289321789321789e-05
Epoch: 7 | Step: 3750 | Avg. loss: 0.381 | lr: 9.244227994227994e-05
Epoch: 7 | Step: 3800 | Avg. loss: 0.373 | lr: 9.199134199134199e-05
Epoch: 7 | Step: 3850 | Avg. loss: 0.397 | lr: 9.154040404040405e-05
Epoch: 7 | Step: 3900 | Avg. loss: 0.402 | lr: 9.10894660894661e-05
Epoch: 7 | Step: 3950 | Avg. loss: 0.426 | lr: 9.063852813852815e-05
Epoch: 7 | Step: 4000 | Avg. loss: 0.390 | lr: 9.018759018759019e-05
Saving model with test loss of 2.256
Epoch: 7 | Step: 4050 | Avg. loss: 0.400 | lr: 8.973665223665224e-05
Epoch: 7 | Step: 4100 | Avg. loss: 0.365 | lr: 8.928571428571429e-05
Epoch: 7 | Step: 4150 | Avg. loss: 0.419 | lr: 8.883477633477634e-05
Epoch: 7 | Step: 4200 | Avg. loss: 0.406 | lr: 8.838383838383838e-05
Epoch: 7 | Step: 4250 | Avg. loss: 0.394 | lr: 8.793290043290044e-05
Epoch: 7 | Step: 4300 | Avg. loss: 0.360 | lr: 8.748196248196248e-05
Epoch: 7 | Step: 4350 | Avg. loss: 0.379 | lr: 8.703102453102452e-05
Epoch: 7 | Step: 4400 | Avg. loss: 0.368 | lr: 8.658008658008658e-05
Epoch: 7 | Step: 4450 | Avg. loss: 0.385 | lr: 8.612914862914862e-05
Epoch: 7 | Step: 4500 | Avg. loss: 0.378 | lr: 8.567821067821068e-05
Epoch: 7 | Step: 4550 | Avg. loss: 0.425 | lr: 8.522727272727272e-05
Epoch: 7 | Step: 4600 | Avg. loss: 0.388 | lr: 8.477633477633479e-05
Epoch: 7 | Step: 4650 | Avg. loss: 0.421 | lr: 8.432539682539683e-05
Epoch: 7 | Step: 4700 | Avg. loss: 0.405 | lr: 8.387445887445887e-05
Epoch: 7 | Step: 4750 | Avg. loss: 0.398 | lr: 8.342352092352093e-05
Epoch: 7 | Step: 4800 | Avg. loss: 0.400 | lr: 8.297258297258297e-05
Epoch: 7 | Step: 4850 | Avg. loss: 0.403 | lr: 8.252164502164503e-05
Epoch: 7 | Step: 4900 | Avg. loss: 0.348 | lr: 8.207070707070707e-05
Epoch: 7 | Step: 4950 | Avg. loss: 0.373 | lr: 8.161976911976913e-05
Epoch: 7 | Step: 5000 | Avg. loss: 0.366 | lr: 8.116883116883117e-05
Saving model with test loss of 2.314
Epoch: 7 | Step: 5050 | Avg. loss: 0.352 | lr: 8.071789321789322e-05
Epoch: 7 | Step: 5100 | Avg. loss: 0.386 | lr: 8.026695526695527e-05
Epoch: 7 | Step: 5150 | Avg. loss: 0.354 | lr: 7.981601731601731e-05
Epoch: 7 | Step: 5200 | Avg. loss: 0.365 | lr: 7.936507936507937e-05
Epoch: 7 | Step: 5250 | Avg. loss: 0.359 | lr: 7.891414141414141e-05
Epoch: 7 | Step: 5300 | Avg. loss: 0.349 | lr: 7.846320346320346e-05
Epoch: 7 | Step: 5350 | Avg. loss: 0.361 | lr: 7.801226551226552e-05
Epoch: 7 | Step: 5400 | Avg. loss: 0.372 | lr: 7.756132756132757e-05
Epoch: 7 | Step: 5450 | Avg. loss: 0.365 | lr: 7.711038961038962e-05
Epoch: 7 | Step: 5500 | Avg. loss: 0.363 | lr: 7.665945165945166e-05
Epoch: 7 | Step: 5550 | Avg. loss: 0.376 | lr: 7.620851370851372e-05
Epoch: 7 | Step: 5600 | Avg. loss: 0.355 | lr: 7.575757575757576e-05
Epoch: 7 | Step: 5650 | Avg. loss: 0.360 | lr: 7.530663780663781e-05
Epoch: 7 | Step: 5700 | Avg. loss: 0.361 | lr: 7.485569985569986e-05
Epoch: 7 | Step: 5750 | Avg. loss: 0.362 | lr: 7.440476190476191e-05
Epoch: 7 | Step: 5800 | Avg. loss: 0.337 | lr: 7.395382395382395e-05
Epoch: 7 | Step: 5850 | Avg. loss: 0.345 | lr: 7.3502886002886e-05
Epoch: 7 | Step: 5900 | Avg. loss: 0.369 | lr: 7.305194805194805e-05
Epoch: 7 | Step: 5950 | Avg. loss: 0.336 | lr: 7.26010101010101e-05
Epoch: 7 | Step: 6000 | Avg. loss: 0.347 | lr: 7.215007215007215e-05
Saving model with test loss of 2.378
Epoch: 7 | Step: 6050 | Avg. loss: 0.338 | lr: 7.169913419913419e-05
Epoch: 7 | Step: 6100 | Avg. loss: 0.367 | lr: 7.124819624819626e-05
Epoch: 7 | Step: 6150 | Avg. loss: 0.381 | lr: 7.07972582972583e-05
Epoch: 7 | Step: 6200 | Avg. loss: 0.355 | lr: 7.034632034632035e-05
Epoch: 7 | Step: 6250 | Avg. loss: 0.383 | lr: 6.98953823953824e-05
Epoch: 7 | Step: 6300 | Avg. loss: 0.357 | lr: 6.944444444444444e-05
Epoch: 7 | Step: 6350 | Avg. loss: 0.328 | lr: 6.89935064935065e-05
Epoch: 7 | Step: 6400 | Avg. loss: 0.325 | lr: 6.854256854256854e-05
Epoch: 7 | Step: 6450 | Avg. loss: 0.354 | lr: 6.80916305916306e-05
Epoch: 7 | Step: 6500 | Avg. loss: 0.360 | lr: 6.764069264069264e-05
Epoch: 7 | Step: 6550 | Avg. loss: 0.359 | lr: 6.718975468975468e-05
Epoch: 7 | Step: 6600 | Avg. loss: 0.357 | lr: 6.673881673881674e-05
Epoch: 7 | Step: 6650 | Avg. loss: 0.340 | lr: 6.628787878787878e-05
Epoch: 7 | Step: 6700 | Avg. loss: 0.347 | lr: 6.583694083694084e-05
Epoch: 7 | Step: 6750 | Avg. loss: 0.354 | lr: 6.538600288600288e-05
Epoch: 7 | Step: 6800 | Avg. loss: 0.346 | lr: 6.493506493506494e-05
Epoch: 7 | Step: 6850 | Avg. loss: 0.315 | lr: 6.448412698412699e-05
Epoch: 7 | Step: 6900 | Avg. loss: 0.362 | lr: 6.403318903318905e-05
Epoch: 7 | Step: 6950 | Avg. loss: 0.353 | lr: 6.358225108225109e-05
Epoch: 7 | Step: 7000 | Avg. loss: 0.341 | lr: 6.313131313131313e-05
Saving model with test loss of 2.441
  0%|          | 0/7000 [00:00<?, ?it/s]
Epoch: 8 | Step: 50 | Avg. loss: 0.338 | lr: 6.268037518037519e-05
Epoch: 8 | Step: 100 | Avg. loss: 0.359 | lr: 6.222943722943723e-05
Epoch: 8 | Step: 150 | Avg. loss: 0.323 | lr: 6.177849927849929e-05
Epoch: 8 | Step: 200 | Avg. loss: 0.338 | lr: 6.132756132756133e-05
Epoch: 8 | Step: 250 | Avg. loss: 0.336 | lr: 6.0876623376623377e-05
Epoch: 8 | Step: 300 | Avg. loss: 0.349 | lr: 6.0425685425685426e-05
Epoch: 8 | Step: 350 | Avg. loss: 0.324 | lr: 5.9974747474747475e-05
Epoch: 8 | Step: 400 | Avg. loss: 0.338 | lr: 5.9523809523809524e-05
Epoch: 8 | Step: 450 | Avg. loss: 0.335 | lr: 5.907287157287158e-05
Epoch: 8 | Step: 500 | Avg. loss: 0.341 | lr: 5.862193362193362e-05
Epoch: 8 | Step: 550 | Avg. loss: 0.312 | lr: 5.817099567099567e-05
Epoch: 8 | Step: 600 | Avg. loss: 0.366 | lr: 5.772005772005772e-05
Epoch: 8 | Step: 650 | Avg. loss: 0.340 | lr: 5.726911976911977e-05
Epoch: 8 | Step: 700 | Avg. loss: 0.329 | lr: 5.681818181818182e-05
Epoch: 8 | Step: 750 | Avg. loss: 0.336 | lr: 5.636724386724387e-05
Epoch: 8 | Step: 800 | Avg. loss: 0.308 | lr: 5.591630591630592e-05
Epoch: 8 | Step: 850 | Avg. loss: 0.309 | lr: 5.546536796536797e-05
Epoch: 8 | Step: 900 | Avg. loss: 0.323 | lr: 5.5014430014430014e-05
Epoch: 8 | Step: 950 | Avg. loss: 0.332 | lr: 5.4563492063492063e-05
Epoch: 8 | Step: 1000 | Avg. loss: 0.320 | lr: 5.411255411255411e-05
Saving model with test loss of 2.501
Epoch: 8 | Step: 1050 | Avg. loss: 0.297 | lr: 5.366161616161616e-05
Epoch: 8 | Step: 1100 | Avg. loss: 0.303 | lr: 5.321067821067821e-05
Epoch: 8 | Step: 1150 | Avg. loss: 0.308 | lr: 5.275974025974026e-05
Epoch: 8 | Step: 1200 | Avg. loss: 0.315 | lr: 5.2308802308802316e-05
Epoch: 8 | Step: 1250 | Avg. loss: 0.317 | lr: 5.185786435786436e-05
Epoch: 8 | Step: 1300 | Avg. loss: 0.304 | lr: 5.140692640692641e-05
Epoch: 8 | Step: 1350 | Avg. loss: 0.309 | lr: 5.0955988455988456e-05
Epoch: 8 | Step: 1400 | Avg. loss: 0.323 | lr: 5.0505050505050505e-05
Epoch: 8 | Step: 1450 | Avg. loss: 0.304 | lr: 5.0054112554112554e-05
Epoch: 8 | Step: 1500 | Avg. loss: 0.299 | lr: 4.96031746031746e-05
Epoch: 8 | Step: 1550 | Avg. loss: 0.318 | lr: 4.915223665223666e-05
Epoch: 8 | Step: 1600 | Avg. loss: 0.305 | lr: 4.870129870129871e-05
Epoch: 8 | Step: 1650 | Avg. loss: 0.314 | lr: 4.825036075036075e-05
Epoch: 8 | Step: 1700 | Avg. loss: 0.319 | lr: 4.77994227994228e-05
Epoch: 8 | Step: 1750 | Avg. loss: 0.305 | lr: 4.734848484848485e-05
Epoch: 8 | Step: 1800 | Avg. loss: 0.295 | lr: 4.68975468975469e-05
Epoch: 8 | Step: 1850 | Avg. loss: 0.301 | lr: 4.6446608946608947e-05
Epoch: 8 | Step: 1900 | Avg. loss: 0.294 | lr: 4.5995670995670996e-05
Epoch: 8 | Step: 1950 | Avg. loss: 0.307 | lr: 4.554473304473305e-05
Epoch: 8 | Step: 2000 | Avg. loss: 0.295 | lr: 4.5093795093795094e-05
Saving model with test loss of 2.547
Epoch: 8 | Step: 2050 | Avg. loss: 0.303 | lr: 4.464285714285714e-05
Epoch: 8 | Step: 2100 | Avg. loss: 0.290 | lr: 4.419191919191919e-05
Epoch: 8 | Step: 2150 | Avg. loss: 0.287 | lr: 4.374098124098124e-05
Epoch: 8 | Step: 2200 | Avg. loss: 0.311 | lr: 4.329004329004329e-05
Epoch: 8 | Step: 2250 | Avg. loss: 0.315 | lr: 4.283910533910534e-05
Epoch: 8 | Step: 2300 | Avg. loss: 0.296 | lr: 4.2388167388167395e-05
Epoch: 8 | Step: 2350 | Avg. loss: 0.295 | lr: 4.193722943722944e-05
Epoch: 8 | Step: 2400 | Avg. loss: 0.283 | lr: 4.1486291486291486e-05
Epoch: 8 | Step: 2450 | Avg. loss: 0.272 | lr: 4.1035353535353535e-05
Epoch: 8 | Step: 2500 | Avg. loss: 0.288 | lr: 4.0584415584415584e-05
Epoch: 8 | Step: 2550 | Avg. loss: 0.281 | lr: 4.0133477633477633e-05
Epoch: 8 | Step: 2600 | Avg. loss: 0.300 | lr: 3.968253968253968e-05
Epoch: 8 | Step: 2650 | Avg. loss: 0.303 | lr: 3.923160173160173e-05
Epoch: 8 | Step: 2700 | Avg. loss: 0.272 | lr: 3.878066378066379e-05
Epoch: 8 | Step: 2750 | Avg. loss: 0.272 | lr: 3.832972582972583e-05
Epoch: 8 | Step: 2800 | Avg. loss: 0.261 | lr: 3.787878787878788e-05
Epoch: 8 | Step: 2850 | Avg. loss: 0.302 | lr: 3.742784992784993e-05
Epoch: 8 | Step: 2900 | Avg. loss: 0.274 | lr: 3.697691197691198e-05
Epoch: 8 | Step: 2950 | Avg. loss: 0.326 | lr: 3.6525974025974026e-05
Epoch: 8 | Step: 3000 | Avg. loss: 0.281 | lr: 3.6075036075036075e-05
Saving model with test loss of 2.638
Epoch: 8 | Step: 3050 | Avg. loss: 0.298 | lr: 3.562409812409813e-05
Epoch: 8 | Step: 3100 | Avg. loss: 0.279 | lr: 3.517316017316017e-05
Epoch: 8 | Step: 3150 | Avg. loss: 0.297 | lr: 3.472222222222222e-05
Epoch: 8 | Step: 3200 | Avg. loss: 0.295 | lr: 3.427128427128427e-05
Epoch: 8 | Step: 3250 | Avg. loss: 0.286 | lr: 3.382034632034632e-05
Epoch: 8 | Step: 3300 | Avg. loss: 0.275 | lr: 3.336940836940837e-05
Epoch: 8 | Step: 3350 | Avg. loss: 0.284 | lr: 3.291847041847042e-05
Epoch: 8 | Step: 3400 | Avg. loss: 0.284 | lr: 3.246753246753247e-05
Epoch: 8 | Step: 3450 | Avg. loss: 0.272 | lr: 3.201659451659452e-05
Epoch: 8 | Step: 3500 | Avg. loss: 0.274 | lr: 3.1565656565656566e-05
Epoch: 8 | Step: 3550 | Avg. loss: 0.265 | lr: 3.1114718614718615e-05
Epoch: 8 | Step: 3600 | Avg. loss: 0.267 | lr: 3.0663780663780664e-05
Epoch: 8 | Step: 3650 | Avg. loss: 0.284 | lr: 3.0212842712842713e-05
Epoch: 8 | Step: 3700 | Avg. loss: 0.274 | lr: 2.9761904761904762e-05
Epoch: 8 | Step: 3750 | Avg. loss: 0.266 | lr: 2.931096681096681e-05
Epoch: 8 | Step: 3800 | Avg. loss: 0.260 | lr: 2.886002886002886e-05
Epoch: 8 | Step: 3850 | Avg. loss: 0.278 | lr: 2.840909090909091e-05
Epoch: 8 | Step: 3900 | Avg. loss: 0.277 | lr: 2.795815295815296e-05
Epoch: 8 | Step: 3950 | Avg. loss: 0.298 | lr: 2.7507215007215007e-05
Epoch: 8 | Step: 4000 | Avg. loss: 0.271 | lr: 2.7056277056277056e-05
Saving model with test loss of 2.681
Epoch: 8 | Step: 4050 | Avg. loss: 0.284 | lr: 2.6605339105339105e-05
Epoch: 8 | Step: 4100 | Avg. loss: 0.253 | lr: 2.6154401154401158e-05
Epoch: 8 | Step: 4150 | Avg. loss: 0.294 | lr: 2.5703463203463203e-05
Epoch: 8 | Step: 4200 | Avg. loss: 0.285 | lr: 2.5252525252525253e-05
Epoch: 8 | Step: 4250 | Avg. loss: 0.274 | lr: 2.48015873015873e-05
Epoch: 8 | Step: 4300 | Avg. loss: 0.242 | lr: 2.4350649350649354e-05
Epoch: 8 | Step: 4350 | Avg. loss: 0.262 | lr: 2.38997113997114e-05
Epoch: 8 | Step: 4400 | Avg. loss: 0.248 | lr: 2.344877344877345e-05
Epoch: 8 | Step: 4450 | Avg. loss: 0.269 | lr: 2.2997835497835498e-05
Epoch: 8 | Step: 4500 | Avg. loss: 0.256 | lr: 2.2546897546897547e-05
Epoch: 8 | Step: 4550 | Avg. loss: 0.303 | lr: 2.2095959595959596e-05
Epoch: 8 | Step: 4600 | Avg. loss: 0.272 | lr: 2.1645021645021645e-05
Epoch: 8 | Step: 4650 | Avg. loss: 0.301 | lr: 2.1194083694083697e-05
Epoch: 8 | Step: 4700 | Avg. loss: 0.286 | lr: 2.0743145743145743e-05
Epoch: 8 | Step: 4750 | Avg. loss: 0.286 | lr: 2.0292207792207792e-05
Epoch: 8 | Step: 4800 | Avg. loss: 0.288 | lr: 1.984126984126984e-05
Epoch: 8 | Step: 4850 | Avg. loss: 0.289 | lr: 1.9390331890331894e-05
Epoch: 8 | Step: 4900 | Avg. loss: 0.241 | lr: 1.893939393939394e-05
Epoch: 8 | Step: 4950 | Avg. loss: 0.262 | lr: 1.848845598845599e-05
Epoch: 8 | Step: 5000 | Avg. loss: 0.254 | lr: 1.8037518037518038e-05
Saving model with test loss of 2.710
Epoch: 8 | Step: 5050 | Avg. loss: 0.247 | lr: 1.7586580086580087e-05
Epoch: 8 | Step: 5100 | Avg. loss: 0.271 | lr: 1.7135642135642136e-05
Epoch: 8 | Step: 5150 | Avg. loss: 0.251 | lr: 1.6684704184704185e-05
Epoch: 8 | Step: 5200 | Avg. loss: 0.258 | lr: 1.6233766233766234e-05
Epoch: 8 | Step: 5250 | Avg. loss: 0.257 | lr: 1.5782828282828283e-05
Epoch: 8 | Step: 5300 | Avg. loss: 0.244 | lr: 1.5331890331890332e-05
Epoch: 8 | Step: 5350 | Avg. loss: 0.256 | lr: 1.4880952380952381e-05
Epoch: 8 | Step: 5400 | Avg. loss: 0.266 | lr: 1.443001443001443e-05
Epoch: 8 | Step: 5450 | Avg. loss: 0.260 | lr: 1.397907647907648e-05
Epoch: 8 | Step: 5500 | Avg. loss: 0.257 | lr: 1.3528138528138528e-05
Epoch: 8 | Step: 5550 | Avg. loss: 0.268 | lr: 1.3077200577200579e-05
Epoch: 8 | Step: 5600 | Avg. loss: 0.253 | lr: 1.2626262626262626e-05
Epoch: 8 | Step: 5650 | Avg. loss: 0.261 | lr: 1.2175324675324677e-05
Epoch: 8 | Step: 5700 | Avg. loss: 0.258 | lr: 1.1724386724386724e-05
Epoch: 8 | Step: 5750 | Avg. loss: 0.258 | lr: 1.1273448773448773e-05
Epoch: 8 | Step: 5800 | Avg. loss: 0.243 | lr: 1.0822510822510823e-05
Epoch: 8 | Step: 5850 | Avg. loss: 0.246 | lr: 1.0371572871572872e-05
Epoch: 8 | Step: 5900 | Avg. loss: 0.264 | lr: 9.92063492063492e-06
Epoch: 8 | Step: 5950 | Avg. loss: 0.236 | lr: 9.46969696969697e-06
Epoch: 8 | Step: 6000 | Avg. loss: 0.248 | lr: 9.018759018759019e-06
Saving model with test loss of 2.758
Epoch: 8 | Step: 6050 | Avg. loss: 0.243 | lr: 8.567821067821068e-06
Epoch: 8 | Step: 6100 | Avg. loss: 0.268 | lr: 8.116883116883117e-06
Epoch: 8 | Step: 6150 | Avg. loss: 0.279 | lr: 7.665945165945166e-06
Epoch: 8 | Step: 6200 | Avg. loss: 0.260 | lr: 7.215007215007215e-06
Epoch: 8 | Step: 6250 | Avg. loss: 0.279 | lr: 6.764069264069264e-06
Epoch: 8 | Step: 6300 | Avg. loss: 0.267 | lr: 6.313131313131313e-06
Epoch: 8 | Step: 6350 | Avg. loss: 0.247 | lr: 5.862193362193362e-06
Epoch: 8 | Step: 6400 | Avg. loss: 0.236 | lr: 5.411255411255411e-06
Epoch: 8 | Step: 6450 | Avg. loss: 0.263 | lr: 4.96031746031746e-06
Epoch: 8 | Step: 6500 | Avg. loss: 0.271 | lr: 4.509379509379509e-06
Epoch: 8 | Step: 6550 | Avg. loss: 0.273 | lr: 4.0584415584415584e-06
Epoch: 8 | Step: 6600 | Avg. loss: 0.276 | lr: 3.6075036075036075e-06
Epoch: 8 | Step: 6650 | Avg. loss: 0.252 | lr: 3.1565656565656566e-06
Epoch: 8 | Step: 6700 | Avg. loss: 0.257 | lr: 2.7056277056277056e-06
Epoch: 8 | Step: 6750 | Avg. loss: 0.271 | lr: 2.2546897546897547e-06
Epoch: 8 | Step: 6800 | Avg. loss: 0.264 | lr: 1.8037518037518038e-06
Epoch: 8 | Step: 6850 | Avg. loss: 0.244 | lr: 1.3528138528138528e-06
Epoch: 8 | Step: 6900 | Avg. loss: 0.277 | lr: 9.018759018759019e-07
Epoch: 8 | Step: 6950 | Avg. loss: 0.274 | lr: 4.5093795093795094e-07
Epoch: 8 | Step: 7000 | Avg. loss: 0.267 | lr: 0.0
Saving model with test loss of 2.739
TIME_fine_tuning_3: 4580.72 seconds
/storage/ice1/1/2/spadmanabha3/satkp/BigData/LLM/conda/LLM_test/lib/python3.9/site-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(
Raw input text: Stop in the name of the law
Translated text:      
{'en': 'This release issued at 1315 hrs.', 'hi': '  1315    '}
32000
{'en': 'This release issued at 1315 hrs.', 'hi': '  1315    '}
100
Map:   0%|          | 0/100 [00:00<?, ? examples/s]Map: 100%|| 100/100 [00:00<00:00, 268.72 examples/s]Map: 100%|| 100/100 [00:00<00:00, 264.04 examples/s]
cuda
Map:   0%|          | 0/100 [00:00<?, ? examples/s]Processing batch 1
Map:  64%|   | 64/100 [00:01<00:00, 36.68 examples/s]Processing batch 2
Map: 100%|| 100/100 [00:02<00:00, 35.93 examples/s]Map: 100%|| 100/100 [00:02<00:00, 36.02 examples/s]
Original: This release issued at 1315 hrs.
Translated:   1315    
Reference:   1315    

Original: The passage of time during nights is reckoned by having a look at the position of the stars above.
Translated:            
Reference:               

Original: (In the field of Archaeology, Numismatics & Epigraphy, Pre History, Anthropology, Fine Arts, Conservation,  Publication, Administration, Finance & Accounts, Establishment, Civil, Legal matters, Stores & Purchase).
Translated: ,   ,  , , 
Reference: (   ,   ,  , ,  , , ,,   , , ,  ,   )

Original: People often lose interest in egalitarian measures when such measures do not directly benefit them.
Translated:             
Reference:                      

Original: He said, 'Hero banna chahta hoon'. 
Translated: , " ,     "
Reference:  ,    . '' 

calculating scores...
computing bert embedding.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|       | 1/4 [00:00<00:02,  1.30it/s]100%|| 4/4 [00:00<00:00,  4.64it/s]
computing greedy matching.
  0%|          | 0/2 [00:00<?, ?it/s] 50%|     | 1/2 [00:00<00:00,  1.69it/s]100%|| 2/2 [00:00<00:00,  3.35it/s]
done in 1.46 seconds, 68.52 sentences/sec
Original: This release issued at 1315 hrs.
Translated:   1315    
Reference:   1315    
BERTScore F1: 1.0000

Original: The passage of time during nights is reckoned by having a look at the position of the stars above.
Translated:            
Reference:               
BERTScore F1: 0.7335

Original: (In the field of Archaeology, Numismatics & Epigraphy, Pre History, Anthropology, Fine Arts, Conservation,  Publication, Administration, Finance & Accounts, Establishment, Civil, Legal matters, Stores & Purchase).
Translated: ,   ,  , , 
Reference: (   ,   ,  , ,  , , ,,   , , ,  ,   )
BERTScore F1: 0.7448

Original: People often lose interest in egalitarian measures when such measures do not directly benefit them.
Translated:             
Reference:                      
BERTScore F1: 0.8849

Original: He said, 'Hero banna chahta hoon'. 
Translated: , " ,     "
Reference:  ,    . '' 
BERTScore F1: 0.7537

Original: 33. For work permits to work in Northern Ireland, please write to: 33
Translated:             
Reference:               
BERTScore F1: 0.7875

Original: They emerged as cultivators, but were denied twice - born status.
Translated:        ,  -  
Reference:            
BERTScore F1: 0.7065

Original: % s authentication failed
Translated: % s   
Reference: % s  
BERTScore F1: 0.9450

Original: Section - 209, Income-tax Act, 1961-2018
Translated:  - 209, - , 1961-2018
Reference:  - 209, - , 1961-2018
BERTScore F1: 1.0000

Original: the duties of the rich to the poor and the poor to the rich.
Translated:            
Reference:     . 
BERTScore F1: 0.6279

Original: CIM Key (past in Mozilla) based on mozilla fire box browsing software.
Translated:         CIM  (
Reference:  (  )    -   
BERTScore F1: 0.6682

Original: Relating to agriculture land.
Translated:    
Reference:       
BERTScore F1: 0.8094

Original: Darn, the kiosk application could not be launched.
Translated: ,       
Reference:  ,       . 
BERTScore F1: 0.8275

Original: A plant of family Euphorbiaceae with brightly colored foliage.
Translated:         
Reference:        
BERTScore F1: 0.7763

Original: The railway contracts were made when the exchange was at Is 10d.
Translated:   ''      
Reference:             10  . 
BERTScore F1: 0.7095

Original: Charlie Simpson helped to raise
Translated:           
Reference:      
BERTScore F1: 0.7520

Original: Please accept my hearty congratulations and best wishes.
Translated:       
Reference:        
BERTScore F1: 0.9552

Original: This book- part autobiography, part a conservationists handbook and part travelogue- traces the course of wildlife from the princely and British era to the present.
Translated:  - ,         
Reference:     ,         , -              
BERTScore F1: 0.7029

Original: Do you call upon Ba 'l and leave the best of creators -
Translated:           
Reference:     ()                 
BERTScore F1: 0.7705

Original: A battery of thirty drag ovens was added a little later.
Translated:           
Reference:         
BERTScore F1: 0.6452

Original: UNDP Project: Strengthening Public Administration and Governance.
Translated:    :        
Reference:  :      
BERTScore F1: 0.8561

Original: The first tranche - of 50 million US Dollars of this grant - was handed over a few weeks ago.
Translated:    50          50 
Reference:    , 50              
BERTScore F1: 0.7998

Original: But when sight is confounded
Translated:     ,
Reference:       
BERTScore F1: 0.7787

Original: Special provision for full value of consideration for transfer of assets other than capital assets in certain cases.
Translated:            
Reference:                    
BERTScore F1: 0.8456

Original: Cases were not classified for jurisdiction according to either the seriousness of the offence or the value of the property involved.
Translated:           
Reference:                    . 
BERTScore F1: 0.7047

Original: Something which functions naturally.
Translated:         
Reference:         
BERTScore F1: 0.8986

Original: These Awards are a recognition of your years of sincere effort and hard work.
Translated:  ,          
Reference:            
BERTScore F1: 0.7413

Original: In such a case, the grant support from PODF is not available.
Translated:   , -       
Reference:          . 
BERTScore F1: 0.8592

Original: Default height of the Composer Window.
Translated:     .
Reference:     . 
BERTScore F1: 1.0000

Original: To provide adequate instructional staff, possessing such qualifications as may be prescribed, for imparting practical and theoretical training and facilities for trade test of apprentices; and
Translated:         theoretical  
Reference:     ,  ,                    ; 
BERTScore F1: 0.7038

Original: At these brisk sales there are woollen shawls and sheets, bamboo and other handicraft goods.
Translated:      , , , , 
Reference:    ,         -  . 
BERTScore F1: 0.7197

Original: a mental or emotional depression, characterized by low level of enthusiasm or eagerness for activity
Translated:    ,       
Reference:    ,              
BERTScore F1: 0.7527

Original: Failed to create child process'% s':% s'% s'
Translated: '% s'     % s
Reference:     % s
BERTScore F1: 0.9247

Original: Reconnecting to LDAP server...
Translated: LDAP      LDAP   
Reference: LDAP     ... 
BERTScore F1: 0.8329

Original: When good news of the birth of a female is given to any of them, his face grows dark and inwardly he chokes.
Translated:               
Reference:                       -  
BERTScore F1: 0.7884

Original: Bad authentication response from server.
Translated:     .
Reference:     . 
BERTScore F1: 1.0000

Original: as between him and them
Translated:          
Reference:       
BERTScore F1: 0.7645

Original: So leave them until they encounter the day when they will be thunderstruck,
Translated:            , 
Reference:   ,              ; 
BERTScore F1: 0.7328

Original: The machine produces much too fast, and brings with it a sort of economic system which I cannot grasp.
Translated:            
Reference:              -  ,      
BERTScore F1: 0.7410

Original: Or is the hidden with them, by which they pass judgements?
Translated:       ( )    (
Reference:     ()        ? 
BERTScore F1: 0.7357

Original: The fiery controversies between him and an equally firm - headed scholar and poet, Balawantrai Thakore, are well known to students of Gujarati literature.
Translated:             
Reference:                   ,          
BERTScore F1: 0.6998

Original: Assign color values for your filter wheel slots
Translated:             
Reference:          
BERTScore F1: 0.7934

Original: The NPS offers two approaches to invest subscribers money:
Translated:            
Reference:            -
BERTScore F1: 0.7688

Original: For one, the stranglehold of the Government, which today controls power, water, fertiliser, seeds, wages and trade of agriculture, must be loosened.
Translated: , , , , ,    
Reference: , , , , ,             . 
BERTScore F1: 0.7871

Original: And those whose scales are light are the people who put themselves to ruin  the recompense of the injustice they used to do to Our signs.
Translated:       ,   , 
Reference: (    )                    
BERTScore F1: 0.6935

Original: from 1926 to 1928, jawaharlal nehru served as the main representative of the all india national committee 1926
Translated:  1928           
Reference:  1928                
BERTScore F1: 0.8039

Original: After a quick bath, they get into their best clothes.
Translated:             
Reference:      
BERTScore F1: 0.7852

Original: They are universal men, who free ourminds from bigotry and superstition, dogma and ritual, and emphasise the central simplicities of religion.
Translated:    ,    ,   
Reference:    ,     , ,                 
BERTScore F1: 0.7259

Original: Revised draft Policy on Inspection, Verification, Monitoring and Overall Procedure Relating to Grant of Forest Clearances and Identification of Forests
Translated:  Clearances          
Reference:         , ,        
BERTScore F1: 0.7682

Original: Draft Recruitment Rules for comments from Stakeholders
Translated:           
Reference:        
BERTScore F1: 0.7616

Original: Give full measure and do not cheat;
Translated:          ;
Reference:  -      
BERTScore F1: 0.6648

Original: The term, Good Governance, appeared in the development lexicon about two decades back.
Translated: ' '          
Reference:            
BERTScore F1: 0.7716

Original: Mixed Albuminurai is related to the changes in the human kidney.
Translated:          
Reference:          . 
BERTScore F1: 0.8279

Original: Considering the utility and food value of various palm products, there is immense potential / scope for further growth and development.
Translated:           
Reference:            ,         /  
BERTScore F1: 0.7937

Original: Something went wrong while displaying this page. Please reload or visit a different page to continue.
Translated:         .  
Reference:    ,    .             . 
BERTScore F1: 0.7639

Original: The share warrants issued to the Ambanis in December 1992 were actually allotted to them in 1994.
Translated:  1992           1994
Reference:      '92      1994    . 
BERTScore F1: 0.7903

Original: Those recommended here are chosen with care and definite purpose.
Translated:           
Reference:                   
BERTScore F1: 0.6603

Original: The nation will immensely benefit from the applications of IRNSS which include terrestrial, aerial and marine navigation, disaster management, vehicle tracking and fleet management etc.
Translated:   ,    ,  ,
Reference:              , ,   , ,        
BERTScore F1: 0.7454

Original: File / URL to Remove:
Translated:    /
Reference:  URL  
BERTScore F1: 0.7575

Original: The State Government / UT is also required to submit periodic returns to the Department of School Education and Literacy, Government of India to provide information on:
Translated:  /          
Reference:           /           
BERTScore F1: 0.7529

Original: More than 50 years later, Costa Rica is still seeing the benefits of this enlightened position.
Translated: 50               
Reference: 50                  
BERTScore F1: 0.7644

Original: Saying: "Make you perfect coats of mail, balancing well the rings of chain armour, and work you (men) righteousness. Truly, I am AllSeer of what you do."
Translated: , "         
Reference:  "         "-              
BERTScore F1: 0.7111

Original: flip the slide back and forth and you have a pointer and you can type text on the
Translated:            
Reference:                  
BERTScore F1: 0.6876

Original: This orchid, known as Darwin 's orchid,
Translated:     Orchid       .
Reference:  ,      , 
BERTScore F1: 0.7002

Original: Commission, etc., on the sale of lottery tickets.
Translated:       
Reference:       
BERTScore F1: 0.7424

Original: No. 5 / 4 / 20ll - Ralbal (Service) Date 14 - 07 - 2011
Translated: . 5/4/2011-. . ()  14-05-07
Reference: . 5/4/2011-. . ()  14-07-2011
BERTScore F1: 0.9741

Original: Bin Laden 's International Islamic Front for Jehad against the US and Israel brings together nearly a dozen Islamic terrorist groups.
Translated:          
Reference:                     . 
BERTScore F1: 0.6927

Original: Google Talk Work Name 3
Translated:     3 
Reference:     3
BERTScore F1: 0.9338

Original: IFCI 's ECONOMIC CONTRIBUTION
Translated:      
Reference:     
BERTScore F1: 0.8949

Original: The Collections of Statistics Act, 1953
Translated:   , 1953
Reference:   , 1953
BERTScore F1: 1.0000

Original: Their unknown authors came from all over the country.
Translated:        
Reference:    -    
BERTScore F1: 0.7986

Original: It is especially useful when the child has fever and diarrhoea.
Translated:            
Reference:              
BERTScore F1: 0.7565

Original: The costs shall be deposited in the Court within four weeks.
Translated:            
Reference:          
BERTScore F1: 0.7248

Original: To make something different in economic matters or a process of change in economic matters.
Translated:           
Reference:              
BERTScore F1: 0.7869

Original: SHRI D. V. SADANANDA GOWDA AND SHRI NARENDRA SINGH TOMAR GETS ADDITIONAL CHARGE OF THE MINISTRY OF CHEMICALS &amp; FERTILIZERS AND THE MINISTRY OF PARLIAMENTARY AFFAIRS RESPECTIVELY
Translated:  . .        .
Reference:                       
BERTScore F1: 0.7355

Original: It provides for risk cover at a comparatively low cost and relief for disability arising due to accident or illness.
Translated:           
Reference:                      
BERTScore F1: 0.7880

Original: And that 's twenty - one.
Translated:       
Reference:    21 
BERTScore F1: 0.7285

Original: And the fundamental reason, I think, why we feel that aging is inevitable
Translated:             
Reference:              
BERTScore F1: 0.7470

Original: To devise suitable and effective check-point for this purpose.
Translated:           
Reference:             
BERTScore F1: 0.7958

Original: Automotive industry in India
Translated:    
Reference:    
BERTScore F1: 0.8937

Original: Send selected contacts to another person
Translated:       .
Reference:       . 
BERTScore F1: 1.0000

Original: Wooden Marker is developed.
Translated:      
Reference:     
BERTScore F1: 0.8846

Original: a tough, white, outer layer of the eye covering all the eyeball except cornea
Translated:  , ,         
Reference:              
BERTScore F1: 0.7488

Original: full of innovative people making films despite great technical odds?
Translated:           
Reference:               ? 
BERTScore F1: 0.7191

Original: They keep your environment green and healthy
Translated:          
Reference:     -     
BERTScore F1: 0.8818

Original: You can see the beautiful meadows and huts of the shepherds along this route.
Translated:              
Reference:    -            
BERTScore F1: 0.6827

Original: These two songs became very popular and also Ralesh Khana the actor of the film including film director got huge popularty.
Translated:             
Reference:                       
BERTScore F1: 0.7470

Original: To further strengthen community participation in the drinking water sector for sustainability, National Rural Drinking Water Quality Monitoring & Surveillance programme has been launched in February, 2006
Translated:              
Reference:                       , 2006     
BERTScore F1: 0.7324

Original: except for God 's sincere servants;
Translated:       ,     
Reference:       ,     
BERTScore F1: 1.0000

Original: EcomarkScheme of India (External website that opens in a new window)
Translated:  -      
Reference:     (        ) 
BERTScore F1: 0.6185

Original: Looking up account details...
Translated:       ...
Reference:      ... 
BERTScore F1: 0.9133

Original: Display a RSS or ATOM Feed on your video
Translated:          
Reference:     RSS     
BERTScore F1: 0.8033

Original: Who set up along with Allah anot her god; presently they shall know.
Translated:          (
Reference:       -  ,       ! 
BERTScore F1: 0.6711

Original: A collection related to drugs.
Translated:          
Reference:     
BERTScore F1: 0.8400

Original: Solar Winds 1. 0 Copyright (c) 2002 Terence M. Welsh http: / / www. reallyslick. com / Ported to KDE by Karl Robillard
Translated:   1.0  (c) 2002  M.  
Reference:   1.0   (c) 2002  .  http:// www. reallyslick. com/     
BERTScore F1: 0.7013

Original: He added another 1000 km of new rail lines are under construction.
Translated:           1000 
Reference:      1000       
BERTScore F1: 0.7734

Original: The rasayana therapy therefore cannot be capsulated into a sort of magic pill and taken without paying heed to the concomitant therapies.
Translated:             
Reference:        ,              
BERTScore F1: 0.7311

Original: Click here to change your name and / or color
Translated:    /       .
Reference:          
BERTScore F1: 0.8325

Original: Monthly installments increases more because of compound interst.
Translated:           
Reference:             
BERTScore F1: 0.7050

Original: Orogenital sex is being performed.
Translated:       
Reference:   -     
BERTScore F1: 0.7632

Average BERTScore F1: 0.7870
Average BLEU score: 0.2207
Original: This release issued at 1315 hrs.
Translated:   1315    
Reference:   1315    
BLEU score: 1.0000

Original: The passage of time during nights is reckoned by having a look at the position of the stars above.
Translated:            
Reference:               
BLEU score: 0.0422

Original: (In the field of Archaeology, Numismatics & Epigraphy, Pre History, Anthropology, Fine Arts, Conservation,  Publication, Administration, Finance & Accounts, Establishment, Civil, Legal matters, Stores & Purchase).
Translated: ,   ,  , , 
Reference: (   ,   ,  , ,  , , ,,   , , ,  ,   )
BLEU score: 0.0047

Original: People often lose interest in egalitarian measures when such measures do not directly benefit them.
Translated:             
Reference:                      
BLEU score: 0.5353

Original: He said, 'Hero banna chahta hoon'. 
Translated: , " ,     "
Reference:  ,    . '' 
BLEU score: 0.0538

Original: 33. For work permits to work in Northern Ireland, please write to: 33
Translated:             
Reference:               
BLEU score: 0.2617

Original: They emerged as cultivators, but were denied twice - born status.
Translated:        ,  -  
Reference:            
BLEU score: 0.0315

Original: % s authentication failed
Translated: % s   
Reference: % s  
BLEU score: 0.7598

Original: Section - 209, Income-tax Act, 1961-2018
Translated:  - 209, - , 1961-2018
Reference:  - 209, - , 1961-2018
BLEU score: 1.0000

Original: the duties of the rich to the poor and the poor to the rich.
Translated:            
Reference:     . 
BLEU score: 0.0112

Original: CIM Key (past in Mozilla) based on mozilla fire box browsing software.
Translated:         CIM  (
Reference:  (  )    -   
BLEU score: 0.0242

Original: Relating to agriculture land.
Translated:    
Reference:       
BLEU score: 0.4289

Original: Darn, the kiosk application could not be launched.
Translated: ,       
Reference:  ,       . 
BLEU score: 0.4228

Original: A plant of family Euphorbiaceae with brightly colored foliage.
Translated:         
Reference:        
BLEU score: 0.0517

Original: The railway contracts were made when the exchange was at Is 10d.
Translated:   ''      
Reference:             10  . 
BLEU score: 0.1356

Original: Charlie Simpson helped to raise
Translated:           
Reference:      
BLEU score: 0.0138

Original: Please accept my hearty congratulations and best wishes.
Translated:       
Reference:        
BLEU score: 0.8261

Original: This book- part autobiography, part a conservationists handbook and part travelogue- traces the course of wildlife from the princely and British era to the present.
Translated:  - ,         
Reference:     ,         , -              
BLEU score: 0.0273

Original: Do you call upon Ba 'l and leave the best of creators -
Translated:           
Reference:     ()                 
BLEU score: 0.0910

Original: A battery of thirty drag ovens was added a little later.
Translated:           
Reference:         
BLEU score: 0.0298

Original: UNDP Project: Strengthening Public Administration and Governance.
Translated:    :        
Reference:  :      
BLEU score: 0.3115

Original: The first tranche - of 50 million US Dollars of this grant - was handed over a few weeks ago.
Translated:    50          50 
Reference:    , 50              
BLEU score: 0.2698

Original: But when sight is confounded
Translated:     ,
Reference:       
BLEU score: 0.0937

Original: Special provision for full value of consideration for transfer of assets other than capital assets in certain cases.
Translated:            
Reference:                    
BLEU score: 0.3256

Original: Cases were not classified for jurisdiction according to either the seriousness of the offence or the value of the property involved.
Translated:           
Reference:                    . 
BLEU score: 0.0150

Original: Something which functions naturally.
Translated:         
Reference:         
BLEU score: 0.5307

Original: These Awards are a recognition of your years of sincere effort and hard work.
Translated:  ,          
Reference:            
BLEU score: 0.1669

Original: In such a case, the grant support from PODF is not available.
Translated:   , -       
Reference:          . 
BLEU score: 0.1441

Original: Default height of the Composer Window.
Translated:     .
Reference:     . 
BLEU score: 1.0000

Original: To provide adequate instructional staff, possessing such qualifications as may be prescribed, for imparting practical and theoretical training and facilities for trade test of apprentices; and
Translated:         theoretical  
Reference:     ,  ,                    ; 
BLEU score: 0.0262

Original: At these brisk sales there are woollen shawls and sheets, bamboo and other handicraft goods.
Translated:      , , , , 
Reference:    ,         -  . 
BLEU score: 0.0343

Original: a mental or emotional depression, characterized by low level of enthusiasm or eagerness for activity
Translated:    ,       
Reference:    ,              
BLEU score: 0.0235

Original: Failed to create child process'% s':% s'% s'
Translated: '% s'     % s
Reference:     % s
BLEU score: 0.6342

Original: Reconnecting to LDAP server...
Translated: LDAP      LDAP   
Reference: LDAP     ... 
BLEU score: 0.5450

Original: When good news of the birth of a female is given to any of them, his face grows dark and inwardly he chokes.
Translated:               
Reference:                       -  
BLEU score: 0.2070

Original: Bad authentication response from server.
Translated:     .
Reference:     . 
BLEU score: 1.0000

Original: as between him and them
Translated:          
Reference:       
BLEU score: 0.0829

Original: So leave them until they encounter the day when they will be thunderstruck,
Translated:            , 
Reference:   ,              ; 
BLEU score: 0.2199

Original: The machine produces much too fast, and brings with it a sort of economic system which I cannot grasp.
Translated:            
Reference:              -  ,      
BLEU score: 0.0773

Original: Or is the hidden with them, by which they pass judgements?
Translated:       ( )    (
Reference:     ()        ? 
BLEU score: 0.0408

Original: The fiery controversies between him and an equally firm - headed scholar and poet, Balawantrai Thakore, are well known to students of Gujarati literature.
Translated:             
Reference:                   ,          
BLEU score: 0.0522

Original: Assign color values for your filter wheel slots
Translated:             
Reference:          
BLEU score: 0.2180

Original: The NPS offers two approaches to invest subscribers money:
Translated:            
Reference:            -
BLEU score: 0.1082

Original: For one, the stranglehold of the Government, which today controls power, water, fertiliser, seeds, wages and trade of agriculture, must be loosened.
Translated: , , , , ,    
Reference: , , , , ,             . 
BLEU score: 0.1378

Original: And those whose scales are light are the people who put themselves to ruin  the recompense of the injustice they used to do to Our signs.
Translated:       ,   , 
Reference: (    )                    
BLEU score: 0.0422

Original: from 1926 to 1928, jawaharlal nehru served as the main representative of the all india national committee 1926
Translated:  1928           
Reference:  1928                
BLEU score: 0.4394

Original: After a quick bath, they get into their best clothes.
Translated:             
Reference:      
BLEU score: 0.0740

Original: They are universal men, who free ourminds from bigotry and superstition, dogma and ritual, and emphasise the central simplicities of religion.
Translated:    ,    ,   
Reference:    ,     , ,                 
BLEU score: 0.0212

Original: Revised draft Policy on Inspection, Verification, Monitoring and Overall Procedure Relating to Grant of Forest Clearances and Identification of Forests
Translated:  Clearances          
Reference:         , ,        
BLEU score: 0.0603

Original: Draft Recruitment Rules for comments from Stakeholders
Translated:           
Reference:        
BLEU score: 0.1217

Original: Give full measure and do not cheat;
Translated:          ;
Reference:  -      
BLEU score: 0.0352

Original: The term, Good Governance, appeared in the development lexicon about two decades back.
Translated: ' '          
Reference:            
BLEU score: 0.0330

Original: Mixed Albuminurai is related to the changes in the human kidney.
Translated:          
Reference:          . 
BLEU score: 0.3021

Original: Considering the utility and food value of various palm products, there is immense potential / scope for further growth and development.
Translated:           
Reference:            ,         /  
BLEU score: 0.1229

Original: Something went wrong while displaying this page. Please reload or visit a different page to continue.
Translated:         .  
Reference:    ,    .             . 
BLEU score: 0.1554

Original: The share warrants issued to the Ambanis in December 1992 were actually allotted to them in 1994.
Translated:  1992           1994
Reference:      '92      1994    . 
BLEU score: 0.1426

Original: Those recommended here are chosen with care and definite purpose.
Translated:           
Reference:                   
BLEU score: 0.0333

Original: The nation will immensely benefit from the applications of IRNSS which include terrestrial, aerial and marine navigation, disaster management, vehicle tracking and fleet management etc.
Translated:   ,    ,  ,
Reference:              , ,   , ,        
BLEU score: 0.0420

Original: File / URL to Remove:
Translated:    /
Reference:  URL  
BLEU score: 0.0662

Original: The State Government / UT is also required to submit periodic returns to the Department of School Education and Literacy, Government of India to provide information on:
Translated:  /          
Reference:           /           
BLEU score: 0.1500

Original: More than 50 years later, Costa Rica is still seeing the benefits of this enlightened position.
Translated: 50               
Reference: 50                  
BLEU score: 0.0609

Original: Saying: "Make you perfect coats of mail, balancing well the rings of chain armour, and work you (men) righteousness. Truly, I am AllSeer of what you do."
Translated: , "         
Reference:  "         "-              
BLEU score: 0.0609

Original: flip the slide back and forth and you have a pointer and you can type text on the
Translated:            
Reference:                  
BLEU score: 0.0343

Original: This orchid, known as Darwin 's orchid,
Translated:     Orchid       .
Reference:  ,      , 
BLEU score: 0.0165

Original: Commission, etc., on the sale of lottery tickets.
Translated:       
Reference:       
BLEU score: 0.0433

Original: No. 5 / 4 / 20ll - Ralbal (Service) Date 14 - 07 - 2011
Translated: . 5/4/2011-. . ()  14-05-07
Reference: . 5/4/2011-. . ()  14-07-2011
BLEU score: 0.9351

Original: Bin Laden 's International Islamic Front for Jehad against the US and Israel brings together nearly a dozen Islamic terrorist groups.
Translated:          
Reference:                     . 
BLEU score: 0.0602

Original: Google Talk Work Name 3
Translated:     3 
Reference:     3
BLEU score: 0.8633

Original: IFCI 's ECONOMIC CONTRIBUTION
Translated:      
Reference:     
BLEU score: 0.1706

Original: The Collections of Statistics Act, 1953
Translated:   , 1953
Reference:   , 1953
BLEU score: 1.0000

Original: Their unknown authors came from all over the country.
Translated:        
Reference:    -    
BLEU score: 0.0943

Original: It is especially useful when the child has fever and diarrhoea.
Translated:            
Reference:              
BLEU score: 0.0408

Original: The costs shall be deposited in the Court within four weeks.
Translated:            
Reference:          
BLEU score: 0.0408

Original: To make something different in economic matters or a process of change in economic matters.
Translated:           
Reference:              
BLEU score: 0.2028

Original: SHRI D. V. SADANANDA GOWDA AND SHRI NARENDRA SINGH TOMAR GETS ADDITIONAL CHARGE OF THE MINISTRY OF CHEMICALS &amp; FERTILIZERS AND THE MINISTRY OF PARLIAMENTARY AFFAIRS RESPECTIVELY
Translated:  . .        .
Reference:                       
BLEU score: 0.0200

Original: It provides for risk cover at a comparatively low cost and relief for disability arising due to accident or illness.
Translated:           
Reference:                      
BLEU score: 0.1358

Original: And that 's twenty - one.
Translated:       
Reference:    21 
BLEU score: 0.0574

Original: And the fundamental reason, I think, why we feel that aging is inevitable
Translated:             
Reference:              
BLEU score: 0.1790

Original: To devise suitable and effective check-point for this purpose.
Translated:           
Reference:             
BLEU score: 0.1259

Original: Automotive industry in India
Translated:    
Reference:    
BLEU score: 0.0894

Original: Send selected contacts to another person
Translated:       .
Reference:       . 
BLEU score: 1.0000

Original: Wooden Marker is developed.
Translated:      
Reference:     
BLEU score: 0.0776

Original: a tough, white, outer layer of the eye covering all the eyeball except cornea
Translated:  , ,         
Reference:              
BLEU score: 0.0858

Original: full of innovative people making films despite great technical odds?
Translated:           
Reference:               ? 
BLEU score: 0.0968

Original: They keep your environment green and healthy
Translated:          
Reference:     -     
BLEU score: 0.2138

Original: You can see the beautiful meadows and huts of the shepherds along this route.
Translated:              
Reference:    -            
BLEU score: 0.0299

Original: These two songs became very popular and also Ralesh Khana the actor of the film including film director got huge popularty.
Translated:             
Reference:                       
BLEU score: 0.0266

Original: To further strengthen community participation in the drinking water sector for sustainability, National Rural Drinking Water Quality Monitoring & Surveillance programme has been launched in February, 2006
Translated:              
Reference:                       , 2006     
BLEU score: 0.0327

Original: except for God 's sincere servants;
Translated:       ,     
Reference:       ,     
BLEU score: 1.0000

Original: EcomarkScheme of India (External website that opens in a new window)
Translated:  -      
Reference:     (        ) 
BLEU score: 0.0140

Original: Looking up account details...
Translated:       ...
Reference:      ... 
BLEU score: 0.0693

Original: Display a RSS or ATOM Feed on your video
Translated:          
Reference:     RSS     
BLEU score: 0.0996

Original: Who set up along with Allah anot her god; presently they shall know.
Translated:          (
Reference:       -  ,       ! 
BLEU score: 0.0377

Original: A collection related to drugs.
Translated:          
Reference:     
BLEU score: 0.2516

Original: Solar Winds 1. 0 Copyright (c) 2002 Terence M. Welsh http: / / www. reallyslick. com / Ported to KDE by Karl Robillard
Translated:   1.0  (c) 2002  M.  
Reference:   1.0   (c) 2002  .  http:// www. reallyslick. com/     
BLEU score: 0.0461

Original: He added another 1000 km of new rail lines are under construction.
Translated:           1000 
Reference:      1000       
BLEU score: 0.3250

Original: The rasayana therapy therefore cannot be capsulated into a sort of magic pill and taken without paying heed to the concomitant therapies.
Translated:             
Reference:        ,              
BLEU score: 0.1212

Original: Click here to change your name and / or color
Translated:    /       .
Reference:          
BLEU score: 0.3840

Original: Monthly installments increases more because of compound interst.
Translated:           
Reference:             
BLEU score: 0.0298

Original: Orogenital sex is being performed.
Translated:       
Reference:   -     
BLEU score: 0.0426

Average ROUGE-1 F1 score: 0.1195
Average ROUGE-2 F1 score: 0.0215
Average ROUGE-L F1 score: 0.1195
Original: This release issued at 1315 hrs.
Translated:   1315    
Reference:   1315    
ROUGE-1 F1 score: 1.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 1.0000

Original: The passage of time during nights is reckoned by having a look at the position of the stars above.
Translated:            
Reference:               
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: (In the field of Archaeology, Numismatics & Epigraphy, Pre History, Anthropology, Fine Arts, Conservation,  Publication, Administration, Finance & Accounts, Establishment, Civil, Legal matters, Stores & Purchase).
Translated: ,   ,  , , 
Reference: (   ,   ,  , ,  , , ,,   , , ,  ,   )
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: People often lose interest in egalitarian measures when such measures do not directly benefit them.
Translated:             
Reference:                      
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: He said, 'Hero banna chahta hoon'. 
Translated: , " ,     "
Reference:  ,    . '' 
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: 33. For work permits to work in Northern Ireland, please write to: 33
Translated:             
Reference:               
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: They emerged as cultivators, but were denied twice - born status.
Translated:        ,  -  
Reference:            
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: % s authentication failed
Translated: % s   
Reference: % s  
ROUGE-1 F1 score: 1.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 1.0000

Original: Section - 209, Income-tax Act, 1961-2018
Translated:  - 209, - , 1961-2018
Reference:  - 209, - , 1961-2018
ROUGE-1 F1 score: 1.0000
ROUGE-2 F1 score: 1.0000
ROUGE-L F1 score: 1.0000

Original: the duties of the rich to the poor and the poor to the rich.
Translated:            
Reference:     . 
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: CIM Key (past in Mozilla) based on mozilla fire box browsing software.
Translated:         CIM  (
Reference:  (  )    -   
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: Relating to agriculture land.
Translated:    
Reference:       
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: Darn, the kiosk application could not be launched.
Translated: ,       
Reference:  ,       . 
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: A plant of family Euphorbiaceae with brightly colored foliage.
Translated:         
Reference:        
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: The railway contracts were made when the exchange was at Is 10d.
Translated:   ''      
Reference:             10  . 
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: Charlie Simpson helped to raise
Translated:           
Reference:      
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: Please accept my hearty congratulations and best wishes.
Translated:       
Reference:        
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: This book- part autobiography, part a conservationists handbook and part travelogue- traces the course of wildlife from the princely and British era to the present.
Translated:  - ,         
Reference:     ,         , -              
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: Do you call upon Ba 'l and leave the best of creators -
Translated:           
Reference:     ()                 
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: A battery of thirty drag ovens was added a little later.
Translated:           
Reference:         
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: UNDP Project: Strengthening Public Administration and Governance.
Translated:    :        
Reference:  :      
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: The first tranche - of 50 million US Dollars of this grant - was handed over a few weeks ago.
Translated:    50          50 
Reference:    , 50              
ROUGE-1 F1 score: 0.6667
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.6667

Original: But when sight is confounded
Translated:     ,
Reference:       
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: Special provision for full value of consideration for transfer of assets other than capital assets in certain cases.
Translated:            
Reference:                    
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: Cases were not classified for jurisdiction according to either the seriousness of the offence or the value of the property involved.
Translated:           
Reference:                    . 
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: Something which functions naturally.
Translated:         
Reference:         
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: These Awards are a recognition of your years of sincere effort and hard work.
Translated:  ,          
Reference:            
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: In such a case, the grant support from PODF is not available.
Translated:   , -       
Reference:          . 
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: Default height of the Composer Window.
Translated:     .
Reference:     . 
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: To provide adequate instructional staff, possessing such qualifications as may be prescribed, for imparting practical and theoretical training and facilities for trade test of apprentices; and
Translated:         theoretical  
Reference:     ,  ,                    ; 
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: At these brisk sales there are woollen shawls and sheets, bamboo and other handicraft goods.
Translated:      , , , , 
Reference:    ,         -  . 
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: a mental or emotional depression, characterized by low level of enthusiasm or eagerness for activity
Translated:    ,       
Reference:    ,              
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: Failed to create child process'% s':% s'% s'
Translated: '% s'     % s
Reference:     % s
ROUGE-1 F1 score: 0.6667
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.6667

Original: Reconnecting to LDAP server...
Translated: LDAP      LDAP   
Reference: LDAP     ... 
ROUGE-1 F1 score: 0.6667
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.6667

Original: When good news of the birth of a female is given to any of them, his face grows dark and inwardly he chokes.
Translated:               
Reference:                       -  
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: Bad authentication response from server.
Translated:     .
Reference:     . 
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: as between him and them
Translated:          
Reference:       
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: So leave them until they encounter the day when they will be thunderstruck,
Translated:            , 
Reference:   ,              ; 
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: The machine produces much too fast, and brings with it a sort of economic system which I cannot grasp.
Translated:            
Reference:              -  ,      
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: Or is the hidden with them, by which they pass judgements?
Translated:       ( )    (
Reference:     ()        ? 
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: The fiery controversies between him and an equally firm - headed scholar and poet, Balawantrai Thakore, are well known to students of Gujarati literature.
Translated:             
Reference:                   ,          
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: Assign color values for your filter wheel slots
Translated:             
Reference:          
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: The NPS offers two approaches to invest subscribers money:
Translated:            
Reference:            -
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: For one, the stranglehold of the Government, which today controls power, water, fertiliser, seeds, wages and trade of agriculture, must be loosened.
Translated: , , , , ,    
Reference: , , , , ,             . 
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: And those whose scales are light are the people who put themselves to ruin  the recompense of the injustice they used to do to Our signs.
Translated:       ,   , 
Reference: (    )                    
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: from 1926 to 1928, jawaharlal nehru served as the main representative of the all india national committee 1926
Translated:  1928           
Reference:  1928                
ROUGE-1 F1 score: 1.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 1.0000

Original: After a quick bath, they get into their best clothes.
Translated:             
Reference:      
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: They are universal men, who free ourminds from bigotry and superstition, dogma and ritual, and emphasise the central simplicities of religion.
Translated:    ,    ,   
Reference:    ,     , ,                 
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: Revised draft Policy on Inspection, Verification, Monitoring and Overall Procedure Relating to Grant of Forest Clearances and Identification of Forests
Translated:  Clearances          
Reference:         , ,        
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: Draft Recruitment Rules for comments from Stakeholders
Translated:           
Reference:        
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: Give full measure and do not cheat;
Translated:          ;
Reference:  -      
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: The term, Good Governance, appeared in the development lexicon about two decades back.
Translated: ' '          
Reference:            
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: Mixed Albuminurai is related to the changes in the human kidney.
Translated:          
Reference:          . 
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: Considering the utility and food value of various palm products, there is immense potential / scope for further growth and development.
Translated:           
Reference:            ,         /  
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: Something went wrong while displaying this page. Please reload or visit a different page to continue.
Translated:         .  
Reference:    ,    .             . 
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: The share warrants issued to the Ambanis in December 1992 were actually allotted to them in 1994.
Translated:  1992           1994
Reference:      '92      1994    . 
ROUGE-1 F1 score: 0.5000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.5000

Original: Those recommended here are chosen with care and definite purpose.
Translated:           
Reference:                   
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: The nation will immensely benefit from the applications of IRNSS which include terrestrial, aerial and marine navigation, disaster management, vehicle tracking and fleet management etc.
Translated:   ,    ,  ,
Reference:              , ,   , ,        
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: File / URL to Remove:
Translated:    /
Reference:  URL  
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: The State Government / UT is also required to submit periodic returns to the Department of School Education and Literacy, Government of India to provide information on:
Translated:  /          
Reference:           /           
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: More than 50 years later, Costa Rica is still seeing the benefits of this enlightened position.
Translated: 50               
Reference: 50                  
ROUGE-1 F1 score: 1.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 1.0000

Original: Saying: "Make you perfect coats of mail, balancing well the rings of chain armour, and work you (men) righteousness. Truly, I am AllSeer of what you do."
Translated: , "         
Reference:  "         "-              
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: flip the slide back and forth and you have a pointer and you can type text on the
Translated:            
Reference:                  
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: This orchid, known as Darwin 's orchid,
Translated:     Orchid       .
Reference:  ,      , 
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: Commission, etc., on the sale of lottery tickets.
Translated:       
Reference:       
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: No. 5 / 4 / 20ll - Ralbal (Service) Date 14 - 07 - 2011
Translated: . 5/4/2011-. . ()  14-05-07
Reference: . 5/4/2011-. . ()  14-07-2011
ROUGE-1 F1 score: 0.8333
ROUGE-2 F1 score: 0.6000
ROUGE-L F1 score: 0.8333

Original: Bin Laden 's International Islamic Front for Jehad against the US and Israel brings together nearly a dozen Islamic terrorist groups.
Translated:          
Reference:                     . 
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: Google Talk Work Name 3
Translated:     3 
Reference:     3
ROUGE-1 F1 score: 1.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 1.0000

Original: IFCI 's ECONOMIC CONTRIBUTION
Translated:      
Reference:     
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: The Collections of Statistics Act, 1953
Translated:   , 1953
Reference:   , 1953
ROUGE-1 F1 score: 1.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 1.0000

Original: Their unknown authors came from all over the country.
Translated:        
Reference:    -    
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: It is especially useful when the child has fever and diarrhoea.
Translated:            
Reference:              
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: The costs shall be deposited in the Court within four weeks.
Translated:            
Reference:          
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: To make something different in economic matters or a process of change in economic matters.
Translated:           
Reference:              
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: SHRI D. V. SADANANDA GOWDA AND SHRI NARENDRA SINGH TOMAR GETS ADDITIONAL CHARGE OF THE MINISTRY OF CHEMICALS &amp; FERTILIZERS AND THE MINISTRY OF PARLIAMENTARY AFFAIRS RESPECTIVELY
Translated:  . .        .
Reference:                       
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: It provides for risk cover at a comparatively low cost and relief for disability arising due to accident or illness.
Translated:           
Reference:                      
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: And that 's twenty - one.
Translated:       
Reference:    21 
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: And the fundamental reason, I think, why we feel that aging is inevitable
Translated:             
Reference:              
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: To devise suitable and effective check-point for this purpose.
Translated:           
Reference:             
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: Automotive industry in India
Translated:    
Reference:    
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: Send selected contacts to another person
Translated:       .
Reference:       . 
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: Wooden Marker is developed.
Translated:      
Reference:     
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: a tough, white, outer layer of the eye covering all the eyeball except cornea
Translated:  , ,         
Reference:              
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: full of innovative people making films despite great technical odds?
Translated:           
Reference:               ? 
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: They keep your environment green and healthy
Translated:          
Reference:     -     
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: You can see the beautiful meadows and huts of the shepherds along this route.
Translated:              
Reference:    -            
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: These two songs became very popular and also Ralesh Khana the actor of the film including film director got huge popularty.
Translated:             
Reference:                       
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: To further strengthen community participation in the drinking water sector for sustainability, National Rural Drinking Water Quality Monitoring & Surveillance programme has been launched in February, 2006
Translated:              
Reference:                       , 2006     
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: except for God 's sincere servants;
Translated:       ,     
Reference:       ,     
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: EcomarkScheme of India (External website that opens in a new window)
Translated:  -      
Reference:     (        ) 
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: Looking up account details...
Translated:       ...
Reference:      ... 
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: Display a RSS or ATOM Feed on your video
Translated:          
Reference:     RSS     
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: Who set up along with Allah anot her god; presently they shall know.
Translated:          (
Reference:       -  ,       ! 
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: A collection related to drugs.
Translated:          
Reference:     
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: Solar Winds 1. 0 Copyright (c) 2002 Terence M. Welsh http: / / www. reallyslick. com / Ported to KDE by Karl Robillard
Translated:   1.0  (c) 2002  M.  
Reference:   1.0   (c) 2002  .  http:// www. reallyslick. com/     
ROUGE-1 F1 score: 0.6154
ROUGE-2 F1 score: 0.5455
ROUGE-L F1 score: 0.6154

Original: He added another 1000 km of new rail lines are under construction.
Translated:           1000 
Reference:      1000       
ROUGE-1 F1 score: 1.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 1.0000

Original: The rasayana therapy therefore cannot be capsulated into a sort of magic pill and taken without paying heed to the concomitant therapies.
Translated:             
Reference:        ,              
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: Click here to change your name and / or color
Translated:    /       .
Reference:          
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: Monthly installments increases more because of compound interst.
Translated:           
Reference:             
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original: Orogenital sex is being performed.
Translated:       
Reference:   -     
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Average METEOR score: 0.3883
Original: This release issued at 1315 hrs.
Translated:   1315    
Reference:   1315    
METEOR score: 0.9999

Original: The passage of time during nights is reckoned by having a look at the position of the stars above.
Translated:            
Reference:               
METEOR score: 0.2217

Original: (In the field of Archaeology, Numismatics & Epigraphy, Pre History, Anthropology, Fine Arts, Conservation,  Publication, Administration, Finance & Accounts, Establishment, Civil, Legal matters, Stores & Purchase).
Translated: ,   ,  , , 
Reference: (   ,   ,  , ,  , , ,,   , , ,  ,   )
METEOR score: 0.0857

Original: People often lose interest in egalitarian measures when such measures do not directly benefit them.
Translated:             
Reference:                      
METEOR score: 0.6350

Original: He said, 'Hero banna chahta hoon'. 
Translated: , " ,     "
Reference:  ,    . '' 
METEOR score: 0.2356

Original: 33. For work permits to work in Northern Ireland, please write to: 33
Translated:             
Reference:               
METEOR score: 0.4905

Original: They emerged as cultivators, but were denied twice - born status.
Translated:        ,  -  
Reference:            
METEOR score: 0.1746

Original: % s authentication failed
Translated: % s   
Reference: % s  
METEOR score: 0.8565

Original: Section - 209, Income-tax Act, 1961-2018
Translated:  - 209, - , 1961-2018
Reference:  - 209, - , 1961-2018
METEOR score: 0.9998

Original: the duties of the rich to the poor and the poor to the rich.
Translated:            
Reference:     . 
METEOR score: 0.0521

Original: CIM Key (past in Mozilla) based on mozilla fire box browsing software.
Translated:         CIM  (
Reference:  (  )    -   
METEOR score: 0.1107

Original: Relating to agriculture land.
Translated:    
Reference:       
METEOR score: 0.5964

Original: Darn, the kiosk application could not be launched.
Translated: ,       
Reference:  ,       . 
METEOR score: 0.5031

Original: A plant of family Euphorbiaceae with brightly colored foliage.
Translated:         
Reference:        
METEOR score: 0.4099

Original: The railway contracts were made when the exchange was at Is 10d.
Translated:   ''      
Reference:             10  . 
METEOR score: 0.2074

Original: Charlie Simpson helped to raise
Translated:           
Reference:      
METEOR score: 0.0763

Original: Please accept my hearty congratulations and best wishes.
Translated:       
Reference:        
METEOR score: 0.8768

Original: This book- part autobiography, part a conservationists handbook and part travelogue- traces the course of wildlife from the princely and British era to the present.
Translated:  - ,         
Reference:     ,         , -              
METEOR score: 0.1160

Original: Do you call upon Ba 'l and leave the best of creators -
Translated:           
Reference:     ()                 
METEOR score: 0.2221

Original: A battery of thirty drag ovens was added a little later.
Translated:           
Reference:         
METEOR score: 0.1190

Original: UNDP Project: Strengthening Public Administration and Governance.
Translated:    :        
Reference:  :      
METEOR score: 0.4574

Original: The first tranche - of 50 million US Dollars of this grant - was handed over a few weeks ago.
Translated:    50          50 
Reference:    , 50              
METEOR score: 0.4425

Original: But when sight is confounded
Translated:     ,
Reference:       
METEOR score: 0.3034

Original: Special provision for full value of consideration for transfer of assets other than capital assets in certain cases.
Translated:            
Reference:                    
METEOR score: 0.4671

Original: Cases were not classified for jurisdiction according to either the seriousness of the offence or the value of the property involved.
Translated:           
Reference:                    . 
METEOR score: 0.1037

Original: Something which functions naturally.
Translated:         
Reference:         
METEOR score: 0.7263

Original: These Awards are a recognition of your years of sincere effort and hard work.
Translated:  ,          
Reference:            
METEOR score: 0.4722

Original: In such a case, the grant support from PODF is not available.
Translated:   , -       
Reference:          . 
METEOR score: 0.4376

Original: Default height of the Composer Window.
Translated:     .
Reference:     . 
METEOR score: 0.9999

Original: To provide adequate instructional staff, possessing such qualifications as may be prescribed, for imparting practical and theoretical training and facilities for trade test of apprentices; and
Translated:         theoretical  
Reference:     ,  ,                    ; 
METEOR score: 0.1729

Original: At these brisk sales there are woollen shawls and sheets, bamboo and other handicraft goods.
Translated:      , , , , 
Reference:    ,         -  . 
METEOR score: 0.1385

Original: a mental or emotional depression, characterized by low level of enthusiasm or eagerness for activity
Translated:    ,       
Reference:    ,              
METEOR score: 0.1454

Original: Failed to create child process'% s':% s'% s'
Translated: '% s'     % s
Reference:     % s
METEOR score: 0.9521

Original: Reconnecting to LDAP server...
Translated: LDAP      LDAP   
Reference: LDAP     ... 
METEOR score: 0.8586

Original: When good news of the birth of a female is given to any of them, his face grows dark and inwardly he chokes.
Translated:               
Reference:                       -  
METEOR score: 0.3425

Original: Bad authentication response from server.
Translated:     .
Reference:     . 
METEOR score: 0.9996

Original: as between him and them
Translated:          
Reference:       
METEOR score: 0.3158

Original: So leave them until they encounter the day when they will be thunderstruck,
Translated:            , 
Reference:   ,              ; 
METEOR score: 0.3290

Original: The machine produces much too fast, and brings with it a sort of economic system which I cannot grasp.
Translated:            
Reference:              -  ,      
METEOR score: 0.2075

Original: Or is the hidden with them, by which they pass judgements?
Translated:       ( )    (
Reference:     ()        ? 
METEOR score: 0.2385

Original: The fiery controversies between him and an equally firm - headed scholar and poet, Balawantrai Thakore, are well known to students of Gujarati literature.
Translated:             
Reference:                   ,          
METEOR score: 0.1602

Original: Assign color values for your filter wheel slots
Translated:             
Reference:          
METEOR score: 0.3727

Original: The NPS offers two approaches to invest subscribers money:
Translated:            
Reference:            -
METEOR score: 0.4211

Original: For one, the stranglehold of the Government, which today controls power, water, fertiliser, seeds, wages and trade of agriculture, must be loosened.
Translated: , , , , ,    
Reference: , , , , ,             . 
METEOR score: 0.2917

Original: And those whose scales are light are the people who put themselves to ruin  the recompense of the injustice they used to do to Our signs.
Translated:       ,   , 
Reference: (    )                    
METEOR score: 0.1839

Original: from 1926 to 1928, jawaharlal nehru served as the main representative of the all india national committee 1926
Translated:  1928           
Reference:  1928                
METEOR score: 0.6140

Original: After a quick bath, they get into their best clothes.
Translated:             
Reference:      
METEOR score: 0.5132

Original: They are universal men, who free ourminds from bigotry and superstition, dogma and ritual, and emphasise the central simplicities of religion.
Translated:    ,    ,   
Reference:    ,     , ,                 
METEOR score: 0.1565

Original: Revised draft Policy on Inspection, Verification, Monitoring and Overall Procedure Relating to Grant of Forest Clearances and Identification of Forests
Translated:  Clearances          
Reference:         , ,        
METEOR score: 0.2016

Original: Draft Recruitment Rules for comments from Stakeholders
Translated:           
Reference:        
METEOR score: 0.2806

Original: Give full measure and do not cheat;
Translated:          ;
Reference:  -      
METEOR score: 0.1099

Original: The term, Good Governance, appeared in the development lexicon about two decades back.
Translated: ' '          
Reference:            
METEOR score: 0.1921

Original: Mixed Albuminurai is related to the changes in the human kidney.
Translated:          
Reference:          . 
METEOR score: 0.5594

Original: Considering the utility and food value of various palm products, there is immense potential / scope for further growth and development.
Translated:           
Reference:            ,         /  
METEOR score: 0.2840

Original: Something went wrong while displaying this page. Please reload or visit a different page to continue.
Translated:         .  
Reference:    ,    .             . 
METEOR score: 0.3497

Original: The share warrants issued to the Ambanis in December 1992 were actually allotted to them in 1994.
Translated:  1992           1994
Reference:      '92      1994    . 
METEOR score: 0.3681

Original: Those recommended here are chosen with care and definite purpose.
Translated:           
Reference:                   
METEOR score: 0.1363

Original: The nation will immensely benefit from the applications of IRNSS which include terrestrial, aerial and marine navigation, disaster management, vehicle tracking and fleet management etc.
Translated:   ,    ,  ,
Reference:              , ,   , ,        
METEOR score: 0.1807

Original: File / URL to Remove:
Translated:    /
Reference:  URL  
METEOR score: 0.4376

Original: The State Government / UT is also required to submit periodic returns to the Department of School Education and Literacy, Government of India to provide information on:
Translated:  /          
Reference:           /           
METEOR score: 0.3829

Original: More than 50 years later, Costa Rica is still seeing the benefits of this enlightened position.
Translated: 50               
Reference: 50                  
METEOR score: 0.2691

Original: Saying: "Make you perfect coats of mail, balancing well the rings of chain armour, and work you (men) righteousness. Truly, I am AllSeer of what you do."
Translated: , "         
Reference:  "         "-              
METEOR score: 0.1947

Original: flip the slide back and forth and you have a pointer and you can type text on the
Translated:            
Reference:                  
METEOR score: 0.1404

Original: This orchid, known as Darwin 's orchid,
Translated:     Orchid       .
Reference:  ,      , 
METEOR score: 0.0781

Original: Commission, etc., on the sale of lottery tickets.
Translated:       
Reference:       
METEOR score: 0.1973

Original: No. 5 / 4 / 20ll - Ralbal (Service) Date 14 - 07 - 2011
Translated: . 5/4/2011-. . ()  14-05-07
Reference: . 5/4/2011-. . ()  14-07-2011
METEOR score: 0.9411

Original: Bin Laden 's International Islamic Front for Jehad against the US and Israel brings together nearly a dozen Islamic terrorist groups.
Translated:          
Reference:                     . 
METEOR score: 0.1256

Original: Google Talk Work Name 3
Translated:     3 
Reference:     3
METEOR score: 0.9867

Original: IFCI 's ECONOMIC CONTRIBUTION
Translated:      
Reference:     
METEOR score: 0.6899

Original: The Collections of Statistics Act, 1953
Translated:   , 1953
Reference:   , 1953
METEOR score: 0.9995

Original: Their unknown authors came from all over the country.
Translated:        
Reference:    -    
METEOR score: 0.3735

Original: It is especially useful when the child has fever and diarrhoea.
Translated:            
Reference:              
METEOR score: 0.1998

Original: The costs shall be deposited in the Court within four weeks.
Translated:            
Reference:          
METEOR score: 0.3234

Original: To make something different in economic matters or a process of change in economic matters.
Translated:           
Reference:              
METEOR score: 0.2533

Original: SHRI D. V. SADANANDA GOWDA AND SHRI NARENDRA SINGH TOMAR GETS ADDITIONAL CHARGE OF THE MINISTRY OF CHEMICALS &amp; FERTILIZERS AND THE MINISTRY OF PARLIAMENTARY AFFAIRS RESPECTIVELY
Translated:  . .        .
Reference:                       
METEOR score: 0.1506

Original: It provides for risk cover at a comparatively low cost and relief for disability arising due to accident or illness.
Translated:           
Reference:                      
METEOR score: 0.3186

Original: And that 's twenty - one.
Translated:       
Reference:    21 
METEOR score: 0.2308

Original: And the fundamental reason, I think, why we feel that aging is inevitable
Translated:             
Reference:              
METEOR score: 0.3546

Original: To devise suitable and effective check-point for this purpose.
Translated:           
Reference:             
METEOR score: 0.2733

Original: Automotive industry in India
Translated:    
Reference:    
METEOR score: 0.5208

Original: Send selected contacts to another person
Translated:       .
Reference:       . 
METEOR score: 0.9999

Original: Wooden Marker is developed.
Translated:      
Reference:     
METEOR score: 0.4848

Original: a tough, white, outer layer of the eye covering all the eyeball except cornea
Translated:  , ,         
Reference:              
METEOR score: 0.3289

Original: full of innovative people making films despite great technical odds?
Translated:           
Reference:               ? 
METEOR score: 0.2716

Original: They keep your environment green and healthy
Translated:          
Reference:     -     
METEOR score: 0.4464

Original: You can see the beautiful meadows and huts of the shepherds along this route.
Translated:              
Reference:    -            
METEOR score: 0.1592

Original: These two songs became very popular and also Ralesh Khana the actor of the film including film director got huge popularty.
Translated:             
Reference:                       
METEOR score: 0.2586

Original: To further strengthen community participation in the drinking water sector for sustainability, National Rural Drinking Water Quality Monitoring & Surveillance programme has been launched in February, 2006
Translated:              
Reference:                       , 2006     
METEOR score: 0.1655

Original: except for God 's sincere servants;
Translated:       ,     
Reference:       ,     
METEOR score: 1.0000

Original: EcomarkScheme of India (External website that opens in a new window)
Translated:  -      
Reference:     (        ) 
METEOR score: 0.0749

Original: Looking up account details...
Translated:       ...
Reference:      ... 
METEOR score: 0.5437

Original: Display a RSS or ATOM Feed on your video
Translated:          
Reference:     RSS     
METEOR score: 0.3843

Original: Who set up along with Allah anot her god; presently they shall know.
Translated:          (
Reference:       -  ,       ! 
METEOR score: 0.0862

Original: A collection related to drugs.
Translated:          
Reference:     
METEOR score: 0.6491

Original: Solar Winds 1. 0 Copyright (c) 2002 Terence M. Welsh http: / / www. reallyslick. com / Ported to KDE by Karl Robillard
Translated:   1.0  (c) 2002  M.  
Reference:   1.0   (c) 2002  .  http:// www. reallyslick. com/     
METEOR score: 0.1874

Original: He added another 1000 km of new rail lines are under construction.
Translated:           1000 
Reference:      1000       
METEOR score: 0.6114

Original: The rasayana therapy therefore cannot be capsulated into a sort of magic pill and taken without paying heed to the concomitant therapies.
Translated:             
Reference:        ,              
METEOR score: 0.3050

Original: Click here to change your name and / or color
Translated:    /       .
Reference:          
METEOR score: 0.5896

Original: Monthly installments increases more because of compound interst.
Translated:           
Reference:             
METEOR score: 0.1422

Original: Orogenital sex is being performed.
Translated:       
Reference:   -     
METEOR score: 0.2214

TIME_translation_testing_finetuned_3: 22.05 seconds
Running the mt5_hindi_eng() function
DatasetDict({
    train: Dataset({
        features: ['translation'],
        num_rows: 1659083
    })
    validation: Dataset({
        features: ['translation'],
        num_rows: 520
    })
    test: Dataset({
        features: ['translation'],
        num_rows: 2507
    })
})
Dataset({
    features: ['translation'],
    num_rows: 839876
})
DatasetDict({
    train: Dataset({
        features: ['translation'],
        num_rows: 112000
    })
    validation: Dataset({
        features: ['translation'],
        num_rows: 16000
    })
    test: Dataset({
        features: ['translation'],
        num_rows: 32000
    })
})
New train set size: 112000
New validation set size: 16000
New test set size: 32000
TIME_data_preparation_4: 2.01 seconds
/storage/ice1/1/2/spadmanabha3/satkp/BigData/LLM/conda/LLM_test/lib/python3.9/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
  0%|          | 0/7000 [00:00<?, ?it/s]
Epoch: 1 | Step: 50 | Avg. loss: 33.875 | lr: 4.464285714285714e-05
Epoch: 1 | Step: 100 | Avg. loss: 19.656 | lr: 8.928571428571429e-05
Epoch: 1 | Step: 150 | Avg. loss: 12.529 | lr: 0.00013392857142857144
Epoch: 1 | Step: 200 | Avg. loss: 9.265 | lr: 0.00017857142857142857
Epoch: 1 | Step: 250 | Avg. loss: 7.201 | lr: 0.00022321428571428573
Epoch: 1 | Step: 300 | Avg. loss: 5.535 | lr: 0.00026785714285714287
Epoch: 1 | Step: 350 | Avg. loss: 4.278 | lr: 0.0003125
Epoch: 1 | Step: 400 | Avg. loss: 3.565 | lr: 0.00035714285714285714
Epoch: 1 | Step: 450 | Avg. loss: 3.289 | lr: 0.00040178571428571433
Epoch: 1 | Step: 500 | Avg. loss: 3.141 | lr: 0.00044642857142857147
Epoch: 1 | Step: 550 | Avg. loss: 2.994 | lr: 0.0004910714285714286
Epoch: 1 | Step: 600 | Avg. loss: 2.793 | lr: 0.0004996392496392497
Epoch: 1 | Step: 650 | Avg. loss: 2.743 | lr: 0.0004991883116883117
Epoch: 1 | Step: 700 | Avg. loss: 2.706 | lr: 0.0004987373737373738
Epoch: 1 | Step: 750 | Avg. loss: 2.625 | lr: 0.0004982864357864358
Epoch: 1 | Step: 800 | Avg. loss: 2.600 | lr: 0.0004978354978354978
Epoch: 1 | Step: 850 | Avg. loss: 2.578 | lr: 0.0004973845598845599
Epoch: 1 | Step: 900 | Avg. loss: 2.526 | lr: 0.000496933621933622
Epoch: 1 | Step: 950 | Avg. loss: 2.461 | lr: 0.000496482683982684
Epoch: 1 | Step: 1000 | Avg. loss: 2.374 | lr: 0.000496031746031746
Saving model with test loss of 2.365
Epoch: 1 | Step: 1050 | Avg. loss: 2.411 | lr: 0.0004955808080808081
Epoch: 1 | Step: 1100 | Avg. loss: 2.421 | lr: 0.0004951298701298701
Epoch: 1 | Step: 1150 | Avg. loss: 2.464 | lr: 0.0004946789321789322
Epoch: 1 | Step: 1200 | Avg. loss: 2.412 | lr: 0.0004942279942279943
Epoch: 1 | Step: 1250 | Avg. loss: 2.369 | lr: 0.0004937770562770563
Epoch: 1 | Step: 1300 | Avg. loss: 2.343 | lr: 0.0004933261183261183
Epoch: 1 | Step: 1350 | Avg. loss: 2.360 | lr: 0.0004928751803751803
Epoch: 1 | Step: 1400 | Avg. loss: 2.336 | lr: 0.0004924242424242425
Epoch: 1 | Step: 1450 | Avg. loss: 2.322 | lr: 0.0004919733044733045
Epoch: 1 | Step: 1500 | Avg. loss: 2.332 | lr: 0.0004915223665223666
Epoch: 1 | Step: 1550 | Avg. loss: 2.301 | lr: 0.0004910714285714286
Epoch: 1 | Step: 1600 | Avg. loss: 2.304 | lr: 0.0004906204906204906
Epoch: 1 | Step: 1650 | Avg. loss: 2.260 | lr: 0.0004901695526695526
Epoch: 1 | Step: 1700 | Avg. loss: 2.297 | lr: 0.0004897186147186148
Epoch: 1 | Step: 1750 | Avg. loss: 2.273 | lr: 0.0004892676767676768
Epoch: 1 | Step: 1800 | Avg. loss: 2.319 | lr: 0.0004888167388167388
Epoch: 1 | Step: 1850 | Avg. loss: 2.213 | lr: 0.0004883658008658009
Epoch: 1 | Step: 1900 | Avg. loss: 2.234 | lr: 0.00048791486291486293
Epoch: 1 | Step: 1950 | Avg. loss: 2.264 | lr: 0.000487463924963925
Epoch: 1 | Step: 2000 | Avg. loss: 2.172 | lr: 0.000487012987012987
Saving model with test loss of 2.122
Epoch: 1 | Step: 2050 | Avg. loss: 2.213 | lr: 0.0004865620490620491
Epoch: 1 | Step: 2100 | Avg. loss: 2.166 | lr: 0.0004861111111111111
Epoch: 1 | Step: 2150 | Avg. loss: 2.162 | lr: 0.00048566017316017317
Epoch: 1 | Step: 2200 | Avg. loss: 2.190 | lr: 0.00048520923520923524
Epoch: 1 | Step: 2250 | Avg. loss: 2.279 | lr: 0.0004847582972582973
Epoch: 1 | Step: 2300 | Avg. loss: 2.190 | lr: 0.0004843073593073593
Epoch: 1 | Step: 2350 | Avg. loss: 2.192 | lr: 0.0004838564213564214
Epoch: 1 | Step: 2400 | Avg. loss: 2.138 | lr: 0.0004834054834054834
Epoch: 1 | Step: 2450 | Avg. loss: 2.145 | lr: 0.0004829545454545455
Epoch: 1 | Step: 2500 | Avg. loss: 2.150 | lr: 0.0004825036075036075
Epoch: 1 | Step: 2550 | Avg. loss: 2.136 | lr: 0.00048205266955266956
Epoch: 1 | Step: 2600 | Avg. loss: 2.142 | lr: 0.0004816017316017316
Epoch: 1 | Step: 2650 | Avg. loss: 2.165 | lr: 0.0004811507936507937
Epoch: 1 | Step: 2700 | Avg. loss: 2.088 | lr: 0.0004806998556998557
Epoch: 1 | Step: 2750 | Avg. loss: 2.141 | lr: 0.0004802489177489178
Epoch: 1 | Step: 2800 | Avg. loss: 2.087 | lr: 0.0004797979797979798
Epoch: 1 | Step: 2850 | Avg. loss: 2.147 | lr: 0.00047934704184704187
Epoch: 1 | Step: 2900 | Avg. loss: 2.109 | lr: 0.0004788961038961039
Epoch: 1 | Step: 2950 | Avg. loss: 2.135 | lr: 0.00047844516594516595
Epoch: 1 | Step: 3000 | Avg. loss: 2.049 | lr: 0.00047799422799422797
Saving model with test loss of 1.993
Epoch: 1 | Step: 3050 | Avg. loss: 2.111 | lr: 0.00047754329004329004
Epoch: 1 | Step: 3100 | Avg. loss: 2.069 | lr: 0.00047709235209235205
Epoch: 1 | Step: 3150 | Avg. loss: 2.116 | lr: 0.0004766414141414142
Epoch: 1 | Step: 3200 | Avg. loss: 2.124 | lr: 0.0004761904761904762
Epoch: 1 | Step: 3250 | Avg. loss: 2.086 | lr: 0.00047573953823953826
Epoch: 1 | Step: 3300 | Avg. loss: 2.093 | lr: 0.00047528860028860033
Epoch: 1 | Step: 3350 | Avg. loss: 2.072 | lr: 0.00047483766233766234
Epoch: 1 | Step: 3400 | Avg. loss: 2.033 | lr: 0.0004743867243867244
Epoch: 1 | Step: 3450 | Avg. loss: 2.074 | lr: 0.00047393578643578643
Epoch: 1 | Step: 3500 | Avg. loss: 2.032 | lr: 0.0004734848484848485
Epoch: 1 | Step: 3550 | Avg. loss: 2.028 | lr: 0.0004730339105339105
Epoch: 1 | Step: 3600 | Avg. loss: 2.040 | lr: 0.00047258297258297264
Epoch: 1 | Step: 3650 | Avg. loss: 2.080 | lr: 0.00047213203463203465
Epoch: 1 | Step: 3700 | Avg. loss: 1.996 | lr: 0.0004716810966810967
Epoch: 1 | Step: 3750 | Avg. loss: 2.005 | lr: 0.00047123015873015874
Epoch: 1 | Step: 3800 | Avg. loss: 1.986 | lr: 0.0004707792207792208
Epoch: 1 | Step: 3850 | Avg. loss: 1.935 | lr: 0.0004703282828282828
Epoch: 1 | Step: 3900 | Avg. loss: 2.037 | lr: 0.0004698773448773449
Epoch: 1 | Step: 3950 | Avg. loss: 2.075 | lr: 0.0004694264069264069
Epoch: 1 | Step: 4000 | Avg. loss: 2.094 | lr: 0.000468975468975469
Saving model with test loss of 1.917
Epoch: 1 | Step: 4050 | Avg. loss: 1.997 | lr: 0.00046852453102453104
Epoch: 1 | Step: 4100 | Avg. loss: 1.977 | lr: 0.0004680735930735931
Epoch: 1 | Step: 4150 | Avg. loss: 1.996 | lr: 0.00046762265512265513
Epoch: 1 | Step: 4200 | Avg. loss: 1.969 | lr: 0.0004671717171717172
Epoch: 1 | Step: 4250 | Avg. loss: 2.003 | lr: 0.0004667207792207792
Epoch: 1 | Step: 4300 | Avg. loss: 1.980 | lr: 0.0004662698412698413
Epoch: 1 | Step: 4350 | Avg. loss: 1.947 | lr: 0.0004658189033189033
Epoch: 1 | Step: 4400 | Avg. loss: 1.944 | lr: 0.00046536796536796537
Epoch: 1 | Step: 4450 | Avg. loss: 2.022 | lr: 0.0004649170274170274
Epoch: 1 | Step: 4500 | Avg. loss: 1.992 | lr: 0.0004644660894660895
Epoch: 1 | Step: 4550 | Avg. loss: 2.028 | lr: 0.0004640151515151515
Epoch: 1 | Step: 4600 | Avg. loss: 2.042 | lr: 0.0004635642135642136
Epoch: 1 | Step: 4650 | Avg. loss: 1.989 | lr: 0.0004631132756132756
Epoch: 1 | Step: 4700 | Avg. loss: 2.087 | lr: 0.0004626623376623377
Epoch: 1 | Step: 4750 | Avg. loss: 2.088 | lr: 0.0004622113997113997
Epoch: 1 | Step: 4800 | Avg. loss: 1.998 | lr: 0.00046176046176046176
Epoch: 1 | Step: 4850 | Avg. loss: 1.998 | lr: 0.00046130952380952383
Epoch: 1 | Step: 4900 | Avg. loss: 1.929 | lr: 0.00046085858585858584
Epoch: 1 | Step: 4950 | Avg. loss: 1.926 | lr: 0.00046040764790764797
Epoch: 1 | Step: 5000 | Avg. loss: 1.912 | lr: 0.00045995670995671
Saving model with test loss of 1.845
Epoch: 1 | Step: 5050 | Avg. loss: 1.876 | lr: 0.00045950577200577205
Epoch: 1 | Step: 5100 | Avg. loss: 1.979 | lr: 0.00045905483405483407
Epoch: 1 | Step: 5150 | Avg. loss: 1.932 | lr: 0.00045860389610389614
Epoch: 1 | Step: 5200 | Avg. loss: 1.995 | lr: 0.00045815295815295815
Epoch: 1 | Step: 5250 | Avg. loss: 1.951 | lr: 0.0004577020202020202
Epoch: 1 | Step: 5300 | Avg. loss: 1.957 | lr: 0.00045725108225108224
Epoch: 1 | Step: 5350 | Avg. loss: 1.890 | lr: 0.0004568001443001443
Epoch: 1 | Step: 5400 | Avg. loss: 1.994 | lr: 0.0004563492063492063
Epoch: 1 | Step: 5450 | Avg. loss: 1.928 | lr: 0.00045589826839826845
Epoch: 1 | Step: 5500 | Avg. loss: 1.948 | lr: 0.00045544733044733046
Epoch: 1 | Step: 5550 | Avg. loss: 1.965 | lr: 0.00045499639249639253
Epoch: 1 | Step: 5600 | Avg. loss: 1.868 | lr: 0.00045454545454545455
Epoch: 1 | Step: 5650 | Avg. loss: 1.908 | lr: 0.0004540945165945166
Epoch: 1 | Step: 5700 | Avg. loss: 1.877 | lr: 0.00045364357864357863
Epoch: 1 | Step: 5750 | Avg. loss: 1.926 | lr: 0.0004531926406926407
Epoch: 1 | Step: 5800 | Avg. loss: 1.940 | lr: 0.0004527417027417027
Epoch: 1 | Step: 5850 | Avg. loss: 1.920 | lr: 0.0004522907647907648
Epoch: 1 | Step: 5900 | Avg. loss: 1.889 | lr: 0.00045183982683982685
Epoch: 1 | Step: 5950 | Avg. loss: 1.847 | lr: 0.0004513888888888889
Epoch: 1 | Step: 6000 | Avg. loss: 1.861 | lr: 0.00045093795093795094
Saving model with test loss of 1.805
Epoch: 1 | Step: 6050 | Avg. loss: 1.910 | lr: 0.000450487012987013
Epoch: 1 | Step: 6100 | Avg. loss: 1.904 | lr: 0.000450036075036075
Epoch: 1 | Step: 6150 | Avg. loss: 1.910 | lr: 0.0004495851370851371
Epoch: 1 | Step: 6200 | Avg. loss: 1.908 | lr: 0.0004491341991341991
Epoch: 1 | Step: 6250 | Avg. loss: 1.957 | lr: 0.0004486832611832612
Epoch: 1 | Step: 6300 | Avg. loss: 1.886 | lr: 0.00044823232323232325
Epoch: 1 | Step: 6350 | Avg. loss: 1.923 | lr: 0.0004477813852813853
Epoch: 1 | Step: 6400 | Avg. loss: 1.893 | lr: 0.0004473304473304474
Epoch: 1 | Step: 6450 | Avg. loss: 1.893 | lr: 0.0004468795093795094
Epoch: 1 | Step: 6500 | Avg. loss: 1.924 | lr: 0.00044642857142857147
Epoch: 1 | Step: 6550 | Avg. loss: 1.904 | lr: 0.0004459776334776335
Epoch: 1 | Step: 6600 | Avg. loss: 1.839 | lr: 0.00044552669552669555
Epoch: 1 | Step: 6650 | Avg. loss: 1.893 | lr: 0.00044507575757575757
Epoch: 1 | Step: 6700 | Avg. loss: 1.882 | lr: 0.00044462481962481964
Epoch: 1 | Step: 6750 | Avg. loss: 1.872 | lr: 0.00044417388167388165
Epoch: 1 | Step: 6800 | Avg. loss: 1.868 | lr: 0.0004437229437229438
Epoch: 1 | Step: 6850 | Avg. loss: 1.831 | lr: 0.0004432720057720058
Epoch: 1 | Step: 6900 | Avg. loss: 1.837 | lr: 0.00044282106782106786
Epoch: 1 | Step: 6950 | Avg. loss: 1.924 | lr: 0.0004423701298701299
Epoch: 1 | Step: 7000 | Avg. loss: 1.899 | lr: 0.00044191919191919195
Saving model with test loss of 1.785
  0%|          | 0/7000 [00:00<?, ?it/s]
Epoch: 2 | Step: 50 | Avg. loss: 1.884 | lr: 0.00044146825396825396
Epoch: 2 | Step: 100 | Avg. loss: 1.888 | lr: 0.00044101731601731603
Epoch: 2 | Step: 150 | Avg. loss: 1.871 | lr: 0.00044056637806637805
Epoch: 2 | Step: 200 | Avg. loss: 1.870 | lr: 0.0004401154401154401
Epoch: 2 | Step: 250 | Avg. loss: 1.818 | lr: 0.00043966450216450213
Epoch: 2 | Step: 300 | Avg. loss: 1.879 | lr: 0.00043921356421356425
Epoch: 2 | Step: 350 | Avg. loss: 1.813 | lr: 0.00043876262626262627
Epoch: 2 | Step: 400 | Avg. loss: 1.794 | lr: 0.00043831168831168834
Epoch: 2 | Step: 450 | Avg. loss: 1.816 | lr: 0.00043786075036075035
Epoch: 2 | Step: 500 | Avg. loss: 1.860 | lr: 0.0004374098124098124
Epoch: 2 | Step: 550 | Avg. loss: 1.835 | lr: 0.00043695887445887444
Epoch: 2 | Step: 600 | Avg. loss: 1.769 | lr: 0.0004365079365079365
Epoch: 2 | Step: 650 | Avg. loss: 1.788 | lr: 0.0004360569985569985
Epoch: 2 | Step: 700 | Avg. loss: 1.823 | lr: 0.0004356060606060606
Epoch: 2 | Step: 750 | Avg. loss: 1.795 | lr: 0.00043515512265512266
Epoch: 2 | Step: 800 | Avg. loss: 1.814 | lr: 0.00043470418470418473
Epoch: 2 | Step: 850 | Avg. loss: 1.813 | lr: 0.0004342532467532468
Epoch: 2 | Step: 900 | Avg. loss: 1.805 | lr: 0.0004338023088023088
Epoch: 2 | Step: 950 | Avg. loss: 1.773 | lr: 0.0004333513708513709
Epoch: 2 | Step: 1000 | Avg. loss: 1.715 | lr: 0.0004329004329004329
Saving model with test loss of 1.780
Epoch: 2 | Step: 1050 | Avg. loss: 1.740 | lr: 0.00043244949494949497
Epoch: 2 | Step: 1100 | Avg. loss: 1.768 | lr: 0.000431998556998557
Epoch: 2 | Step: 1150 | Avg. loss: 1.827 | lr: 0.00043154761904761905
Epoch: 2 | Step: 1200 | Avg. loss: 1.804 | lr: 0.0004310966810966811
Epoch: 2 | Step: 1250 | Avg. loss: 1.759 | lr: 0.0004306457431457432
Epoch: 2 | Step: 1300 | Avg. loss: 1.738 | lr: 0.0004301948051948052
Epoch: 2 | Step: 1350 | Avg. loss: 1.764 | lr: 0.0004297438672438673
Epoch: 2 | Step: 1400 | Avg. loss: 1.772 | lr: 0.0004292929292929293
Epoch: 2 | Step: 1450 | Avg. loss: 1.743 | lr: 0.00042884199134199136
Epoch: 2 | Step: 1500 | Avg. loss: 1.769 | lr: 0.0004283910533910534
Epoch: 2 | Step: 1550 | Avg. loss: 1.761 | lr: 0.00042794011544011545
Epoch: 2 | Step: 1600 | Avg. loss: 1.766 | lr: 0.00042748917748917746
Epoch: 2 | Step: 1650 | Avg. loss: 1.733 | lr: 0.0004270382395382396
Epoch: 2 | Step: 1700 | Avg. loss: 1.795 | lr: 0.0004265873015873016
Epoch: 2 | Step: 1750 | Avg. loss: 1.752 | lr: 0.00042613636363636367
Epoch: 2 | Step: 1800 | Avg. loss: 1.805 | lr: 0.0004256854256854257
Epoch: 2 | Step: 1850 | Avg. loss: 1.705 | lr: 0.00042523448773448775
Epoch: 2 | Step: 1900 | Avg. loss: 1.738 | lr: 0.00042478354978354977
Epoch: 2 | Step: 1950 | Avg. loss: 1.771 | lr: 0.00042433261183261184
Epoch: 2 | Step: 2000 | Avg. loss: 1.703 | lr: 0.00042388167388167385
Saving model with test loss of 1.744
Epoch: 2 | Step: 2050 | Avg. loss: 1.753 | lr: 0.0004234307359307359
Epoch: 2 | Step: 2100 | Avg. loss: 1.692 | lr: 0.00042297979797979794
Epoch: 2 | Step: 2150 | Avg. loss: 1.690 | lr: 0.00042252886002886006
Epoch: 2 | Step: 2200 | Avg. loss: 1.739 | lr: 0.0004220779220779221
Epoch: 2 | Step: 2250 | Avg. loss: 1.819 | lr: 0.00042162698412698415
Epoch: 2 | Step: 2300 | Avg. loss: 1.753 | lr: 0.0004211760461760462
Epoch: 2 | Step: 2350 | Avg. loss: 1.747 | lr: 0.00042072510822510823
Epoch: 2 | Step: 2400 | Avg. loss: 1.691 | lr: 0.0004202741702741703
Epoch: 2 | Step: 2450 | Avg. loss: 1.713 | lr: 0.0004198232323232323
Epoch: 2 | Step: 2500 | Avg. loss: 1.724 | lr: 0.0004193722943722944
Epoch: 2 | Step: 2550 | Avg. loss: 1.712 | lr: 0.0004189213564213564
Epoch: 2 | Step: 2600 | Avg. loss: 1.712 | lr: 0.0004184704184704185
Epoch: 2 | Step: 2650 | Avg. loss: 1.748 | lr: 0.00041801948051948054
Epoch: 2 | Step: 2700 | Avg. loss: 1.691 | lr: 0.0004175685425685426
Epoch: 2 | Step: 2750 | Avg. loss: 1.738 | lr: 0.0004171176046176046
Epoch: 2 | Step: 2800 | Avg. loss: 1.671 | lr: 0.0004166666666666667
Epoch: 2 | Step: 2850 | Avg. loss: 1.758 | lr: 0.0004162157287157287
Epoch: 2 | Step: 2900 | Avg. loss: 1.696 | lr: 0.0004157647907647908
Epoch: 2 | Step: 2950 | Avg. loss: 1.754 | lr: 0.0004153138528138528
Epoch: 2 | Step: 3000 | Avg. loss: 1.657 | lr: 0.00041486291486291486
Saving model with test loss of 1.724
Epoch: 2 | Step: 3050 | Avg. loss: 1.715 | lr: 0.00041441197691197693
Epoch: 2 | Step: 3100 | Avg. loss: 1.705 | lr: 0.000413961038961039
Epoch: 2 | Step: 3150 | Avg. loss: 1.749 | lr: 0.000413510101010101
Epoch: 2 | Step: 3200 | Avg. loss: 1.741 | lr: 0.0004130591630591631
Epoch: 2 | Step: 3250 | Avg. loss: 1.708 | lr: 0.0004126082251082251
Epoch: 2 | Step: 3300 | Avg. loss: 1.721 | lr: 0.00041215728715728717
Epoch: 2 | Step: 3350 | Avg. loss: 1.686 | lr: 0.0004117063492063492
Epoch: 2 | Step: 3400 | Avg. loss: 1.681 | lr: 0.00041125541125541126
Epoch: 2 | Step: 3450 | Avg. loss: 1.711 | lr: 0.00041080447330447327
Epoch: 2 | Step: 3500 | Avg. loss: 1.678 | lr: 0.0004103535353535354
Epoch: 2 | Step: 3550 | Avg. loss: 1.662 | lr: 0.0004099025974025974
Epoch: 2 | Step: 3600 | Avg. loss: 1.696 | lr: 0.0004094516594516595
Epoch: 2 | Step: 3650 | Avg. loss: 1.698 | lr: 0.0004090007215007215
Epoch: 2 | Step: 3700 | Avg. loss: 1.635 | lr: 0.00040854978354978356
Epoch: 2 | Step: 3750 | Avg. loss: 1.654 | lr: 0.0004080988455988456
Epoch: 2 | Step: 3800 | Avg. loss: 1.631 | lr: 0.00040764790764790765
Epoch: 2 | Step: 3850 | Avg. loss: 1.607 | lr: 0.0004071969696969697
Epoch: 2 | Step: 3900 | Avg. loss: 1.696 | lr: 0.00040674603174603173
Epoch: 2 | Step: 3950 | Avg. loss: 1.734 | lr: 0.00040629509379509386
Epoch: 2 | Step: 4000 | Avg. loss: 1.741 | lr: 0.00040584415584415587
Saving model with test loss of 1.710
Epoch: 2 | Step: 4050 | Avg. loss: 1.649 | lr: 0.00040539321789321794
Epoch: 2 | Step: 4100 | Avg. loss: 1.637 | lr: 0.00040494227994227996
Epoch: 2 | Step: 4150 | Avg. loss: 1.665 | lr: 0.000404491341991342
Epoch: 2 | Step: 4200 | Avg. loss: 1.640 | lr: 0.00040404040404040404
Epoch: 2 | Step: 4250 | Avg. loss: 1.661 | lr: 0.0004035894660894661
Epoch: 2 | Step: 4300 | Avg. loss: 1.642 | lr: 0.0004031385281385281
Epoch: 2 | Step: 4350 | Avg. loss: 1.629 | lr: 0.0004026875901875902
Epoch: 2 | Step: 4400 | Avg. loss: 1.593 | lr: 0.0004022366522366522
Epoch: 2 | Step: 4450 | Avg. loss: 1.684 | lr: 0.00040178571428571433
Epoch: 2 | Step: 4500 | Avg. loss: 1.654 | lr: 0.00040133477633477635
Epoch: 2 | Step: 4550 | Avg. loss: 1.694 | lr: 0.0004008838383838384
Epoch: 2 | Step: 4600 | Avg. loss: 1.711 | lr: 0.00040043290043290043
Epoch: 2 | Step: 4650 | Avg. loss: 1.670 | lr: 0.0003999819624819625
Epoch: 2 | Step: 4700 | Avg. loss: 1.744 | lr: 0.0003995310245310245
Epoch: 2 | Step: 4750 | Avg. loss: 1.707 | lr: 0.0003990800865800866
Epoch: 2 | Step: 4800 | Avg. loss: 1.671 | lr: 0.0003986291486291486
Epoch: 2 | Step: 4850 | Avg. loss: 1.660 | lr: 0.00039817821067821067
Epoch: 2 | Step: 4900 | Avg. loss: 1.600 | lr: 0.00039772727272727274
Epoch: 2 | Step: 4950 | Avg. loss: 1.606 | lr: 0.0003972763347763348
Epoch: 2 | Step: 5000 | Avg. loss: 1.580 | lr: 0.0003968253968253968
Saving model with test loss of 1.691
Epoch: 2 | Step: 5050 | Avg. loss: 1.546 | lr: 0.0003963744588744589
Epoch: 2 | Step: 5100 | Avg. loss: 1.651 | lr: 0.0003959235209235209
Epoch: 2 | Step: 5150 | Avg. loss: 1.602 | lr: 0.000395472582972583
Epoch: 2 | Step: 5200 | Avg. loss: 1.657 | lr: 0.000395021645021645
Epoch: 2 | Step: 5250 | Avg. loss: 1.616 | lr: 0.00039457070707070706
Epoch: 2 | Step: 5300 | Avg. loss: 1.635 | lr: 0.0003941197691197691
Epoch: 2 | Step: 5350 | Avg. loss: 1.562 | lr: 0.0003936688311688312
Epoch: 2 | Step: 5400 | Avg. loss: 1.670 | lr: 0.00039321789321789327
Epoch: 2 | Step: 5450 | Avg. loss: 1.618 | lr: 0.0003927669552669553
Epoch: 2 | Step: 5500 | Avg. loss: 1.619 | lr: 0.00039231601731601736
Epoch: 2 | Step: 5550 | Avg. loss: 1.648 | lr: 0.00039186507936507937
Epoch: 2 | Step: 5600 | Avg. loss: 1.563 | lr: 0.00039141414141414144
Epoch: 2 | Step: 5650 | Avg. loss: 1.599 | lr: 0.00039096320346320346
Epoch: 2 | Step: 5700 | Avg. loss: 1.566 | lr: 0.0003905122655122655
Epoch: 2 | Step: 5750 | Avg. loss: 1.609 | lr: 0.00039006132756132754
Epoch: 2 | Step: 5800 | Avg. loss: 1.625 | lr: 0.00038961038961038966
Epoch: 2 | Step: 5850 | Avg. loss: 1.605 | lr: 0.0003891594516594517
Epoch: 2 | Step: 5900 | Avg. loss: 1.572 | lr: 0.00038870851370851375
Epoch: 2 | Step: 5950 | Avg. loss: 1.540 | lr: 0.00038825757575757576
Epoch: 2 | Step: 6000 | Avg. loss: 1.546 | lr: 0.00038780663780663783
Saving model with test loss of 1.679
Epoch: 2 | Step: 6050 | Avg. loss: 1.589 | lr: 0.00038735569985569985
Epoch: 2 | Step: 6100 | Avg. loss: 1.596 | lr: 0.0003869047619047619
Epoch: 2 | Step: 6150 | Avg. loss: 1.614 | lr: 0.00038645382395382393
Epoch: 2 | Step: 6200 | Avg. loss: 1.596 | lr: 0.000386002886002886
Epoch: 2 | Step: 6250 | Avg. loss: 1.640 | lr: 0.000385551948051948
Epoch: 2 | Step: 6300 | Avg. loss: 1.570 | lr: 0.00038510101010101014
Epoch: 2 | Step: 6350 | Avg. loss: 1.607 | lr: 0.00038465007215007216
Epoch: 2 | Step: 6400 | Avg. loss: 1.575 | lr: 0.0003841991341991342
Epoch: 2 | Step: 6450 | Avg. loss: 1.568 | lr: 0.00038374819624819624
Epoch: 2 | Step: 6500 | Avg. loss: 1.603 | lr: 0.0003832972582972583
Epoch: 2 | Step: 6550 | Avg. loss: 1.581 | lr: 0.0003828463203463203
Epoch: 2 | Step: 6600 | Avg. loss: 1.529 | lr: 0.0003823953823953824
Epoch: 2 | Step: 6650 | Avg. loss: 1.584 | lr: 0.0003819444444444444
Epoch: 2 | Step: 6700 | Avg. loss: 1.576 | lr: 0.0003814935064935065
Epoch: 2 | Step: 6750 | Avg. loss: 1.555 | lr: 0.00038104256854256855
Epoch: 2 | Step: 6800 | Avg. loss: 1.557 | lr: 0.0003805916305916306
Epoch: 2 | Step: 6850 | Avg. loss: 1.521 | lr: 0.0003801406926406927
Epoch: 2 | Step: 6900 | Avg. loss: 1.530 | lr: 0.0003796897546897547
Epoch: 2 | Step: 6950 | Avg. loss: 1.607 | lr: 0.00037923881673881677
Epoch: 2 | Step: 7000 | Avg. loss: 1.585 | lr: 0.0003787878787878788
Saving model with test loss of 1.659
  0%|          | 0/7000 [00:00<?, ?it/s]
Epoch: 3 | Step: 50 | Avg. loss: 1.577 | lr: 0.00037833694083694086
Epoch: 3 | Step: 100 | Avg. loss: 1.571 | lr: 0.00037788600288600287
Epoch: 3 | Step: 150 | Avg. loss: 1.554 | lr: 0.00037743506493506494
Epoch: 3 | Step: 200 | Avg. loss: 1.557 | lr: 0.000376984126984127
Epoch: 3 | Step: 250 | Avg. loss: 1.509 | lr: 0.0003765331890331891
Epoch: 3 | Step: 300 | Avg. loss: 1.572 | lr: 0.0003760822510822511
Epoch: 3 | Step: 350 | Avg. loss: 1.515 | lr: 0.00037563131313131316
Epoch: 3 | Step: 400 | Avg. loss: 1.478 | lr: 0.0003751803751803752
Epoch: 3 | Step: 450 | Avg. loss: 1.507 | lr: 0.00037472943722943725
Epoch: 3 | Step: 500 | Avg. loss: 1.546 | lr: 0.00037427849927849926
Epoch: 3 | Step: 550 | Avg. loss: 1.520 | lr: 0.00037382756132756133
Epoch: 3 | Step: 600 | Avg. loss: 1.476 | lr: 0.00037337662337662335
Epoch: 3 | Step: 650 | Avg. loss: 1.488 | lr: 0.00037292568542568547
Epoch: 3 | Step: 700 | Avg. loss: 1.511 | lr: 0.0003724747474747475
Epoch: 3 | Step: 750 | Avg. loss: 1.502 | lr: 0.00037202380952380956
Epoch: 3 | Step: 800 | Avg. loss: 1.500 | lr: 0.00037157287157287157
Epoch: 3 | Step: 850 | Avg. loss: 1.505 | lr: 0.00037112193362193364
Epoch: 3 | Step: 900 | Avg. loss: 1.499 | lr: 0.00037067099567099566
Epoch: 3 | Step: 950 | Avg. loss: 1.458 | lr: 0.0003702200577200577
Epoch: 3 | Step: 1000 | Avg. loss: 1.428 | lr: 0.00036976911976911974
Saving model with test loss of 1.689
Epoch: 3 | Step: 1050 | Avg. loss: 1.429 | lr: 0.0003693181818181818
Epoch: 3 | Step: 1100 | Avg. loss: 1.452 | lr: 0.0003688672438672438
Epoch: 3 | Step: 1150 | Avg. loss: 1.520 | lr: 0.00036841630591630595
Epoch: 3 | Step: 1200 | Avg. loss: 1.494 | lr: 0.00036796536796536797
Epoch: 3 | Step: 1250 | Avg. loss: 1.455 | lr: 0.00036751443001443003
Epoch: 3 | Step: 1300 | Avg. loss: 1.430 | lr: 0.00036706349206349205
Epoch: 3 | Step: 1350 | Avg. loss: 1.455 | lr: 0.0003666125541125541
Epoch: 3 | Step: 1400 | Avg. loss: 1.462 | lr: 0.0003661616161616162
Epoch: 3 | Step: 1450 | Avg. loss: 1.421 | lr: 0.0003657106782106782
Epoch: 3 | Step: 1500 | Avg. loss: 1.449 | lr: 0.0003652597402597403
Epoch: 3 | Step: 1550 | Avg. loss: 1.443 | lr: 0.0003648088023088023
Epoch: 3 | Step: 1600 | Avg. loss: 1.468 | lr: 0.0003643578643578644
Epoch: 3 | Step: 1650 | Avg. loss: 1.431 | lr: 0.0003639069264069264
Epoch: 3 | Step: 1700 | Avg. loss: 1.480 | lr: 0.0003634559884559885
Epoch: 3 | Step: 1750 | Avg. loss: 1.443 | lr: 0.0003630050505050505
Epoch: 3 | Step: 1800 | Avg. loss: 1.482 | lr: 0.0003625541125541126
Epoch: 3 | Step: 1850 | Avg. loss: 1.404 | lr: 0.0003621031746031746
Epoch: 3 | Step: 1900 | Avg. loss: 1.430 | lr: 0.00036165223665223667
Epoch: 3 | Step: 1950 | Avg. loss: 1.453 | lr: 0.0003612012987012987
Epoch: 3 | Step: 2000 | Avg. loss: 1.392 | lr: 0.00036075036075036075
Saving model with test loss of 1.681
Epoch: 3 | Step: 2050 | Avg. loss: 1.439 | lr: 0.0003602994227994228
Epoch: 3 | Step: 2100 | Avg. loss: 1.388 | lr: 0.0003598484848484849
Epoch: 3 | Step: 2150 | Avg. loss: 1.368 | lr: 0.0003593975468975469
Epoch: 3 | Step: 2200 | Avg. loss: 1.431 | lr: 0.000358946608946609
Epoch: 3 | Step: 2250 | Avg. loss: 1.503 | lr: 0.000358495670995671
Epoch: 3 | Step: 2300 | Avg. loss: 1.433 | lr: 0.00035804473304473306
Epoch: 3 | Step: 2350 | Avg. loss: 1.430 | lr: 0.0003575937950937951
Epoch: 3 | Step: 2400 | Avg. loss: 1.386 | lr: 0.00035714285714285714
Epoch: 3 | Step: 2450 | Avg. loss: 1.398 | lr: 0.00035669191919191916
Epoch: 3 | Step: 2500 | Avg. loss: 1.405 | lr: 0.0003562409812409813
Epoch: 3 | Step: 2550 | Avg. loss: 1.398 | lr: 0.0003557900432900433
Epoch: 3 | Step: 2600 | Avg. loss: 1.397 | lr: 0.00035533910533910537
Epoch: 3 | Step: 2650 | Avg. loss: 1.436 | lr: 0.0003548881673881674
Epoch: 3 | Step: 2700 | Avg. loss: 1.382 | lr: 0.00035443722943722945
Epoch: 3 | Step: 2750 | Avg. loss: 1.411 | lr: 0.00035398629148629147
Epoch: 3 | Step: 2800 | Avg. loss: 1.363 | lr: 0.00035353535353535354
Epoch: 3 | Step: 2850 | Avg. loss: 1.444 | lr: 0.0003530844155844156
Epoch: 3 | Step: 2900 | Avg. loss: 1.372 | lr: 0.0003526334776334776
Epoch: 3 | Step: 2950 | Avg. loss: 1.453 | lr: 0.0003521825396825397
Epoch: 3 | Step: 3000 | Avg. loss: 1.337 | lr: 0.00035173160173160176
Saving model with test loss of 1.653
Epoch: 3 | Step: 3050 | Avg. loss: 1.404 | lr: 0.00035128066378066383
Epoch: 3 | Step: 3100 | Avg. loss: 1.401 | lr: 0.00035082972582972584
Epoch: 3 | Step: 3150 | Avg. loss: 1.433 | lr: 0.0003503787878787879
Epoch: 3 | Step: 3200 | Avg. loss: 1.417 | lr: 0.00034992784992784993
Epoch: 3 | Step: 3250 | Avg. loss: 1.391 | lr: 0.000349476911976912
Epoch: 3 | Step: 3300 | Avg. loss: 1.412 | lr: 0.000349025974025974
Epoch: 3 | Step: 3350 | Avg. loss: 1.365 | lr: 0.0003485750360750361
Epoch: 3 | Step: 3400 | Avg. loss: 1.376 | lr: 0.0003481240981240981
Epoch: 3 | Step: 3450 | Avg. loss: 1.389 | lr: 0.0003476731601731602
Epoch: 3 | Step: 3500 | Avg. loss: 1.370 | lr: 0.00034722222222222224
Epoch: 3 | Step: 3550 | Avg. loss: 1.344 | lr: 0.0003467712842712843
Epoch: 3 | Step: 3600 | Avg. loss: 1.389 | lr: 0.0003463203463203463
Epoch: 3 | Step: 3650 | Avg. loss: 1.377 | lr: 0.0003458694083694084
Epoch: 3 | Step: 3700 | Avg. loss: 1.322 | lr: 0.0003454184704184704
Epoch: 3 | Step: 3750 | Avg. loss: 1.346 | lr: 0.0003449675324675325
Epoch: 3 | Step: 3800 | Avg. loss: 1.325 | lr: 0.0003445165945165945
Epoch: 3 | Step: 3850 | Avg. loss: 1.299 | lr: 0.00034406565656565656
Epoch: 3 | Step: 3900 | Avg. loss: 1.365 | lr: 0.00034361471861471863
Epoch: 3 | Step: 3950 | Avg. loss: 1.416 | lr: 0.0003431637806637807
Epoch: 3 | Step: 4000 | Avg. loss: 1.418 | lr: 0.0003427128427128427
Saving model with test loss of 1.661
Epoch: 3 | Step: 4050 | Avg. loss: 1.327 | lr: 0.0003422619047619048
Epoch: 3 | Step: 4100 | Avg. loss: 1.319 | lr: 0.0003418109668109668
Epoch: 3 | Step: 4150 | Avg. loss: 1.355 | lr: 0.00034136002886002887
Epoch: 3 | Step: 4200 | Avg. loss: 1.335 | lr: 0.0003409090909090909
Epoch: 3 | Step: 4250 | Avg. loss: 1.343 | lr: 0.00034045815295815295
Epoch: 3 | Step: 4300 | Avg. loss: 1.331 | lr: 0.00034000721500721497
Epoch: 3 | Step: 4350 | Avg. loss: 1.331 | lr: 0.0003395562770562771
Epoch: 3 | Step: 4400 | Avg. loss: 1.281 | lr: 0.00033910533910533916
Epoch: 3 | Step: 4450 | Avg. loss: 1.361 | lr: 0.0003386544011544012
Epoch: 3 | Step: 4500 | Avg. loss: 1.346 | lr: 0.00033820346320346324
Epoch: 3 | Step: 4550 | Avg. loss: 1.384 | lr: 0.00033775252525252526
Epoch: 3 | Step: 4600 | Avg. loss: 1.393 | lr: 0.00033730158730158733
Epoch: 3 | Step: 4650 | Avg. loss: 1.371 | lr: 0.00033685064935064934
Epoch: 3 | Step: 4700 | Avg. loss: 1.415 | lr: 0.0003363997113997114
Epoch: 3 | Step: 4750 | Avg. loss: 1.382 | lr: 0.00033594877344877343
Epoch: 3 | Step: 4800 | Avg. loss: 1.366 | lr: 0.0003354978354978355
Epoch: 3 | Step: 4850 | Avg. loss: 1.353 | lr: 0.00033504689754689757
Epoch: 3 | Step: 4900 | Avg. loss: 1.292 | lr: 0.00033459595959595964
Epoch: 3 | Step: 4950 | Avg. loss: 1.306 | lr: 0.00033414502164502165
Epoch: 3 | Step: 5000 | Avg. loss: 1.279 | lr: 0.0003336940836940837
Saving model with test loss of 1.651
Epoch: 3 | Step: 5050 | Avg. loss: 1.249 | lr: 0.00033324314574314574
Epoch: 3 | Step: 5100 | Avg. loss: 1.346 | lr: 0.0003327922077922078
Epoch: 3 | Step: 5150 | Avg. loss: 1.295 | lr: 0.0003323412698412698
Epoch: 3 | Step: 5200 | Avg. loss: 1.338 | lr: 0.0003318903318903319
Epoch: 3 | Step: 5250 | Avg. loss: 1.302 | lr: 0.0003314393939393939
Epoch: 3 | Step: 5300 | Avg. loss: 1.313 | lr: 0.00033098845598845603
Epoch: 3 | Step: 5350 | Avg. loss: 1.255 | lr: 0.00033053751803751804
Epoch: 3 | Step: 5400 | Avg. loss: 1.348 | lr: 0.0003300865800865801
Epoch: 3 | Step: 5450 | Avg. loss: 1.313 | lr: 0.00032963564213564213
Epoch: 3 | Step: 5500 | Avg. loss: 1.307 | lr: 0.0003291847041847042
Epoch: 3 | Step: 5550 | Avg. loss: 1.335 | lr: 0.0003287337662337662
Epoch: 3 | Step: 5600 | Avg. loss: 1.260 | lr: 0.0003282828282828283
Epoch: 3 | Step: 5650 | Avg. loss: 1.294 | lr: 0.0003278318903318903
Epoch: 3 | Step: 5700 | Avg. loss: 1.266 | lr: 0.00032738095238095237
Epoch: 3 | Step: 5750 | Avg. loss: 1.294 | lr: 0.00032693001443001444
Epoch: 3 | Step: 5800 | Avg. loss: 1.314 | lr: 0.0003264790764790765
Epoch: 3 | Step: 5850 | Avg. loss: 1.296 | lr: 0.0003260281385281386
Epoch: 3 | Step: 5900 | Avg. loss: 1.276 | lr: 0.0003255772005772006
Epoch: 3 | Step: 5950 | Avg. loss: 1.260 | lr: 0.00032512626262626266
Epoch: 3 | Step: 6000 | Avg. loss: 1.252 | lr: 0.0003246753246753247
Saving model with test loss of 1.655
Epoch: 3 | Step: 6050 | Avg. loss: 1.283 | lr: 0.00032422438672438674
Epoch: 3 | Step: 6100 | Avg. loss: 1.294 | lr: 0.00032377344877344876
Epoch: 3 | Step: 6150 | Avg. loss: 1.318 | lr: 0.00032332251082251083
Epoch: 3 | Step: 6200 | Avg. loss: 1.299 | lr: 0.0003228715728715729
Epoch: 3 | Step: 6250 | Avg. loss: 1.346 | lr: 0.00032242063492063497
Epoch: 3 | Step: 6300 | Avg. loss: 1.270 | lr: 0.000321969696969697
Epoch: 3 | Step: 6350 | Avg. loss: 1.301 | lr: 0.00032151875901875905
Epoch: 3 | Step: 6400 | Avg. loss: 1.260 | lr: 0.00032106782106782107
Epoch: 3 | Step: 6450 | Avg. loss: 1.259 | lr: 0.00032061688311688314
Epoch: 3 | Step: 6500 | Avg. loss: 1.299 | lr: 0.00032016594516594515
Epoch: 3 | Step: 6550 | Avg. loss: 1.285 | lr: 0.0003197150072150072
Epoch: 3 | Step: 6600 | Avg. loss: 1.236 | lr: 0.00031926406926406924
Epoch: 3 | Step: 6650 | Avg. loss: 1.275 | lr: 0.0003188131313131313
Epoch: 3 | Step: 6700 | Avg. loss: 1.280 | lr: 0.0003183621933621934
Epoch: 3 | Step: 6750 | Avg. loss: 1.265 | lr: 0.00031791125541125544
Epoch: 3 | Step: 6800 | Avg. loss: 1.258 | lr: 0.00031746031746031746
Epoch: 3 | Step: 6850 | Avg. loss: 1.240 | lr: 0.00031700937950937953
Epoch: 3 | Step: 6900 | Avg. loss: 1.239 | lr: 0.00031655844155844154
Epoch: 3 | Step: 6950 | Avg. loss: 1.299 | lr: 0.0003161075036075036
Epoch: 3 | Step: 7000 | Avg. loss: 1.284 | lr: 0.00031565656565656563
Saving model with test loss of 1.653
  0%|          | 0/7000 [00:00<?, ?it/s]
Epoch: 4 | Step: 50 | Avg. loss: 1.288 | lr: 0.0003152056277056277
Epoch: 4 | Step: 100 | Avg. loss: 1.287 | lr: 0.0003147546897546897
Epoch: 4 | Step: 150 | Avg. loss: 1.261 | lr: 0.00031430375180375184
Epoch: 4 | Step: 200 | Avg. loss: 1.261 | lr: 0.00031385281385281385
Epoch: 4 | Step: 250 | Avg. loss: 1.226 | lr: 0.0003134018759018759
Epoch: 4 | Step: 300 | Avg. loss: 1.273 | lr: 0.00031295093795093794
Epoch: 4 | Step: 350 | Avg. loss: 1.228 | lr: 0.0003125
Epoch: 4 | Step: 400 | Avg. loss: 1.185 | lr: 0.0003120490620490621
Epoch: 4 | Step: 450 | Avg. loss: 1.215 | lr: 0.0003115981240981241
Epoch: 4 | Step: 500 | Avg. loss: 1.239 | lr: 0.00031114718614718616
Epoch: 4 | Step: 550 | Avg. loss: 1.224 | lr: 0.0003106962481962482
Epoch: 4 | Step: 600 | Avg. loss: 1.201 | lr: 0.0003102453102453103
Epoch: 4 | Step: 650 | Avg. loss: 1.204 | lr: 0.0003097943722943723
Epoch: 4 | Step: 700 | Avg. loss: 1.215 | lr: 0.0003093434343434344
Epoch: 4 | Step: 750 | Avg. loss: 1.223 | lr: 0.0003088924963924964
Epoch: 4 | Step: 800 | Avg. loss: 1.207 | lr: 0.00030844155844155847
Epoch: 4 | Step: 850 | Avg. loss: 1.217 | lr: 0.0003079906204906205
Epoch: 4 | Step: 900 | Avg. loss: 1.215 | lr: 0.00030753968253968255
Epoch: 4 | Step: 950 | Avg. loss: 1.181 | lr: 0.00030708874458874457
Epoch: 4 | Step: 1000 | Avg. loss: 1.158 | lr: 0.00030663780663780664
Saving model with test loss of 1.698
Epoch: 4 | Step: 1050 | Avg. loss: 1.143 | lr: 0.0003061868686868687
Epoch: 4 | Step: 1100 | Avg. loss: 1.151 | lr: 0.0003057359307359308
Epoch: 4 | Step: 1150 | Avg. loss: 1.236 | lr: 0.0003052849927849928
Epoch: 4 | Step: 1200 | Avg. loss: 1.218 | lr: 0.00030483405483405486
Epoch: 4 | Step: 1250 | Avg. loss: 1.173 | lr: 0.0003043831168831169
Epoch: 4 | Step: 1300 | Avg. loss: 1.152 | lr: 0.00030393217893217895
Epoch: 4 | Step: 1350 | Avg. loss: 1.172 | lr: 0.00030348124098124096
Epoch: 4 | Step: 1400 | Avg. loss: 1.190 | lr: 0.00030303030303030303
Epoch: 4 | Step: 1450 | Avg. loss: 1.144 | lr: 0.00030257936507936505
Epoch: 4 | Step: 1500 | Avg. loss: 1.163 | lr: 0.0003021284271284271
Epoch: 4 | Step: 1550 | Avg. loss: 1.169 | lr: 0.0003016774891774892
Epoch: 4 | Step: 1600 | Avg. loss: 1.183 | lr: 0.00030122655122655125
Epoch: 4 | Step: 1650 | Avg. loss: 1.164 | lr: 0.00030077561327561327
Epoch: 4 | Step: 1700 | Avg. loss: 1.196 | lr: 0.00030032467532467534
Epoch: 4 | Step: 1750 | Avg. loss: 1.165 | lr: 0.00029987373737373735
Epoch: 4 | Step: 1800 | Avg. loss: 1.194 | lr: 0.0002994227994227994
Epoch: 4 | Step: 1850 | Avg. loss: 1.167 | lr: 0.00029897186147186144
Epoch: 4 | Step: 1900 | Avg. loss: 1.169 | lr: 0.0002985209235209235
Epoch: 4 | Step: 1950 | Avg. loss: 1.176 | lr: 0.0002980699855699856
Epoch: 4 | Step: 2000 | Avg. loss: 1.123 | lr: 0.00029761904761904765
Saving model with test loss of 1.693
Epoch: 4 | Step: 2050 | Avg. loss: 1.164 | lr: 0.0002971681096681097
Epoch: 4 | Step: 2100 | Avg. loss: 1.115 | lr: 0.00029671717171717173
Epoch: 4 | Step: 2150 | Avg. loss: 1.099 | lr: 0.0002962662337662338
Epoch: 4 | Step: 2200 | Avg. loss: 1.158 | lr: 0.0002958152958152958
Epoch: 4 | Step: 2250 | Avg. loss: 1.222 | lr: 0.0002953643578643579
Epoch: 4 | Step: 2300 | Avg. loss: 1.156 | lr: 0.0002949134199134199
Epoch: 4 | Step: 2350 | Avg. loss: 1.160 | lr: 0.00029446248196248197
Epoch: 4 | Step: 2400 | Avg. loss: 1.107 | lr: 0.000294011544011544
Epoch: 4 | Step: 2450 | Avg. loss: 1.112 | lr: 0.0002935606060606061
Epoch: 4 | Step: 2500 | Avg. loss: 1.128 | lr: 0.0002931096681096681
Epoch: 4 | Step: 2550 | Avg. loss: 1.121 | lr: 0.0002926587301587302
Epoch: 4 | Step: 2600 | Avg. loss: 1.130 | lr: 0.0002922077922077922
Epoch: 4 | Step: 2650 | Avg. loss: 1.159 | lr: 0.0002917568542568543
Epoch: 4 | Step: 2700 | Avg. loss: 1.116 | lr: 0.0002913059163059163
Epoch: 4 | Step: 2750 | Avg. loss: 1.130 | lr: 0.00029085497835497836
Epoch: 4 | Step: 2800 | Avg. loss: 1.092 | lr: 0.0002904040404040404
Epoch: 4 | Step: 2850 | Avg. loss: 1.165 | lr: 0.00028995310245310245
Epoch: 4 | Step: 2900 | Avg. loss: 1.099 | lr: 0.0002895021645021645
Epoch: 4 | Step: 2950 | Avg. loss: 1.174 | lr: 0.0002890512265512266
Epoch: 4 | Step: 3000 | Avg. loss: 1.073 | lr: 0.0002886002886002886
Saving model with test loss of 1.704
Epoch: 4 | Step: 3050 | Avg. loss: 1.123 | lr: 0.00028814935064935067
Epoch: 4 | Step: 3100 | Avg. loss: 1.138 | lr: 0.0002876984126984127
Epoch: 4 | Step: 3150 | Avg. loss: 1.161 | lr: 0.00028724747474747475
Epoch: 4 | Step: 3200 | Avg. loss: 1.138 | lr: 0.00028679653679653677
Epoch: 4 | Step: 3250 | Avg. loss: 1.119 | lr: 0.00028634559884559884
Epoch: 4 | Step: 3300 | Avg. loss: 1.137 | lr: 0.00028589466089466085
Epoch: 4 | Step: 3350 | Avg. loss: 1.093 | lr: 0.0002854437229437229
Epoch: 4 | Step: 3400 | Avg. loss: 1.112 | lr: 0.00028499278499278505
Epoch: 4 | Step: 3450 | Avg. loss: 1.104 | lr: 0.00028454184704184706
Epoch: 4 | Step: 3500 | Avg. loss: 1.102 | lr: 0.00028409090909090913
Epoch: 4 | Step: 3550 | Avg. loss: 1.065 | lr: 0.00028363997113997115
Epoch: 4 | Step: 3600 | Avg. loss: 1.119 | lr: 0.0002831890331890332
Epoch: 4 | Step: 3650 | Avg. loss: 1.112 | lr: 0.00028273809523809523
Epoch: 4 | Step: 3700 | Avg. loss: 1.050 | lr: 0.0002822871572871573
Epoch: 4 | Step: 3750 | Avg. loss: 1.074 | lr: 0.0002818362193362193
Epoch: 4 | Step: 3800 | Avg. loss: 1.057 | lr: 0.0002813852813852814
Epoch: 4 | Step: 3850 | Avg. loss: 1.037 | lr: 0.00028093434343434345
Epoch: 4 | Step: 3900 | Avg. loss: 1.090 | lr: 0.0002804834054834055
Epoch: 4 | Step: 3950 | Avg. loss: 1.136 | lr: 0.00028003246753246754
Epoch: 4 | Step: 4000 | Avg. loss: 1.121 | lr: 0.0002795815295815296
Saving model with test loss of 1.725
Epoch: 4 | Step: 4050 | Avg. loss: 1.053 | lr: 0.0002791305916305916
Epoch: 4 | Step: 4100 | Avg. loss: 1.051 | lr: 0.0002786796536796537
Epoch: 4 | Step: 4150 | Avg. loss: 1.091 | lr: 0.0002782287157287157
Epoch: 4 | Step: 4200 | Avg. loss: 1.075 | lr: 0.0002777777777777778
Epoch: 4 | Step: 4250 | Avg. loss: 1.066 | lr: 0.0002773268398268398
Epoch: 4 | Step: 4300 | Avg. loss: 1.059 | lr: 0.0002768759018759019
Epoch: 4 | Step: 4350 | Avg. loss: 1.069 | lr: 0.00027642496392496393
Epoch: 4 | Step: 4400 | Avg. loss: 1.019 | lr: 0.000275974025974026
Epoch: 4 | Step: 4450 | Avg. loss: 1.081 | lr: 0.000275523088023088
Epoch: 4 | Step: 4500 | Avg. loss: 1.074 | lr: 0.0002750721500721501
Epoch: 4 | Step: 4550 | Avg. loss: 1.119 | lr: 0.0002746212121212121
Epoch: 4 | Step: 4600 | Avg. loss: 1.123 | lr: 0.00027417027417027417
Epoch: 4 | Step: 4650 | Avg. loss: 1.102 | lr: 0.0002737193362193362
Epoch: 4 | Step: 4700 | Avg. loss: 1.129 | lr: 0.00027326839826839825
Epoch: 4 | Step: 4750 | Avg. loss: 1.106 | lr: 0.0002728174603174603
Epoch: 4 | Step: 4800 | Avg. loss: 1.095 | lr: 0.0002723665223665224
Epoch: 4 | Step: 4850 | Avg. loss: 1.086 | lr: 0.0002719155844155844
Epoch: 4 | Step: 4900 | Avg. loss: 1.026 | lr: 0.0002714646464646465
Epoch: 4 | Step: 4950 | Avg. loss: 1.051 | lr: 0.00027101370851370855
Epoch: 4 | Step: 5000 | Avg. loss: 1.029 | lr: 0.00027056277056277056
Saving model with test loss of 1.724
Epoch: 4 | Step: 5050 | Avg. loss: 0.991 | lr: 0.00027011183261183263
Epoch: 4 | Step: 5100 | Avg. loss: 1.075 | lr: 0.00026966089466089465
Epoch: 4 | Step: 5150 | Avg. loss: 1.030 | lr: 0.0002692099567099567
Epoch: 4 | Step: 5200 | Avg. loss: 1.069 | lr: 0.00026875901875901873
Epoch: 4 | Step: 5250 | Avg. loss: 1.042 | lr: 0.00026830808080808086
Epoch: 4 | Step: 5300 | Avg. loss: 1.042 | lr: 0.00026785714285714287
Epoch: 4 | Step: 5350 | Avg. loss: 0.993 | lr: 0.00026740620490620494
Epoch: 4 | Step: 5400 | Avg. loss: 1.077 | lr: 0.00026695526695526696
Epoch: 4 | Step: 5450 | Avg. loss: 1.053 | lr: 0.000266504329004329
Epoch: 4 | Step: 5500 | Avg. loss: 1.041 | lr: 0.00026605339105339104
Epoch: 4 | Step: 5550 | Avg. loss: 1.068 | lr: 0.0002656024531024531
Epoch: 4 | Step: 5600 | Avg. loss: 0.997 | lr: 0.0002651515151515151
Epoch: 4 | Step: 5650 | Avg. loss: 1.032 | lr: 0.0002647005772005772
Epoch: 4 | Step: 5700 | Avg. loss: 1.008 | lr: 0.00026424963924963926
Epoch: 4 | Step: 5750 | Avg. loss: 1.030 | lr: 0.00026379870129870133
Epoch: 4 | Step: 5800 | Avg. loss: 1.050 | lr: 0.00026334776334776335
Epoch: 4 | Step: 5850 | Avg. loss: 1.025 | lr: 0.0002628968253968254
Epoch: 4 | Step: 5900 | Avg. loss: 1.026 | lr: 0.00026244588744588743
Epoch: 4 | Step: 5950 | Avg. loss: 1.010 | lr: 0.0002619949494949495
Epoch: 4 | Step: 6000 | Avg. loss: 0.995 | lr: 0.0002615440115440115
Saving model with test loss of 1.763
Epoch: 4 | Step: 6050 | Avg. loss: 1.028 | lr: 0.0002610930735930736
Epoch: 4 | Step: 6100 | Avg. loss: 1.036 | lr: 0.0002606421356421356
Epoch: 4 | Step: 6150 | Avg. loss: 1.054 | lr: 0.0002601911976911977
Epoch: 4 | Step: 6200 | Avg. loss: 1.044 | lr: 0.00025974025974025974
Epoch: 4 | Step: 6250 | Avg. loss: 1.074 | lr: 0.0002592893217893218
Epoch: 4 | Step: 6300 | Avg. loss: 1.009 | lr: 0.0002588383838383838
Epoch: 4 | Step: 6350 | Avg. loss: 1.030 | lr: 0.0002583874458874459
Epoch: 4 | Step: 6400 | Avg. loss: 0.994 | lr: 0.00025793650793650796
Epoch: 4 | Step: 6450 | Avg. loss: 1.013 | lr: 0.00025748556998557
Epoch: 4 | Step: 6500 | Avg. loss: 1.037 | lr: 0.00025703463203463205
Epoch: 4 | Step: 6550 | Avg. loss: 1.025 | lr: 0.00025658369408369406
Epoch: 4 | Step: 6600 | Avg. loss: 0.983 | lr: 0.0002561327561327562
Epoch: 4 | Step: 6650 | Avg. loss: 1.011 | lr: 0.0002556818181818182
Epoch: 4 | Step: 6700 | Avg. loss: 1.019 | lr: 0.00025523088023088027
Epoch: 4 | Step: 6750 | Avg. loss: 1.004 | lr: 0.0002547799422799423
Epoch: 4 | Step: 6800 | Avg. loss: 0.998 | lr: 0.00025432900432900436
Epoch: 4 | Step: 6850 | Avg. loss: 0.988 | lr: 0.00025387806637806637
Epoch: 4 | Step: 6900 | Avg. loss: 0.985 | lr: 0.00025342712842712844
Epoch: 4 | Step: 6950 | Avg. loss: 1.034 | lr: 0.00025297619047619046
Epoch: 4 | Step: 7000 | Avg. loss: 1.011 | lr: 0.0002525252525252525
Saving model with test loss of 1.741
  0%|          | 0/7000 [00:00<?, ?it/s]
Epoch: 5 | Step: 50 | Avg. loss: 1.029 | lr: 0.00025207431457431454
Epoch: 5 | Step: 100 | Avg. loss: 1.027 | lr: 0.00025162337662337666
Epoch: 5 | Step: 150 | Avg. loss: 0.993 | lr: 0.0002511724386724387
Epoch: 5 | Step: 200 | Avg. loss: 1.003 | lr: 0.00025072150072150075
Epoch: 5 | Step: 250 | Avg. loss: 0.983 | lr: 0.00025027056277056276
Epoch: 5 | Step: 300 | Avg. loss: 1.014 | lr: 0.00024981962481962483
Epoch: 5 | Step: 350 | Avg. loss: 0.978 | lr: 0.0002493686868686869
Epoch: 5 | Step: 400 | Avg. loss: 0.929 | lr: 0.0002489177489177489
Epoch: 5 | Step: 450 | Avg. loss: 0.972 | lr: 0.000248466810966811
Epoch: 5 | Step: 500 | Avg. loss: 0.979 | lr: 0.000248015873015873
Epoch: 5 | Step: 550 | Avg. loss: 0.974 | lr: 0.00024756493506493507
Epoch: 5 | Step: 600 | Avg. loss: 0.960 | lr: 0.00024711399711399714
Epoch: 5 | Step: 650 | Avg. loss: 0.953 | lr: 0.00024666305916305916
Epoch: 5 | Step: 700 | Avg. loss: 0.959 | lr: 0.0002462121212121212
Epoch: 5 | Step: 750 | Avg. loss: 0.973 | lr: 0.0002457611832611833
Epoch: 5 | Step: 800 | Avg. loss: 0.949 | lr: 0.0002453102453102453
Epoch: 5 | Step: 850 | Avg. loss: 0.961 | lr: 0.0002448593073593074
Epoch: 5 | Step: 900 | Avg. loss: 0.970 | lr: 0.0002444083694083694
Epoch: 5 | Step: 950 | Avg. loss: 0.935 | lr: 0.00024395743145743146
Epoch: 5 | Step: 1000 | Avg. loss: 0.912 | lr: 0.0002435064935064935
Saving model with test loss of 1.815
Epoch: 5 | Step: 1050 | Avg. loss: 0.898 | lr: 0.00024305555555555555
Epoch: 5 | Step: 1100 | Avg. loss: 0.898 | lr: 0.00024260461760461762
Epoch: 5 | Step: 1150 | Avg. loss: 0.973 | lr: 0.00024215367965367966
Epoch: 5 | Step: 1200 | Avg. loss: 0.963 | lr: 0.0002417027417027417
Epoch: 5 | Step: 1250 | Avg. loss: 0.921 | lr: 0.00024125180375180374
Epoch: 5 | Step: 1300 | Avg. loss: 0.919 | lr: 0.0002408008658008658
Epoch: 5 | Step: 1350 | Avg. loss: 0.918 | lr: 0.00024034992784992786
Epoch: 5 | Step: 1400 | Avg. loss: 0.944 | lr: 0.0002398989898989899
Epoch: 5 | Step: 1450 | Avg. loss: 0.903 | lr: 0.00023944805194805194
Epoch: 5 | Step: 1500 | Avg. loss: 0.911 | lr: 0.00023899711399711398
Epoch: 5 | Step: 1550 | Avg. loss: 0.926 | lr: 0.00023854617604617603
Epoch: 5 | Step: 1600 | Avg. loss: 0.934 | lr: 0.0002380952380952381
Epoch: 5 | Step: 1650 | Avg. loss: 0.932 | lr: 0.00023764430014430016
Epoch: 5 | Step: 1700 | Avg. loss: 0.948 | lr: 0.0002371933621933622
Epoch: 5 | Step: 1750 | Avg. loss: 0.930 | lr: 0.00023674242424242425
Epoch: 5 | Step: 1800 | Avg. loss: 0.938 | lr: 0.00023629148629148632
Epoch: 5 | Step: 1850 | Avg. loss: 0.892 | lr: 0.00023584054834054836
Epoch: 5 | Step: 1900 | Avg. loss: 0.916 | lr: 0.0002353896103896104
Epoch: 5 | Step: 1950 | Avg. loss: 0.924 | lr: 0.00023493867243867245
Epoch: 5 | Step: 2000 | Avg. loss: 0.889 | lr: 0.0002344877344877345
Saving model with test loss of 1.824
Epoch: 5 | Step: 2050 | Avg. loss: 0.913 | lr: 0.00023403679653679656
Epoch: 5 | Step: 2100 | Avg. loss: 0.889 | lr: 0.0002335858585858586
Epoch: 5 | Step: 2150 | Avg. loss: 0.864 | lr: 0.00023313492063492064
Epoch: 5 | Step: 2200 | Avg. loss: 0.911 | lr: 0.00023268398268398268
Epoch: 5 | Step: 2250 | Avg. loss: 0.972 | lr: 0.00023223304473304475
Epoch: 5 | Step: 2300 | Avg. loss: 0.910 | lr: 0.0002317821067821068
Epoch: 5 | Step: 2350 | Avg. loss: 0.921 | lr: 0.00023133116883116884
Epoch: 5 | Step: 2400 | Avg. loss: 0.869 | lr: 0.00023088023088023088
Epoch: 5 | Step: 2450 | Avg. loss: 0.875 | lr: 0.00023042929292929292
Epoch: 5 | Step: 2500 | Avg. loss: 0.878 | lr: 0.000229978354978355
Epoch: 5 | Step: 2550 | Avg. loss: 0.875 | lr: 0.00022952741702741703
Epoch: 5 | Step: 2600 | Avg. loss: 0.882 | lr: 0.00022907647907647908
Epoch: 5 | Step: 2650 | Avg. loss: 0.910 | lr: 0.00022862554112554112
Epoch: 5 | Step: 2700 | Avg. loss: 0.886 | lr: 0.00022817460317460316
Epoch: 5 | Step: 2750 | Avg. loss: 0.875 | lr: 0.00022772366522366523
Epoch: 5 | Step: 2800 | Avg. loss: 0.862 | lr: 0.00022727272727272727
Epoch: 5 | Step: 2850 | Avg. loss: 0.920 | lr: 0.00022682178932178931
Epoch: 5 | Step: 2900 | Avg. loss: 0.862 | lr: 0.00022637085137085136
Epoch: 5 | Step: 2950 | Avg. loss: 0.926 | lr: 0.00022591991341991343
Epoch: 5 | Step: 3000 | Avg. loss: 0.844 | lr: 0.00022546897546897547
Saving model with test loss of 1.825
Epoch: 5 | Step: 3050 | Avg. loss: 0.873 | lr: 0.0002250180375180375
Epoch: 5 | Step: 3100 | Avg. loss: 0.903 | lr: 0.00022456709956709955
Epoch: 5 | Step: 3150 | Avg. loss: 0.916 | lr: 0.00022411616161616162
Epoch: 5 | Step: 3200 | Avg. loss: 0.893 | lr: 0.0002236652236652237
Epoch: 5 | Step: 3250 | Avg. loss: 0.875 | lr: 0.00022321428571428573
Epoch: 5 | Step: 3300 | Avg. loss: 0.893 | lr: 0.00022276334776334778
Epoch: 5 | Step: 3350 | Avg. loss: 0.846 | lr: 0.00022231240981240982
Epoch: 5 | Step: 3400 | Avg. loss: 0.869 | lr: 0.0002218614718614719
Epoch: 5 | Step: 3450 | Avg. loss: 0.866 | lr: 0.00022141053391053393
Epoch: 5 | Step: 3500 | Avg. loss: 0.862 | lr: 0.00022095959595959597
Epoch: 5 | Step: 3550 | Avg. loss: 0.825 | lr: 0.00022050865800865802
Epoch: 5 | Step: 3600 | Avg. loss: 0.879 | lr: 0.00022005772005772006
Epoch: 5 | Step: 3650 | Avg. loss: 0.873 | lr: 0.00021960678210678213
Epoch: 5 | Step: 3700 | Avg. loss: 0.809 | lr: 0.00021915584415584417
Epoch: 5 | Step: 3750 | Avg. loss: 0.847 | lr: 0.0002187049062049062
Epoch: 5 | Step: 3800 | Avg. loss: 0.824 | lr: 0.00021825396825396825
Epoch: 5 | Step: 3850 | Avg. loss: 0.803 | lr: 0.0002178030303030303
Epoch: 5 | Step: 3900 | Avg. loss: 0.847 | lr: 0.00021735209235209237
Epoch: 5 | Step: 3950 | Avg. loss: 0.890 | lr: 0.0002169011544011544
Epoch: 5 | Step: 4000 | Avg. loss: 0.868 | lr: 0.00021645021645021645
Saving model with test loss of 1.882
Epoch: 5 | Step: 4050 | Avg. loss: 0.814 | lr: 0.0002159992784992785
Epoch: 5 | Step: 4100 | Avg. loss: 0.814 | lr: 0.00021554834054834056
Epoch: 5 | Step: 4150 | Avg. loss: 0.852 | lr: 0.0002150974025974026
Epoch: 5 | Step: 4200 | Avg. loss: 0.840 | lr: 0.00021464646464646465
Epoch: 5 | Step: 4250 | Avg. loss: 0.831 | lr: 0.0002141955266955267
Epoch: 5 | Step: 4300 | Avg. loss: 0.816 | lr: 0.00021374458874458873
Epoch: 5 | Step: 4350 | Avg. loss: 0.840 | lr: 0.0002132936507936508
Epoch: 5 | Step: 4400 | Avg. loss: 0.785 | lr: 0.00021284271284271284
Epoch: 5 | Step: 4450 | Avg. loss: 0.832 | lr: 0.00021239177489177488
Epoch: 5 | Step: 4500 | Avg. loss: 0.837 | lr: 0.00021194083694083693
Epoch: 5 | Step: 4550 | Avg. loss: 0.880 | lr: 0.00021148989898989897
Epoch: 5 | Step: 4600 | Avg. loss: 0.881 | lr: 0.00021103896103896104
Epoch: 5 | Step: 4650 | Avg. loss: 0.862 | lr: 0.0002105880230880231
Epoch: 5 | Step: 4700 | Avg. loss: 0.864 | lr: 0.00021013708513708515
Epoch: 5 | Step: 4750 | Avg. loss: 0.861 | lr: 0.0002096861471861472
Epoch: 5 | Step: 4800 | Avg. loss: 0.861 | lr: 0.00020923520923520926
Epoch: 5 | Step: 4850 | Avg. loss: 0.852 | lr: 0.0002087842712842713
Epoch: 5 | Step: 4900 | Avg. loss: 0.797 | lr: 0.00020833333333333335
Epoch: 5 | Step: 4950 | Avg. loss: 0.819 | lr: 0.0002078823953823954
Epoch: 5 | Step: 5000 | Avg. loss: 0.804 | lr: 0.00020743145743145743
Saving model with test loss of 1.842
Epoch: 5 | Step: 5050 | Avg. loss: 0.766 | lr: 0.0002069805194805195
Epoch: 5 | Step: 5100 | Avg. loss: 0.828 | lr: 0.00020652958152958154
Epoch: 5 | Step: 5150 | Avg. loss: 0.794 | lr: 0.00020607864357864359
Epoch: 5 | Step: 5200 | Avg. loss: 0.828 | lr: 0.00020562770562770563
Epoch: 5 | Step: 5250 | Avg. loss: 0.811 | lr: 0.0002051767676767677
Epoch: 5 | Step: 5300 | Avg. loss: 0.798 | lr: 0.00020472582972582974
Epoch: 5 | Step: 5350 | Avg. loss: 0.761 | lr: 0.00020427489177489178
Epoch: 5 | Step: 5400 | Avg. loss: 0.836 | lr: 0.00020382395382395382
Epoch: 5 | Step: 5450 | Avg. loss: 0.818 | lr: 0.00020337301587301587
Epoch: 5 | Step: 5500 | Avg. loss: 0.796 | lr: 0.00020292207792207794
Epoch: 5 | Step: 5550 | Avg. loss: 0.841 | lr: 0.00020247113997113998
Epoch: 5 | Step: 5600 | Avg. loss: 0.780 | lr: 0.00020202020202020202
Epoch: 5 | Step: 5650 | Avg. loss: 0.809 | lr: 0.00020156926406926406
Epoch: 5 | Step: 5700 | Avg. loss: 0.791 | lr: 0.0002011183261183261
Epoch: 5 | Step: 5750 | Avg. loss: 0.806 | lr: 0.00020066738816738817
Epoch: 5 | Step: 5800 | Avg. loss: 0.808 | lr: 0.00020021645021645022
Epoch: 5 | Step: 5850 | Avg. loss: 0.796 | lr: 0.00019976551226551226
Epoch: 5 | Step: 5900 | Avg. loss: 0.799 | lr: 0.0001993145743145743
Epoch: 5 | Step: 5950 | Avg. loss: 0.774 | lr: 0.00019886363636363637
Epoch: 5 | Step: 6000 | Avg. loss: 0.779 | lr: 0.0001984126984126984
Saving model with test loss of 1.945
Epoch: 5 | Step: 6050 | Avg. loss: 0.802 | lr: 0.00019796176046176045
Epoch: 5 | Step: 6100 | Avg. loss: 0.812 | lr: 0.0001975108225108225
Epoch: 5 | Step: 6150 | Avg. loss: 0.815 | lr: 0.00019705988455988454
Epoch: 5 | Step: 6200 | Avg. loss: 0.813 | lr: 0.00019660894660894664
Epoch: 5 | Step: 6250 | Avg. loss: 0.838 | lr: 0.00019615800865800868
Epoch: 5 | Step: 6300 | Avg. loss: 0.780 | lr: 0.00019570707070707072
Epoch: 5 | Step: 6350 | Avg. loss: 0.796 | lr: 0.00019525613275613276
Epoch: 5 | Step: 6400 | Avg. loss: 0.762 | lr: 0.00019480519480519483
Epoch: 5 | Step: 6450 | Avg. loss: 0.783 | lr: 0.00019435425685425687
Epoch: 5 | Step: 6500 | Avg. loss: 0.799 | lr: 0.00019390331890331892
Epoch: 5 | Step: 6550 | Avg. loss: 0.788 | lr: 0.00019345238095238096
Epoch: 5 | Step: 6600 | Avg. loss: 0.762 | lr: 0.000193001443001443
Epoch: 5 | Step: 6650 | Avg. loss: 0.767 | lr: 0.00019255050505050507
Epoch: 5 | Step: 6700 | Avg. loss: 0.784 | lr: 0.0001920995670995671
Epoch: 5 | Step: 6750 | Avg. loss: 0.771 | lr: 0.00019164862914862916
Epoch: 5 | Step: 6800 | Avg. loss: 0.773 | lr: 0.0001911976911976912
Epoch: 5 | Step: 6850 | Avg. loss: 0.761 | lr: 0.00019074675324675324
Epoch: 5 | Step: 6900 | Avg. loss: 0.768 | lr: 0.0001902958152958153
Epoch: 5 | Step: 6950 | Avg. loss: 0.793 | lr: 0.00018984487734487735
Epoch: 5 | Step: 7000 | Avg. loss: 0.773 | lr: 0.0001893939393939394
Saving model with test loss of 1.957
  0%|          | 0/7000 [00:00<?, ?it/s]
Epoch: 6 | Step: 50 | Avg. loss: 0.801 | lr: 0.00018894300144300144
Epoch: 6 | Step: 100 | Avg. loss: 0.793 | lr: 0.0001884920634920635
Epoch: 6 | Step: 150 | Avg. loss: 0.769 | lr: 0.00018804112554112555
Epoch: 6 | Step: 200 | Avg. loss: 0.774 | lr: 0.0001875901875901876
Epoch: 6 | Step: 250 | Avg. loss: 0.762 | lr: 0.00018713924963924963
Epoch: 6 | Step: 300 | Avg. loss: 0.781 | lr: 0.00018668831168831167
Epoch: 6 | Step: 350 | Avg. loss: 0.747 | lr: 0.00018623737373737374
Epoch: 6 | Step: 400 | Avg. loss: 0.703 | lr: 0.00018578643578643579
Epoch: 6 | Step: 450 | Avg. loss: 0.743 | lr: 0.00018533549783549783
Epoch: 6 | Step: 500 | Avg. loss: 0.755 | lr: 0.00018488455988455987
Epoch: 6 | Step: 550 | Avg. loss: 0.747 | lr: 0.0001844336219336219
Epoch: 6 | Step: 600 | Avg. loss: 0.747 | lr: 0.00018398268398268398
Epoch: 6 | Step: 650 | Avg. loss: 0.731 | lr: 0.00018353174603174602
Epoch: 6 | Step: 700 | Avg. loss: 0.732 | lr: 0.0001830808080808081
Epoch: 6 | Step: 750 | Avg. loss: 0.749 | lr: 0.00018262987012987014
Epoch: 6 | Step: 800 | Avg. loss: 0.731 | lr: 0.0001821789321789322
Epoch: 6 | Step: 850 | Avg. loss: 0.727 | lr: 0.00018172799422799425
Epoch: 6 | Step: 900 | Avg. loss: 0.741 | lr: 0.0001812770562770563
Epoch: 6 | Step: 950 | Avg. loss: 0.717 | lr: 0.00018082611832611833
Epoch: 6 | Step: 1000 | Avg. loss: 0.697 | lr: 0.00018037518037518038
Saving model with test loss of 2.032
Epoch: 6 | Step: 1050 | Avg. loss: 0.679 | lr: 0.00017992424242424244
Epoch: 6 | Step: 1100 | Avg. loss: 0.680 | lr: 0.0001794733044733045
Epoch: 6 | Step: 1150 | Avg. loss: 0.745 | lr: 0.00017902236652236653
Epoch: 6 | Step: 1200 | Avg. loss: 0.735 | lr: 0.00017857142857142857
Epoch: 6 | Step: 1250 | Avg. loss: 0.697 | lr: 0.00017812049062049064
Epoch: 6 | Step: 1300 | Avg. loss: 0.709 | lr: 0.00017766955266955268
Epoch: 6 | Step: 1350 | Avg. loss: 0.696 | lr: 0.00017721861471861473
Epoch: 6 | Step: 1400 | Avg. loss: 0.733 | lr: 0.00017676767676767677
Epoch: 6 | Step: 1450 | Avg. loss: 0.685 | lr: 0.0001763167388167388
Epoch: 6 | Step: 1500 | Avg. loss: 0.697 | lr: 0.00017586580086580088
Epoch: 6 | Step: 1550 | Avg. loss: 0.703 | lr: 0.00017541486291486292
Epoch: 6 | Step: 1600 | Avg. loss: 0.714 | lr: 0.00017496392496392496
Epoch: 6 | Step: 1650 | Avg. loss: 0.720 | lr: 0.000174512987012987
Epoch: 6 | Step: 1700 | Avg. loss: 0.726 | lr: 0.00017406204906204905
Epoch: 6 | Step: 1750 | Avg. loss: 0.713 | lr: 0.00017361111111111112
Epoch: 6 | Step: 1800 | Avg. loss: 0.706 | lr: 0.00017316017316017316
Epoch: 6 | Step: 1850 | Avg. loss: 0.675 | lr: 0.0001727092352092352
Epoch: 6 | Step: 1900 | Avg. loss: 0.702 | lr: 0.00017225829725829724
Epoch: 6 | Step: 1950 | Avg. loss: 0.713 | lr: 0.00017180735930735931
Epoch: 6 | Step: 2000 | Avg. loss: 0.678 | lr: 0.00017135642135642136
Saving model with test loss of 2.029
Epoch: 6 | Step: 2050 | Avg. loss: 0.688 | lr: 0.0001709054834054834
Epoch: 6 | Step: 2100 | Avg. loss: 0.674 | lr: 0.00017045454545454544
Epoch: 6 | Step: 2150 | Avg. loss: 0.657 | lr: 0.00017000360750360748
Epoch: 6 | Step: 2200 | Avg. loss: 0.694 | lr: 0.00016955266955266958
Epoch: 6 | Step: 2250 | Avg. loss: 0.753 | lr: 0.00016910173160173162
Epoch: 6 | Step: 2300 | Avg. loss: 0.684 | lr: 0.00016865079365079366
Epoch: 6 | Step: 2350 | Avg. loss: 0.694 | lr: 0.0001681998556998557
Epoch: 6 | Step: 2400 | Avg. loss: 0.661 | lr: 0.00016774891774891775
Epoch: 6 | Step: 2450 | Avg. loss: 0.662 | lr: 0.00016729797979797982
Epoch: 6 | Step: 2500 | Avg. loss: 0.676 | lr: 0.00016684704184704186
Epoch: 6 | Step: 2550 | Avg. loss: 0.666 | lr: 0.0001663961038961039
Epoch: 6 | Step: 2600 | Avg. loss: 0.663 | lr: 0.00016594516594516595
Epoch: 6 | Step: 2650 | Avg. loss: 0.687 | lr: 0.00016549422799422801
Epoch: 6 | Step: 2700 | Avg. loss: 0.673 | lr: 0.00016504329004329006
Epoch: 6 | Step: 2750 | Avg. loss: 0.654 | lr: 0.0001645923520923521
Epoch: 6 | Step: 2800 | Avg. loss: 0.657 | lr: 0.00016414141414141414
Epoch: 6 | Step: 2850 | Avg. loss: 0.695 | lr: 0.00016369047619047618
Epoch: 6 | Step: 2900 | Avg. loss: 0.649 | lr: 0.00016323953823953825
Epoch: 6 | Step: 2950 | Avg. loss: 0.711 | lr: 0.0001627886002886003
Epoch: 6 | Step: 3000 | Avg. loss: 0.644 | lr: 0.00016233766233766234
Saving model with test loss of 2.055
Epoch: 6 | Step: 3050 | Avg. loss: 0.666 | lr: 0.00016188672438672438
Epoch: 6 | Step: 3100 | Avg. loss: 0.683 | lr: 0.00016143578643578645
Epoch: 6 | Step: 3150 | Avg. loss: 0.702 | lr: 0.0001609848484848485
Epoch: 6 | Step: 3200 | Avg. loss: 0.676 | lr: 0.00016053391053391053
Epoch: 6 | Step: 3250 | Avg. loss: 0.664 | lr: 0.00016008297258297258
Epoch: 6 | Step: 3300 | Avg. loss: 0.670 | lr: 0.00015963203463203462
Epoch: 6 | Step: 3350 | Avg. loss: 0.642 | lr: 0.0001591810966810967
Epoch: 6 | Step: 3400 | Avg. loss: 0.656 | lr: 0.00015873015873015873
Epoch: 6 | Step: 3450 | Avg. loss: 0.651 | lr: 0.00015827922077922077
Epoch: 6 | Step: 3500 | Avg. loss: 0.647 | lr: 0.00015782828282828281
Epoch: 6 | Step: 3550 | Avg. loss: 0.607 | lr: 0.00015737734487734486
Epoch: 6 | Step: 3600 | Avg. loss: 0.670 | lr: 0.00015692640692640693
Epoch: 6 | Step: 3650 | Avg. loss: 0.658 | lr: 0.00015647546897546897
Epoch: 6 | Step: 3700 | Avg. loss: 0.604 | lr: 0.00015602453102453104
Epoch: 6 | Step: 3750 | Avg. loss: 0.641 | lr: 0.00015557359307359308
Epoch: 6 | Step: 3800 | Avg. loss: 0.622 | lr: 0.00015512265512265515
Epoch: 6 | Step: 3850 | Avg. loss: 0.599 | lr: 0.0001546717171717172
Epoch: 6 | Step: 3900 | Avg. loss: 0.638 | lr: 0.00015422077922077923
Epoch: 6 | Step: 3950 | Avg. loss: 0.673 | lr: 0.00015376984126984128
Epoch: 6 | Step: 4000 | Avg. loss: 0.650 | lr: 0.00015331890331890332
Saving model with test loss of 2.123
Epoch: 6 | Step: 4050 | Avg. loss: 0.601 | lr: 0.0001528679653679654
Epoch: 6 | Step: 4100 | Avg. loss: 0.605 | lr: 0.00015241702741702743
Epoch: 6 | Step: 4150 | Avg. loss: 0.638 | lr: 0.00015196608946608947
Epoch: 6 | Step: 4200 | Avg. loss: 0.636 | lr: 0.00015151515151515152
Epoch: 6 | Step: 4250 | Avg. loss: 0.629 | lr: 0.00015106421356421356
Epoch: 6 | Step: 4300 | Avg. loss: 0.612 | lr: 0.00015061327561327563
Epoch: 6 | Step: 4350 | Avg. loss: 0.632 | lr: 0.00015016233766233767
Epoch: 6 | Step: 4400 | Avg. loss: 0.586 | lr: 0.0001497113997113997
Epoch: 6 | Step: 4450 | Avg. loss: 0.622 | lr: 0.00014926046176046175
Epoch: 6 | Step: 4500 | Avg. loss: 0.618 | lr: 0.00014880952380952382
Epoch: 6 | Step: 4550 | Avg. loss: 0.675 | lr: 0.00014835858585858587
Epoch: 6 | Step: 4600 | Avg. loss: 0.673 | lr: 0.0001479076479076479
Epoch: 6 | Step: 4650 | Avg. loss: 0.649 | lr: 0.00014745670995670995
Epoch: 6 | Step: 4700 | Avg. loss: 0.636 | lr: 0.000147005772005772
Epoch: 6 | Step: 4750 | Avg. loss: 0.643 | lr: 0.00014655483405483406
Epoch: 6 | Step: 4800 | Avg. loss: 0.654 | lr: 0.0001461038961038961
Epoch: 6 | Step: 4850 | Avg. loss: 0.642 | lr: 0.00014565295815295815
Epoch: 6 | Step: 4900 | Avg. loss: 0.593 | lr: 0.0001452020202020202
Epoch: 6 | Step: 4950 | Avg. loss: 0.613 | lr: 0.00014475108225108226
Epoch: 6 | Step: 5000 | Avg. loss: 0.603 | lr: 0.0001443001443001443
Saving model with test loss of 2.144
Epoch: 6 | Step: 5050 | Avg. loss: 0.574 | lr: 0.00014384920634920634
Epoch: 6 | Step: 5100 | Avg. loss: 0.622 | lr: 0.00014339826839826838
Epoch: 6 | Step: 5150 | Avg. loss: 0.588 | lr: 0.00014294733044733043
Epoch: 6 | Step: 5200 | Avg. loss: 0.615 | lr: 0.00014249639249639252
Epoch: 6 | Step: 5250 | Avg. loss: 0.600 | lr: 0.00014204545454545457
Epoch: 6 | Step: 5300 | Avg. loss: 0.590 | lr: 0.0001415945165945166
Epoch: 6 | Step: 5350 | Avg. loss: 0.567 | lr: 0.00014114357864357865
Epoch: 6 | Step: 5400 | Avg. loss: 0.629 | lr: 0.0001406926406926407
Epoch: 6 | Step: 5450 | Avg. loss: 0.607 | lr: 0.00014024170274170276
Epoch: 6 | Step: 5500 | Avg. loss: 0.585 | lr: 0.0001397907647907648
Epoch: 6 | Step: 5550 | Avg. loss: 0.629 | lr: 0.00013933982683982685
Epoch: 6 | Step: 5600 | Avg. loss: 0.593 | lr: 0.0001388888888888889
Epoch: 6 | Step: 5650 | Avg. loss: 0.598 | lr: 0.00013843795093795096
Epoch: 6 | Step: 5700 | Avg. loss: 0.584 | lr: 0.000137987012987013
Epoch: 6 | Step: 5750 | Avg. loss: 0.606 | lr: 0.00013753607503607504
Epoch: 6 | Step: 5800 | Avg. loss: 0.601 | lr: 0.00013708513708513709
Epoch: 6 | Step: 5850 | Avg. loss: 0.593 | lr: 0.00013663419913419913
Epoch: 6 | Step: 5900 | Avg. loss: 0.596 | lr: 0.0001361832611832612
Epoch: 6 | Step: 5950 | Avg. loss: 0.562 | lr: 0.00013573232323232324
Epoch: 6 | Step: 6000 | Avg. loss: 0.576 | lr: 0.00013528138528138528
Saving model with test loss of 2.276
Epoch: 6 | Step: 6050 | Avg. loss: 0.603 | lr: 0.00013483044733044732
Epoch: 6 | Step: 6100 | Avg. loss: 0.614 | lr: 0.00013437950937950937
Epoch: 6 | Step: 6150 | Avg. loss: 0.607 | lr: 0.00013392857142857144
Epoch: 6 | Step: 6200 | Avg. loss: 0.614 | lr: 0.00013347763347763348
Epoch: 6 | Step: 6250 | Avg. loss: 0.625 | lr: 0.00013302669552669552
Epoch: 6 | Step: 6300 | Avg. loss: 0.570 | lr: 0.00013257575757575756
Epoch: 6 | Step: 6350 | Avg. loss: 0.590 | lr: 0.00013212481962481963
Epoch: 6 | Step: 6400 | Avg. loss: 0.567 | lr: 0.00013167388167388167
Epoch: 6 | Step: 6450 | Avg. loss: 0.581 | lr: 0.00013122294372294372
Epoch: 6 | Step: 6500 | Avg. loss: 0.589 | lr: 0.00013077200577200576
Epoch: 6 | Step: 6550 | Avg. loss: 0.579 | lr: 0.0001303210678210678
Epoch: 6 | Step: 6600 | Avg. loss: 0.556 | lr: 0.00012987012987012987
Epoch: 6 | Step: 6650 | Avg. loss: 0.557 | lr: 0.0001294191919191919
Epoch: 6 | Step: 6700 | Avg. loss: 0.582 | lr: 0.00012896825396825398
Epoch: 6 | Step: 6750 | Avg. loss: 0.567 | lr: 0.00012851731601731602
Epoch: 6 | Step: 6800 | Avg. loss: 0.568 | lr: 0.0001280663780663781
Epoch: 6 | Step: 6850 | Avg. loss: 0.559 | lr: 0.00012761544011544014
Epoch: 6 | Step: 6900 | Avg. loss: 0.573 | lr: 0.00012716450216450218
Epoch: 6 | Step: 6950 | Avg. loss: 0.585 | lr: 0.00012671356421356422
Epoch: 6 | Step: 7000 | Avg. loss: 0.569 | lr: 0.00012626262626262626
Saving model with test loss of 2.302
  0%|          | 0/7000 [00:00<?, ?it/s]
Epoch: 7 | Step: 50 | Avg. loss: 0.595 | lr: 0.00012581168831168833
Epoch: 7 | Step: 100 | Avg. loss: 0.600 | lr: 0.00012536075036075037
Epoch: 7 | Step: 150 | Avg. loss: 0.574 | lr: 0.00012490981240981242
Epoch: 7 | Step: 200 | Avg. loss: 0.572 | lr: 0.00012445887445887446
Epoch: 7 | Step: 250 | Avg. loss: 0.571 | lr: 0.0001240079365079365
Epoch: 7 | Step: 300 | Avg. loss: 0.583 | lr: 0.00012355699855699857
Epoch: 7 | Step: 350 | Avg. loss: 0.552 | lr: 0.0001231060606060606
Epoch: 7 | Step: 400 | Avg. loss: 0.510 | lr: 0.00012265512265512266
Epoch: 7 | Step: 450 | Avg. loss: 0.547 | lr: 0.0001222041847041847
Epoch: 7 | Step: 500 | Avg. loss: 0.553 | lr: 0.00012175324675324675
Epoch: 7 | Step: 550 | Avg. loss: 0.548 | lr: 0.00012130230880230881
Epoch: 7 | Step: 600 | Avg. loss: 0.556 | lr: 0.00012085137085137085
Epoch: 7 | Step: 650 | Avg. loss: 0.546 | lr: 0.0001204004329004329
Epoch: 7 | Step: 700 | Avg. loss: 0.537 | lr: 0.00011994949494949495
Epoch: 7 | Step: 750 | Avg. loss: 0.550 | lr: 0.00011949855699855699
Epoch: 7 | Step: 800 | Avg. loss: 0.535 | lr: 0.00011904761904761905
Epoch: 7 | Step: 850 | Avg. loss: 0.535 | lr: 0.0001185966810966811
Epoch: 7 | Step: 900 | Avg. loss: 0.553 | lr: 0.00011814574314574316
Epoch: 7 | Step: 950 | Avg. loss: 0.527 | lr: 0.0001176948051948052
Epoch: 7 | Step: 1000 | Avg. loss: 0.510 | lr: 0.00011724386724386724
Saving model with test loss of 2.409
Epoch: 7 | Step: 1050 | Avg. loss: 0.500 | lr: 0.0001167929292929293
Epoch: 7 | Step: 1100 | Avg. loss: 0.491 | lr: 0.00011634199134199134
Epoch: 7 | Step: 1150 | Avg. loss: 0.547 | lr: 0.0001158910533910534
Epoch: 7 | Step: 1200 | Avg. loss: 0.544 | lr: 0.00011544011544011544
Epoch: 7 | Step: 1250 | Avg. loss: 0.506 | lr: 0.0001149891774891775
Epoch: 7 | Step: 1300 | Avg. loss: 0.524 | lr: 0.00011453823953823954
Epoch: 7 | Step: 1350 | Avg. loss: 0.509 | lr: 0.00011408730158730158
Epoch: 7 | Step: 1400 | Avg. loss: 0.548 | lr: 0.00011363636363636364
Epoch: 7 | Step: 1450 | Avg. loss: 0.506 | lr: 0.00011318542568542568
Epoch: 7 | Step: 1500 | Avg. loss: 0.507 | lr: 0.00011273448773448773
Epoch: 7 | Step: 1550 | Avg. loss: 0.513 | lr: 0.00011228354978354978
Epoch: 7 | Step: 1600 | Avg. loss: 0.530 | lr: 0.00011183261183261185
Epoch: 7 | Step: 1650 | Avg. loss: 0.539 | lr: 0.00011138167388167389
Epoch: 7 | Step: 1700 | Avg. loss: 0.536 | lr: 0.00011093073593073594
Epoch: 7 | Step: 1750 | Avg. loss: 0.526 | lr: 0.00011047979797979799
Epoch: 7 | Step: 1800 | Avg. loss: 0.509 | lr: 0.00011002886002886003
Epoch: 7 | Step: 1850 | Avg. loss: 0.481 | lr: 0.00010957792207792208
Epoch: 7 | Step: 1900 | Avg. loss: 0.512 | lr: 0.00010912698412698413
Epoch: 7 | Step: 1950 | Avg. loss: 0.528 | lr: 0.00010867604617604618
Epoch: 7 | Step: 2000 | Avg. loss: 0.491 | lr: 0.00010822510822510823
Saving model with test loss of 2.413
Epoch: 7 | Step: 2050 | Avg. loss: 0.500 | lr: 0.00010777417027417028
Epoch: 7 | Step: 2100 | Avg. loss: 0.488 | lr: 0.00010732323232323232
Epoch: 7 | Step: 2150 | Avg. loss: 0.479 | lr: 0.00010687229437229437
Epoch: 7 | Step: 2200 | Avg. loss: 0.496 | lr: 0.00010642135642135642
Epoch: 7 | Step: 2250 | Avg. loss: 0.556 | lr: 0.00010597041847041846
Epoch: 7 | Step: 2300 | Avg. loss: 0.493 | lr: 0.00010551948051948052
Epoch: 7 | Step: 2350 | Avg. loss: 0.507 | lr: 0.00010506854256854258
Epoch: 7 | Step: 2400 | Avg. loss: 0.483 | lr: 0.00010461760461760463
Epoch: 7 | Step: 2450 | Avg. loss: 0.480 | lr: 0.00010416666666666667
Epoch: 7 | Step: 2500 | Avg. loss: 0.483 | lr: 0.00010371572871572872
Epoch: 7 | Step: 2550 | Avg. loss: 0.481 | lr: 0.00010326479076479077
Epoch: 7 | Step: 2600 | Avg. loss: 0.479 | lr: 0.00010281385281385281
Epoch: 7 | Step: 2650 | Avg. loss: 0.501 | lr: 0.00010236291486291487
Epoch: 7 | Step: 2700 | Avg. loss: 0.491 | lr: 0.00010191197691197691
Epoch: 7 | Step: 2750 | Avg. loss: 0.466 | lr: 0.00010146103896103897
Epoch: 7 | Step: 2800 | Avg. loss: 0.475 | lr: 0.00010101010101010101
Epoch: 7 | Step: 2850 | Avg. loss: 0.504 | lr: 0.00010055916305916305
Epoch: 7 | Step: 2900 | Avg. loss: 0.467 | lr: 0.00010010822510822511
Epoch: 7 | Step: 2950 | Avg. loss: 0.513 | lr: 9.965728715728715e-05
Epoch: 7 | Step: 3000 | Avg. loss: 0.472 | lr: 9.92063492063492e-05
Saving model with test loss of 2.505
Epoch: 7 | Step: 3050 | Avg. loss: 0.488 | lr: 9.875541125541125e-05
Epoch: 7 | Step: 3100 | Avg. loss: 0.493 | lr: 9.830447330447332e-05
Epoch: 7 | Step: 3150 | Avg. loss: 0.513 | lr: 9.785353535353536e-05
Epoch: 7 | Step: 3200 | Avg. loss: 0.492 | lr: 9.740259740259742e-05
Epoch: 7 | Step: 3250 | Avg. loss: 0.484 | lr: 9.695165945165946e-05
Epoch: 7 | Step: 3300 | Avg. loss: 0.479 | lr: 9.65007215007215e-05
Epoch: 7 | Step: 3350 | Avg. loss: 0.463 | lr: 9.604978354978356e-05
Epoch: 7 | Step: 3400 | Avg. loss: 0.476 | lr: 9.55988455988456e-05
Epoch: 7 | Step: 3450 | Avg. loss: 0.467 | lr: 9.514790764790765e-05
Epoch: 7 | Step: 3500 | Avg. loss: 0.465 | lr: 9.46969696969697e-05
Epoch: 7 | Step: 3550 | Avg. loss: 0.434 | lr: 9.424603174603175e-05
Epoch: 7 | Step: 3600 | Avg. loss: 0.482 | lr: 9.37950937950938e-05
Epoch: 7 | Step: 3650 | Avg. loss: 0.482 | lr: 9.334415584415584e-05
Epoch: 7 | Step: 3700 | Avg. loss: 0.425 | lr: 9.289321789321789e-05
Epoch: 7 | Step: 3750 | Avg. loss: 0.471 | lr: 9.244227994227994e-05
Epoch: 7 | Step: 3800 | Avg. loss: 0.449 | lr: 9.199134199134199e-05
Epoch: 7 | Step: 3850 | Avg. loss: 0.424 | lr: 9.154040404040405e-05
Epoch: 7 | Step: 3900 | Avg. loss: 0.456 | lr: 9.10894660894661e-05
Epoch: 7 | Step: 3950 | Avg. loss: 0.490 | lr: 9.063852813852815e-05
Epoch: 7 | Step: 4000 | Avg. loss: 0.467 | lr: 9.018759018759019e-05
Saving model with test loss of 2.604
Epoch: 7 | Step: 4050 | Avg. loss: 0.427 | lr: 8.973665223665224e-05
Epoch: 7 | Step: 4100 | Avg. loss: 0.441 | lr: 8.928571428571429e-05
Epoch: 7 | Step: 4150 | Avg. loss: 0.456 | lr: 8.883477633477634e-05
Epoch: 7 | Step: 4200 | Avg. loss: 0.459 | lr: 8.838383838383838e-05
Epoch: 7 | Step: 4250 | Avg. loss: 0.459 | lr: 8.793290043290044e-05
Epoch: 7 | Step: 4300 | Avg. loss: 0.442 | lr: 8.748196248196248e-05
Epoch: 7 | Step: 4350 | Avg. loss: 0.458 | lr: 8.703102453102452e-05
Epoch: 7 | Step: 4400 | Avg. loss: 0.424 | lr: 8.658008658008658e-05
Epoch: 7 | Step: 4450 | Avg. loss: 0.445 | lr: 8.612914862914862e-05
Epoch: 7 | Step: 4500 | Avg. loss: 0.434 | lr: 8.567821067821068e-05
Epoch: 7 | Step: 4550 | Avg. loss: 0.493 | lr: 8.522727272727272e-05
Epoch: 7 | Step: 4600 | Avg. loss: 0.490 | lr: 8.477633477633479e-05
Epoch: 7 | Step: 4650 | Avg. loss: 0.472 | lr: 8.432539682539683e-05
Epoch: 7 | Step: 4700 | Avg. loss: 0.457 | lr: 8.387445887445887e-05
Epoch: 7 | Step: 4750 | Avg. loss: 0.454 | lr: 8.342352092352093e-05
Epoch: 7 | Step: 4800 | Avg. loss: 0.479 | lr: 8.297258297258297e-05
Epoch: 7 | Step: 4850 | Avg. loss: 0.466 | lr: 8.252164502164503e-05
Epoch: 7 | Step: 4900 | Avg. loss: 0.428 | lr: 8.207070707070707e-05
Epoch: 7 | Step: 4950 | Avg. loss: 0.440 | lr: 8.161976911976913e-05
Epoch: 7 | Step: 5000 | Avg. loss: 0.435 | lr: 8.116883116883117e-05
Saving model with test loss of 2.627
Epoch: 7 | Step: 5050 | Avg. loss: 0.417 | lr: 8.071789321789322e-05
Epoch: 7 | Step: 5100 | Avg. loss: 0.445 | lr: 8.026695526695527e-05
Epoch: 7 | Step: 5150 | Avg. loss: 0.422 | lr: 7.981601731601731e-05
Epoch: 7 | Step: 5200 | Avg. loss: 0.434 | lr: 7.936507936507937e-05
Epoch: 7 | Step: 5250 | Avg. loss: 0.437 | lr: 7.891414141414141e-05
Epoch: 7 | Step: 5300 | Avg. loss: 0.427 | lr: 7.846320346320346e-05
Epoch: 7 | Step: 5350 | Avg. loss: 0.405 | lr: 7.801226551226552e-05
Epoch: 7 | Step: 5400 | Avg. loss: 0.453 | lr: 7.756132756132757e-05
Epoch: 7 | Step: 5450 | Avg. loss: 0.432 | lr: 7.711038961038962e-05
Epoch: 7 | Step: 5500 | Avg. loss: 0.418 | lr: 7.665945165945166e-05
Epoch: 7 | Step: 5550 | Avg. loss: 0.460 | lr: 7.620851370851372e-05
Epoch: 7 | Step: 5600 | Avg. loss: 0.425 | lr: 7.575757575757576e-05
Epoch: 7 | Step: 5650 | Avg. loss: 0.427 | lr: 7.530663780663781e-05
Epoch: 7 | Step: 5700 | Avg. loss: 0.412 | lr: 7.485569985569986e-05
Epoch: 7 | Step: 5750 | Avg. loss: 0.443 | lr: 7.440476190476191e-05
Epoch: 7 | Step: 5800 | Avg. loss: 0.430 | lr: 7.395382395382395e-05
Epoch: 7 | Step: 5850 | Avg. loss: 0.435 | lr: 7.3502886002886e-05
Epoch: 7 | Step: 5900 | Avg. loss: 0.429 | lr: 7.305194805194805e-05
Epoch: 7 | Step: 5950 | Avg. loss: 0.404 | lr: 7.26010101010101e-05
Epoch: 7 | Step: 6000 | Avg. loss: 0.412 | lr: 7.215007215007215e-05
Saving model with test loss of 2.701
Epoch: 7 | Step: 6050 | Avg. loss: 0.430 | lr: 7.169913419913419e-05
Epoch: 7 | Step: 6100 | Avg. loss: 0.438 | lr: 7.124819624819626e-05
Epoch: 7 | Step: 6150 | Avg. loss: 0.433 | lr: 7.07972582972583e-05
Epoch: 7 | Step: 6200 | Avg. loss: 0.448 | lr: 7.034632034632035e-05
Epoch: 7 | Step: 6250 | Avg. loss: 0.457 | lr: 6.98953823953824e-05
Epoch: 7 | Step: 6300 | Avg. loss: 0.405 | lr: 6.944444444444444e-05
Epoch: 7 | Step: 6350 | Avg. loss: 0.422 | lr: 6.89935064935065e-05
Epoch: 7 | Step: 6400 | Avg. loss: 0.401 | lr: 6.854256854256854e-05
Epoch: 7 | Step: 6450 | Avg. loss: 0.424 | lr: 6.80916305916306e-05
Epoch: 7 | Step: 6500 | Avg. loss: 0.429 | lr: 6.764069264069264e-05
Epoch: 7 | Step: 6550 | Avg. loss: 0.409 | lr: 6.718975468975468e-05
Epoch: 7 | Step: 6600 | Avg. loss: 0.395 | lr: 6.673881673881674e-05
Epoch: 7 | Step: 6650 | Avg. loss: 0.393 | lr: 6.628787878787878e-05
Epoch: 7 | Step: 6700 | Avg. loss: 0.416 | lr: 6.583694083694084e-05
Epoch: 7 | Step: 6750 | Avg. loss: 0.400 | lr: 6.538600288600288e-05
Epoch: 7 | Step: 6800 | Avg. loss: 0.401 | lr: 6.493506493506494e-05
Epoch: 7 | Step: 6850 | Avg. loss: 0.400 | lr: 6.448412698412699e-05
Epoch: 7 | Step: 6900 | Avg. loss: 0.411 | lr: 6.403318903318905e-05
Epoch: 7 | Step: 6950 | Avg. loss: 0.418 | lr: 6.358225108225109e-05
Epoch: 7 | Step: 7000 | Avg. loss: 0.404 | lr: 6.313131313131313e-05
Saving model with test loss of 2.726
  0%|          | 0/7000 [00:00<?, ?it/s]
Epoch: 8 | Step: 50 | Avg. loss: 0.427 | lr: 6.268037518037519e-05
Epoch: 8 | Step: 100 | Avg. loss: 0.431 | lr: 6.222943722943723e-05
Epoch: 8 | Step: 150 | Avg. loss: 0.416 | lr: 6.177849927849929e-05
Epoch: 8 | Step: 200 | Avg. loss: 0.414 | lr: 6.132756132756133e-05
Epoch: 8 | Step: 250 | Avg. loss: 0.417 | lr: 6.0876623376623377e-05
Epoch: 8 | Step: 300 | Avg. loss: 0.426 | lr: 6.0425685425685426e-05
Epoch: 8 | Step: 350 | Avg. loss: 0.394 | lr: 5.9974747474747475e-05
Epoch: 8 | Step: 400 | Avg. loss: 0.364 | lr: 5.9523809523809524e-05
Epoch: 8 | Step: 450 | Avg. loss: 0.393 | lr: 5.907287157287158e-05
Epoch: 8 | Step: 500 | Avg. loss: 0.390 | lr: 5.862193362193362e-05
Epoch: 8 | Step: 550 | Avg. loss: 0.390 | lr: 5.817099567099567e-05
Epoch: 8 | Step: 600 | Avg. loss: 0.402 | lr: 5.772005772005772e-05
Epoch: 8 | Step: 650 | Avg. loss: 0.382 | lr: 5.726911976911977e-05
Epoch: 8 | Step: 700 | Avg. loss: 0.385 | lr: 5.681818181818182e-05
Epoch: 8 | Step: 750 | Avg. loss: 0.393 | lr: 5.636724386724387e-05
Epoch: 8 | Step: 800 | Avg. loss: 0.383 | lr: 5.591630591630592e-05
Epoch: 8 | Step: 850 | Avg. loss: 0.377 | lr: 5.546536796536797e-05
Epoch: 8 | Step: 900 | Avg. loss: 0.403 | lr: 5.5014430014430014e-05
Epoch: 8 | Step: 950 | Avg. loss: 0.383 | lr: 5.4563492063492063e-05
Epoch: 8 | Step: 1000 | Avg. loss: 0.365 | lr: 5.411255411255411e-05
Saving model with test loss of 2.924
Epoch: 8 | Step: 1050 | Avg. loss: 0.359 | lr: 5.366161616161616e-05
Epoch: 8 | Step: 1100 | Avg. loss: 0.350 | lr: 5.321067821067821e-05
Epoch: 8 | Step: 1150 | Avg. loss: 0.399 | lr: 5.275974025974026e-05
Epoch: 8 | Step: 1200 | Avg. loss: 0.387 | lr: 5.2308802308802316e-05
Epoch: 8 | Step: 1250 | Avg. loss: 0.360 | lr: 5.185786435786436e-05
Epoch: 8 | Step: 1300 | Avg. loss: 0.369 | lr: 5.140692640692641e-05
Epoch: 8 | Step: 1350 | Avg. loss: 0.365 | lr: 5.0955988455988456e-05
Epoch: 8 | Step: 1400 | Avg. loss: 0.395 | lr: 5.0505050505050505e-05
Epoch: 8 | Step: 1450 | Avg. loss: 0.364 | lr: 5.0054112554112554e-05
Epoch: 8 | Step: 1500 | Avg. loss: 0.358 | lr: 4.96031746031746e-05
Epoch: 8 | Step: 1550 | Avg. loss: 0.367 | lr: 4.915223665223666e-05
Epoch: 8 | Step: 1600 | Avg. loss: 0.381 | lr: 4.870129870129871e-05
Epoch: 8 | Step: 1650 | Avg. loss: 0.382 | lr: 4.825036075036075e-05
Epoch: 8 | Step: 1700 | Avg. loss: 0.381 | lr: 4.77994227994228e-05
Epoch: 8 | Step: 1750 | Avg. loss: 0.381 | lr: 4.734848484848485e-05
Epoch: 8 | Step: 1800 | Avg. loss: 0.360 | lr: 4.68975468975469e-05
Epoch: 8 | Step: 1850 | Avg. loss: 0.341 | lr: 4.6446608946608947e-05
Epoch: 8 | Step: 1900 | Avg. loss: 0.365 | lr: 4.5995670995670996e-05
Epoch: 8 | Step: 1950 | Avg. loss: 0.387 | lr: 4.554473304473305e-05
Epoch: 8 | Step: 2000 | Avg. loss: 0.350 | lr: 4.5093795093795094e-05
Saving model with test loss of 2.948
Epoch: 8 | Step: 2050 | Avg. loss: 0.359 | lr: 4.464285714285714e-05
Epoch: 8 | Step: 2100 | Avg. loss: 0.350 | lr: 4.419191919191919e-05
Epoch: 8 | Step: 2150 | Avg. loss: 0.347 | lr: 4.374098124098124e-05
Epoch: 8 | Step: 2200 | Avg. loss: 0.356 | lr: 4.329004329004329e-05
Epoch: 8 | Step: 2250 | Avg. loss: 0.398 | lr: 4.283910533910534e-05
Epoch: 8 | Step: 2300 | Avg. loss: 0.359 | lr: 4.2388167388167395e-05
Epoch: 8 | Step: 2350 | Avg. loss: 0.368 | lr: 4.193722943722944e-05
Epoch: 8 | Step: 2400 | Avg. loss: 0.346 | lr: 4.1486291486291486e-05
Epoch: 8 | Step: 2450 | Avg. loss: 0.347 | lr: 4.1035353535353535e-05
Epoch: 8 | Step: 2500 | Avg. loss: 0.348 | lr: 4.0584415584415584e-05
Epoch: 8 | Step: 2550 | Avg. loss: 0.344 | lr: 4.0133477633477633e-05
Epoch: 8 | Step: 2600 | Avg. loss: 0.346 | lr: 3.968253968253968e-05
Epoch: 8 | Step: 2650 | Avg. loss: 0.365 | lr: 3.923160173160173e-05
Epoch: 8 | Step: 2700 | Avg. loss: 0.361 | lr: 3.878066378066379e-05
Epoch: 8 | Step: 2750 | Avg. loss: 0.340 | lr: 3.832972582972583e-05
Epoch: 8 | Step: 2800 | Avg. loss: 0.343 | lr: 3.787878787878788e-05
Epoch: 8 | Step: 2850 | Avg. loss: 0.363 | lr: 3.742784992784993e-05
Epoch: 8 | Step: 2900 | Avg. loss: 0.336 | lr: 3.697691197691198e-05
Epoch: 8 | Step: 2950 | Avg. loss: 0.367 | lr: 3.6525974025974026e-05
Epoch: 8 | Step: 3000 | Avg. loss: 0.340 | lr: 3.6075036075036075e-05
Saving model with test loss of 3.013
Epoch: 8 | Step: 3050 | Avg. loss: 0.361 | lr: 3.562409812409813e-05
Epoch: 8 | Step: 3100 | Avg. loss: 0.359 | lr: 3.517316017316017e-05
Epoch: 8 | Step: 3150 | Avg. loss: 0.374 | lr: 3.472222222222222e-05
Epoch: 8 | Step: 3200 | Avg. loss: 0.353 | lr: 3.427128427128427e-05
Epoch: 8 | Step: 3250 | Avg. loss: 0.356 | lr: 3.382034632034632e-05
Epoch: 8 | Step: 3300 | Avg. loss: 0.341 | lr: 3.336940836940837e-05
Epoch: 8 | Step: 3350 | Avg. loss: 0.331 | lr: 3.291847041847042e-05
Epoch: 8 | Step: 3400 | Avg. loss: 0.346 | lr: 3.246753246753247e-05
Epoch: 8 | Step: 3450 | Avg. loss: 0.340 | lr: 3.201659451659452e-05
Epoch: 8 | Step: 3500 | Avg. loss: 0.337 | lr: 3.1565656565656566e-05
Epoch: 8 | Step: 3550 | Avg. loss: 0.311 | lr: 3.1114718614718615e-05
Epoch: 8 | Step: 3600 | Avg. loss: 0.346 | lr: 3.0663780663780664e-05
Epoch: 8 | Step: 3650 | Avg. loss: 0.356 | lr: 3.0212842712842713e-05
Epoch: 8 | Step: 3700 | Avg. loss: 0.306 | lr: 2.9761904761904762e-05
Epoch: 8 | Step: 3750 | Avg. loss: 0.340 | lr: 2.931096681096681e-05
Epoch: 8 | Step: 3800 | Avg. loss: 0.330 | lr: 2.886002886002886e-05
Epoch: 8 | Step: 3850 | Avg. loss: 0.308 | lr: 2.840909090909091e-05
Epoch: 8 | Step: 3900 | Avg. loss: 0.332 | lr: 2.795815295815296e-05
Epoch: 8 | Step: 3950 | Avg. loss: 0.359 | lr: 2.7507215007215007e-05
Epoch: 8 | Step: 4000 | Avg. loss: 0.339 | lr: 2.7056277056277056e-05
Saving model with test loss of 3.042
Epoch: 8 | Step: 4050 | Avg. loss: 0.309 | lr: 2.6605339105339105e-05
Epoch: 8 | Step: 4100 | Avg. loss: 0.321 | lr: 2.6154401154401158e-05
Epoch: 8 | Step: 4150 | Avg. loss: 0.335 | lr: 2.5703463203463203e-05
Epoch: 8 | Step: 4200 | Avg. loss: 0.337 | lr: 2.5252525252525253e-05
Epoch: 8 | Step: 4250 | Avg. loss: 0.335 | lr: 2.48015873015873e-05
Epoch: 8 | Step: 4300 | Avg. loss: 0.326 | lr: 2.4350649350649354e-05
Epoch: 8 | Step: 4350 | Avg. loss: 0.330 | lr: 2.38997113997114e-05
Epoch: 8 | Step: 4400 | Avg. loss: 0.307 | lr: 2.344877344877345e-05
Epoch: 8 | Step: 4450 | Avg. loss: 0.331 | lr: 2.2997835497835498e-05
Epoch: 8 | Step: 4500 | Avg. loss: 0.322 | lr: 2.2546897546897547e-05
Epoch: 8 | Step: 4550 | Avg. loss: 0.366 | lr: 2.2095959595959596e-05
Epoch: 8 | Step: 4600 | Avg. loss: 0.371 | lr: 2.1645021645021645e-05
Epoch: 8 | Step: 4650 | Avg. loss: 0.353 | lr: 2.1194083694083697e-05
Epoch: 8 | Step: 4700 | Avg. loss: 0.336 | lr: 2.0743145743145743e-05
Epoch: 8 | Step: 4750 | Avg. loss: 0.335 | lr: 2.0292207792207792e-05
Epoch: 8 | Step: 4800 | Avg. loss: 0.358 | lr: 1.984126984126984e-05
Epoch: 8 | Step: 4850 | Avg. loss: 0.345 | lr: 1.9390331890331894e-05
Epoch: 8 | Step: 4900 | Avg. loss: 0.319 | lr: 1.893939393939394e-05
Epoch: 8 | Step: 4950 | Avg. loss: 0.331 | lr: 1.848845598845599e-05
Epoch: 8 | Step: 5000 | Avg. loss: 0.328 | lr: 1.8037518037518038e-05
Saving model with test loss of 3.082
Epoch: 8 | Step: 5050 | Avg. loss: 0.316 | lr: 1.7586580086580087e-05
Epoch: 8 | Step: 5100 | Avg. loss: 0.331 | lr: 1.7135642135642136e-05
Epoch: 8 | Step: 5150 | Avg. loss: 0.312 | lr: 1.6684704184704185e-05
Epoch: 8 | Step: 5200 | Avg. loss: 0.323 | lr: 1.6233766233766234e-05
Epoch: 8 | Step: 5250 | Avg. loss: 0.336 | lr: 1.5782828282828283e-05
Epoch: 8 | Step: 5300 | Avg. loss: 0.325 | lr: 1.5331890331890332e-05
Epoch: 8 | Step: 5350 | Avg. loss: 0.304 | lr: 1.4880952380952381e-05
Epoch: 8 | Step: 5400 | Avg. loss: 0.345 | lr: 1.443001443001443e-05
Epoch: 8 | Step: 5450 | Avg. loss: 0.332 | lr: 1.397907647907648e-05
Epoch: 8 | Step: 5500 | Avg. loss: 0.326 | lr: 1.3528138528138528e-05
Epoch: 8 | Step: 5550 | Avg. loss: 0.347 | lr: 1.3077200577200579e-05
Epoch: 8 | Step: 5600 | Avg. loss: 0.333 | lr: 1.2626262626262626e-05
Epoch: 8 | Step: 5650 | Avg. loss: 0.326 | lr: 1.2175324675324677e-05
Epoch: 8 | Step: 5700 | Avg. loss: 0.319 | lr: 1.1724386724386724e-05
Epoch: 8 | Step: 5750 | Avg. loss: 0.344 | lr: 1.1273448773448773e-05
Epoch: 8 | Step: 5800 | Avg. loss: 0.323 | lr: 1.0822510822510823e-05
Epoch: 8 | Step: 5850 | Avg. loss: 0.336 | lr: 1.0371572871572872e-05
Epoch: 8 | Step: 5900 | Avg. loss: 0.338 | lr: 9.92063492063492e-06
Epoch: 8 | Step: 5950 | Avg. loss: 0.317 | lr: 9.46969696969697e-06
Epoch: 8 | Step: 6000 | Avg. loss: 0.328 | lr: 9.018759018759019e-06
Saving model with test loss of 3.087
Epoch: 8 | Step: 6050 | Avg. loss: 0.337 | lr: 8.567821067821068e-06
Epoch: 8 | Step: 6100 | Avg. loss: 0.346 | lr: 8.116883116883117e-06
Epoch: 8 | Step: 6150 | Avg. loss: 0.341 | lr: 7.665945165945166e-06
Epoch: 8 | Step: 6200 | Avg. loss: 0.351 | lr: 7.215007215007215e-06
Epoch: 8 | Step: 6250 | Avg. loss: 0.361 | lr: 6.764069264069264e-06
Epoch: 8 | Step: 6300 | Avg. loss: 0.320 | lr: 6.313131313131313e-06
Epoch: 8 | Step: 6350 | Avg. loss: 0.331 | lr: 5.862193362193362e-06
Epoch: 8 | Step: 6400 | Avg. loss: 0.319 | lr: 5.411255411255411e-06
Epoch: 8 | Step: 6450 | Avg. loss: 0.334 | lr: 4.96031746031746e-06
Epoch: 8 | Step: 6500 | Avg. loss: 0.353 | lr: 4.509379509379509e-06
Epoch: 8 | Step: 6550 | Avg. loss: 0.341 | lr: 4.0584415584415584e-06
Epoch: 8 | Step: 6600 | Avg. loss: 0.326 | lr: 3.6075036075036075e-06
Epoch: 8 | Step: 6650 | Avg. loss: 0.324 | lr: 3.1565656565656566e-06
Epoch: 8 | Step: 6700 | Avg. loss: 0.338 | lr: 2.7056277056277056e-06
Epoch: 8 | Step: 6750 | Avg. loss: 0.322 | lr: 2.2546897546897547e-06
Epoch: 8 | Step: 6800 | Avg. loss: 0.326 | lr: 1.8037518037518038e-06
Epoch: 8 | Step: 6850 | Avg. loss: 0.331 | lr: 1.3528138528138528e-06
Epoch: 8 | Step: 6900 | Avg. loss: 0.344 | lr: 9.018759018759019e-07
Epoch: 8 | Step: 6950 | Avg. loss: 0.345 | lr: 4.5093795093795094e-07
Epoch: 8 | Step: 7000 | Avg. loss: 0.337 | lr: 0.0
Saving model with test loss of 3.059
TIME_fine_tuning_4: 4505.39 seconds
/storage/ice1/1/2/spadmanabha3/satkp/BigData/LLM/conda/LLM_test/lib/python3.9/site-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(
Raw input text:     
Translated text: Wait without asking yourselves to enter the name of law
{'en': 'This release issued at 1315 hrs.', 'hi': '  1315    '}
32000
{'en': 'This release issued at 1315 hrs.', 'hi': '  1315    '}
100
cuda
Map:   0%|          | 0/100 [00:00<?, ? examples/s]Processing batch 1
Map:  64%|   | 64/100 [00:01<00:00, 37.00 examples/s]Processing batch 2
Map: 100%|| 100/100 [00:02<00:00, 37.30 examples/s]Map: 100%|| 100/100 [00:02<00:00, 37.20 examples/s]
Original:   1315    
Translated: This release issued at 1315 hrs.
Reference: This release issued at 1315 hrs.

Original:               
Translated: Time estimates are drawn from the heavenly position of the stars.
Reference: The passage of time during nights is reckoned by having a look at the position of the stars above.

Original: (   ,   ,  , ,  , , ,,   , , ,  ,   )
Translated: In the field of Purabity, minimum standards of monopoly and epigraphis, procurement, administration, p
Reference: (In the field of Archaeology, Numismatics & Epigraphy, Pre History, Anthropology, Fine Arts, Conservation,  Publication, Administration, Finance & Accounts, Establishment, Civil, Legal matters, Stores & Purchase).

Original:                      
Translated: When innovative measures are not directly beneficial for others, they often stop them.
Reference: People often lose interest in egalitarian measures when such measures do not directly benefit them.

Original:  ,    . '' 
Translated: He wanted to have a merchant.  he remarked.
Reference: He said, 'Hero banna chahta hoon'. 

calculating scores...
computing bert embedding.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|       | 1/4 [00:00<00:00,  4.63it/s] 75%|  | 3/4 [00:00<00:00,  9.03it/s]100%|| 4/4 [00:00<00:00, 10.68it/s]
computing greedy matching.
  0%|          | 0/2 [00:00<?, ?it/s]100%|| 2/2 [00:00<00:00, 138.09it/s]
done in 0.39 seconds, 256.29 sentences/sec
Original:   1315    
Translated: This release issued at 1315 hrs.
Reference: This release issued at 1315 hrs.
BERTScore F1: 1.0000

Original:               
Translated: Time estimates are drawn from the heavenly position of the stars.
Reference: The passage of time during nights is reckoned by having a look at the position of the stars above.
BERTScore F1: 0.8970

Original: (   ,   ,  , ,  , , ,,   , , ,  ,   )
Translated: In the field of Purabity, minimum standards of monopoly and epigraphis, procurement, administration, p
Reference: (In the field of Archaeology, Numismatics & Epigraphy, Pre History, Anthropology, Fine Arts, Conservation,  Publication, Administration, Finance & Accounts, Establishment, Civil, Legal matters, Stores & Purchase).
BERTScore F1: 0.8392

Original:                      
Translated: When innovative measures are not directly beneficial for others, they often stop them.
Reference: People often lose interest in egalitarian measures when such measures do not directly benefit them.
BERTScore F1: 0.9026

Original:  ,    . '' 
Translated: He wanted to have a merchant.  he remarked.
Reference: He said, 'Hero banna chahta hoon'. 
BERTScore F1: 0.8443

Original:               
Translated: For work in Noord - Loire, Please write these:
Reference: 33. For work permits to work in Northern Ireland, please write to: 33
BERTScore F1: 0.8625

Original:            
Translated: They became farmers but did not give degrees.
Reference: They emerged as cultivators, but were denied twice - born status.
BERTScore F1: 0.8932

Original: % s  
Translated: % s authentication failed as authentication failed
Reference: % s authentication failed
BERTScore F1: 0.9463

Original:  - 209, - , 1961-2018
Translated: Section - 209, Income-tax Act, 1961-2018
Reference: Section - 209, Income-tax Act, 1961-2018
BERTScore F1: 1.0000

Original:     . 
Translated: All these summonses were given to the Deputy Commissioner.
Reference: the duties of the rich to the poor and the poor to the rich.
BERTScore F1: 0.8548

Original:  (  )    -   
Translated: Mozilla Firefox is based on Simanski (Mozilla) earlier.
Reference: CIM Key (past in Mozilla) based on mozilla fire box browsing software.
BERTScore F1: 0.8538

Original:       
Translated: Which is associated with the agricultural land.
Reference: Relating to agriculture land.
BERTScore F1: 0.8953

Original:  ,       . 
Translated: But no, CRISC app could not be launched.
Reference: Darn, the kiosk application could not be launched.
BERTScore F1: 0.9276

Original:        
Translated: Skins are a plant of family Euphorbiaceae with dyare specimens.
Reference: A plant of family Euphorbiaceae with brightly colored foliage.
BERTScore F1: 0.9128

Original:             10  . 
Translated: railways contracts had been made when the rate of exchange was 10 pt.
Reference: The railway contracts were made when the exchange was at Is 10d.
BERTScore F1: 0.9213

Original:      
Translated: Charles Simmons, with his efforts, proved to be one of the most despicable and distinction points
Reference: Charlie Simpson helped to raise
BERTScore F1: 0.8457

Original:        
Translated: Please accept my heartfelt congratulations and best wishes.
Reference: Please accept my hearty congratulations and best wishes.
BERTScore F1: 0.9898

Original:     ,         , -              
Translated: The book, which is briefly - inspired by the Rajbhasha and even today - 
Reference: This book- part autobiography, part a conservationists handbook and part travelogue- traces the course of wildlife from the princely and British era to the present.
BERTScore F1: 0.8397

Original:     ()                 
Translated: Do you consider (Allah) the most wicked is He who has His treasuries and has none
Reference: Do you call upon Ba 'l and leave the best of creators -
BERTScore F1: 0.8297

Original:         
Translated: As he came to know from the later experiments.
Reference: A battery of thirty drag ovens was added a little later.
BERTScore F1: 0.8677

Original:  :      
Translated: . UNEP Project: Streciation of public administration and governance;
Reference: UNDP Project: Strengthening Public Administration and Governance.
BERTScore F1: 0.8807

Original:    , 50              
Translated: The first claim from this relief has been signed few weeks in advance.
Reference: The first tranche - of 50 million US Dollars of this grant - was handed over a few weeks ago.
BERTScore F1: 0.8934

Original:       
Translated: And when the eyes are wrinkled forth, - - then - - they 
Reference: But when sight is confounded
BERTScore F1: 0.8413

Original:                    
Translated: In certain cases, special provision for entire value of capital for transfer of assets other than capital assets.
Reference: Special provision for full value of consideration for transfer of assets other than capital assets in certain cases.
BERTScore F1: 0.9476

Original:                    . 
Translated: From the point of view, jurisdiction of matters was not based on worth of crime.
Reference: Cases were not classified for jurisdiction according to either the seriousness of the offence or the value of the property involved.
BERTScore F1: 0.8686

Original:         
Translated: Something that works naturally
Reference: Something which functions naturally.
BERTScore F1: 0.9417

Original:            
Translated: These awards are a collective recognition for the utmost effort and hard work of your years.
Reference: These Awards are a recognition of your years of sincere effort and hard work.
BERTScore F1: 0.9558

Original:          . 
Translated: In such cases, the support assistance will not be available from PODF in any cases either through 
Reference: In such a case, the grant support from PODF is not available.
BERTScore F1: 0.9322

Original:     . 
Translated: The default height of the Composer Window.
Reference: Default height of the Composer Window.
BERTScore F1: 0.9780

Original:     ,  ,                    ; 
Translated: Granting of adequate remunerative staff, as set out for theoretical and practical training; and
Reference: To provide adequate instructional staff, possessing such qualifications as may be prescribed, for imparting practical and theoretical training and facilities for trade test of apprentices; and
BERTScore F1: 0.8798

Original:    ,         -  . 
Translated: These include the units of the hill stove, bamboo huts and other well - kept 
Reference: At these brisk sales there are woollen shawls and sheets, bamboo and other handicraft goods.
BERTScore F1: 0.8440

Original:    ,              
Translated: Mental or emotional indifference is an attribute of lack of enthusiasm or enthusiasm
Reference: a mental or emotional depression, characterized by low level of enthusiasm or eagerness for activity
BERTScore F1: 0.8819

Original:     % s
Translated: Failed to create child process:% s < / s > Failed to create child process
Reference: Failed to create child process'% s':% s'% s'
BERTScore F1: 0.8855

Original: LDAP     ... 
Translated: Reconnecting to LDAP server...
Reference: Reconnecting to LDAP server...
BERTScore F1: 1.0000

Original:                       -  
Translated: When news is brought to one of them, they fall in their bones and wait for a
Reference: When good news of the birth of a female is given to any of them, his face grows dark and inwardly he chokes.
BERTScore F1: 0.8918

Original:     . 
Translated: Invalid authentication response from server.
Reference: Bad authentication response from server.
BERTScore F1: 0.9992

Original:       
Translated: As far as he has been associated with it and followed them, they are bound to agree.
Reference: as between him and them
BERTScore F1: 0.8456

Original:   ,              ; 
Translated: So face the unbelievers a day when their dejections are severe (some) and
Reference: So leave them until they encounter the day when they will be thunderstruck,
BERTScore F1: 0.8533

Original:              -  ,      
Translated: The device produces a highly stratified goods and drives with it an economies like
Reference: The machine produces much too fast, and brings with it a sort of economic system which I cannot grasp.
BERTScore F1: 0.8899

Original:     ()        ? 
Translated: Or that the Unseen in it (the Quran) which they write down?
Reference: Or is the hidden with them, by which they pass judgements?
BERTScore F1: 0.8563

Original:                   ,          
Translated: Among the skilfully debated learned and author, Balvantrai Thakor, are better in regard to his
Reference: The fiery controversies between him and an equally firm - headed scholar and poet, Balawantrai Thakore, are well known to students of Gujarati literature.
BERTScore F1: 0.8546

Original:          
Translated: Specify the value of the color value for filter - wheel slots
Reference: Assign color values for your filter wheel slots
BERTScore F1: 0.9352

Original:            -
Translated: You are provided two types of options for NPS investment: -
Reference: The NPS offers two approaches to invest subscribers money:
BERTScore F1: 0.9087

Original: , , , , ,             . 
Translated: Suggested government grievances covering electricity, water, waste, labour, etc. should be
Reference: For one, the stranglehold of the Government, which today controls power, water, fertiliser, seeds, wages and trade of agriculture, must be loosened.
BERTScore F1: 0.8655

Original: (    )                    
Translated: And they whose scales will be light, will be punished by Our command.
Reference: And those whose scales are light are the people who put themselves to ruin  the recompense of the injustice they used to do to Our signs.
BERTScore F1: 0.8773

Original:  1928                
Translated: From 1926 to 1928, Jawaharlal was served as General Secretary of All India Congress Committee. 1926
Reference: from 1926 to 1928, jawaharlal nehru served as the main representative of the all india national committee 1926
BERTScore F1: 0.9080

Original:      
Translated: dressed herself well, and she 'd rather be dressed up with her.
Reference: After a quick bath, they get into their best clothes.
BERTScore F1: 0.8450

Original:    ,     , ,                 
Translated: They are universal people who atrophy our minds from fundamentalismos, dalliancer, oppressors and
Reference: They are universal men, who free ourminds from bigotry and superstition, dogma and ritual, and emphasise the central simplicities of religion.
BERTScore F1: 0.8527

Original:         , ,        
Translated: Conduct inspection, verification, surveillance and overall process related submitted policy.
Reference: Revised draft Policy on Inspection, Verification, Monitoring and Overall Procedure Relating to Grant of Forest Clearances and Identification of Forests
BERTScore F1: 0.8828

Original:        
Translated: The proposals of the Rules are invited to invite further kommentarer of the stakeholders
Reference: Draft Recruitment Rules for comments from Stakeholders
BERTScore F1: 0.8510

Original:  -      
Translated: Measure in full, pure expenses, and do not be of the deserved 
Reference: Give full measure and do not cheat;
BERTScore F1: 0.8052

Original:            
Translated: The term Sujhaarishi occurred about two decades ago.
Reference: The term, Good Governance, appeared in the development lexicon about two decades back.
BERTScore F1: 0.8903

Original:          . 
Translated: The Mixed Haemorrhage refers to changes in the human gallows.
Reference: Mixed Albuminurai is related to the changes in the human kidney.
BERTScore F1: 0.8773

Original:            ,         /  
Translated: It has a widespread potential for increasing and upgrading the crops.
Reference: Considering the utility and food value of various palm products, there is immense potential / scope for further growth and development.
BERTScore F1: 0.8871

Original:    ,    .             . 
Translated: Something went wrong, while loading this page. Please go to a different page to continue.
Reference: Something went wrong while displaying this page. Please reload or visit a different page to continue.
BERTScore F1: 0.9582

Original:      '92      1994    . 
Translated: The share bond which the Ambani Ghani aunty was released in December 1994.
Reference: The share warrants issued to the Ambanis in December 1992 were actually allotted to them in 1994.
BERTScore F1: 0.8805

Original:                   
Translated: The choice of books included therewith has been seriously done in this respect.
Reference: Those recommended here are chosen with care and definite purpose.
BERTScore F1: 0.8743

Original:              , ,   , ,        
Translated: Our country will benefit from INSR application which includes spatial, marine landing, vehicle management, etc.
Reference: The nation will immensely benefit from the applications of IRNSS which include terrestrial, aerial and marine navigation, disaster management, vehicle tracking and fleet management etc.
BERTScore F1: 0.9288

Original:  URL  
Translated: Remove the file URL:
Reference: File / URL to Remove:
BERTScore F1: 0.8806

Original:           /           
Translated: The State Governments / UTs are asked to pass periodical information by the Education Department of Govt.
Reference: The State Government / UT is also required to submit periodic returns to the Department of School Education and Literacy, Government of India to provide information on:
BERTScore F1: 0.9113

Original: 50                  
Translated: After 50 years of tireless imprint, Costa Rica has taken an extraordinarily good fare.
Reference: More than 50 years later, Costa Rica is still seeing the benefits of this enlightened position.
BERTScore F1: 0.8864

Original:  "         "-              
Translated: "And do good deeds; verily I shall see what you used to do.
Reference: Saying: "Make you perfect coats of mail, balancing well the rings of chain armour, and work you (men) righteousness. Truly, I am AllSeer of what you do."
BERTScore F1: 0.8461

Original:                  
Translated: forward from the recess and you can write a signal here and you can write a text
Reference: flip the slide back and forth and you have a pointer and you can type text on the
BERTScore F1: 0.8810

Original:  ,      , 
Translated: This Orchid is called Orchid - Orchid - This is called Orchid -
Reference: This orchid, known as Darwin 's orchid,
BERTScore F1: 0.8598

Original:       
Translated: Please include commission on sale of laceiries and commission on purchase of laceiries.
Reference: Commission, etc., on the sale of lottery tickets.
BERTScore F1: 0.8594

Original: . 5/4/2011-. . ()  14-07-2011
Translated: No. 5 / 4 / 2011 - Ralbal (Service) Date 14 - 07 - 2011
Reference: No. 5 / 4 / 20ll - Ralbal (Service) Date 14 - 07 - 2011
BERTScore F1: 0.9673

Original:                     . 
Translated: For jihad in In Laden, the International Intellectual Reserve of America and Israel, one hundred of ethnic
Reference: Bin Laden 's International Islamic Front for Jehad against the US and Israel brings together nearly a dozen Islamic terrorist groups.
BERTScore F1: 0.8270

Original:     3
Translated: Google Talk Work Name 3
Reference: Google Talk Work Name 3
BERTScore F1: 1.0000

Original:     
Translated: IFCI's contributing to the economy and contributes to the economy of Nepal, according to
Reference: IFCI 's ECONOMIC CONTRIBUTION
BERTScore F1: 0.8339

Original:   , 1953
Translated: The Collections of Statistics Act, 1953 was mooted in all the works of the Collections Act and the Act that contain
Reference: The Collections of Statistics Act, 1953
BERTScore F1: 0.8867

Original:    -    
Translated: His notable authors will remain for ever in the country.
Reference: Their unknown authors came from all over the country.
BERTScore F1: 0.9030

Original:              
Translated: When a child has fever or exaggeration, it is considered worthy of a gift to
Reference: It is especially useful when the child has fever and diarrhoea.
BERTScore F1: 0.8780

Original:          
Translated: The cost will be levied within the Court within four working days.
Reference: The costs shall be deposited in the Court within four weeks.
BERTScore F1: 0.9323

Original:              
Translated: The process of bringing some change in economic matters.
Reference: To make something different in economic matters or a process of change in economic matters.
BERTScore F1: 0.9110

Original:                       
Translated: Mr. Suratand Gauhar was charged with the Ministry of Chemicals and Fertilizers and
Reference: SHRI D. V. SADANANDA GOWDA AND SHRI NARENDRA SINGH TOMAR GETS ADDITIONAL CHARGE OF THE MINISTRY OF CHEMICALS &amp; FERTILIZERS AND THE MINISTRY OF PARLIAMENTARY AFFAIRS RESPECTIVELY
BERTScore F1: 0.8218

Original:                      
Translated: It provides for reducing damage for comparatively lower costs and for incurring cases of fatal
Reference: It provides for risk cover at a comparatively low cost and relief for disability arising due to accident or illness.
BERTScore F1: 0.8842

Original:    21 
Translated: And the thing that 's going on is 21, and it' s 21 - prostrate.
Reference: And that 's twenty - one.
BERTScore F1: 0.8785

Original:              
Translated: And it 's a basic factor as to the basic reason for us think that age is
Reference: And the fundamental reason, I think, why we feel that aging is inevitable
BERTScore F1: 0.8834

Original:             
Translated: Practice as well as effective check in this area for appropriate and effective detection.
Reference: To devise suitable and effective check-point for this purpose.
BERTScore F1: 0.8961

Original:    
Translated: The automobile industry in India has become one of the biggest losers in the transport industry across India.
Reference: Automotive industry in India
BERTScore F1: 0.8985

Original:       . 
Translated: Send selected contacts to another person
Reference: Send selected contacts to another person
BERTScore F1: 1.0000

Original:     
Translated: Wooden belt was factory de - manufactured wooden belt.
Reference: Wooden Marker is developed.
BERTScore F1: 0.8581

Original:              
Translated: A solid external membrane which covers the palp with the entire eye, shrinking with the turbid
Reference: a tough, white, outer layer of the eye covering all the eyeball except cornea
BERTScore F1: 0.8753

Original:               ? 
Translated: Where even after large technological changes people are filming?
Reference: full of innovative people making films despite great technical odds?
BERTScore F1: 0.8832

Original:     -     
Translated: They help you green out and clean your environment.
Reference: They keep your environment green and healthy
BERTScore F1: 0.9400

Original:    -            
Translated: Along with the causes of the lingh, the shrubs of the goose are seen
Reference: You can see the beautiful meadows and huts of the shepherds along this route.
BERTScore F1: 0.8640

Original:                       
Translated: These two songs became very popular and the dialogues were extremely popular between the directors and
Reference: These two songs became very popular and also Ralesh Khana the actor of the film including film director got huge popularty.
BERTScore F1: 0.8978

Original:                       , 2006     
Translated: The National Project for Rural Water Quality Improvement and Enforcement Programme was launched in February, 2006.
Reference: To further strengthen community participation in the drinking water sector for sustainability, National Rural Drinking Water Quality Monitoring & Surveillance programme has been launched in February, 2006
BERTScore F1: 0.9173

Original:       ,     
Translated: except the sincere worshipers of Allah.
Reference: except for God 's sincere servants;
BERTScore F1: 0.8873

Original:     (        ) 
Translated: Howe schemes in India (External website that opens in a new window)
Reference: EcomarkScheme of India (External website that opens in a new window)
BERTScore F1: 0.8594

Original:      ... 
Translated: View the details of the account...
Reference: Looking up account details...
BERTScore F1: 0.9217

Original:     RSS     
Translated: Display a RSS or item feed on your video.
Reference: Display a RSS or ATOM Feed on your video
BERTScore F1: 0.9532

Original:       -  ,       ! 
Translated: Those who hold God along with God they shall know.
Reference: Who set up along with Allah anot her god; presently they shall know.
BERTScore F1: 0.8806

Original:     
Translated: A set of reference related to medication.
Reference: A collection related to drugs.
BERTScore F1: 0.9252

Original:   1.0   (c) 2002  .  http:// www. reallyslick. com/     
Translated: SpamAssassin - 0. 0 server (c) 2002 Written by Scarlett M. Wills http
Reference: Solar Winds 1. 0 Copyright (c) 2002 Terence M. Welsh http: / / www. reallyslick. com / Ported to KDE by Karl Robillard
BERTScore F1: 0.8585

Original:      1000       
Translated: He said the State has already constructed 1000 km of new rail lines.
Reference: He added another 1000 km of new rail lines are under construction.
BERTScore F1: 0.9523

Original:        ,              
Translated: Instead of co - operative medication, it is not taken as magical pill.
Reference: The rasayana therapy therefore cannot be capsulated into a sort of magic pill and taken without paying heed to the concomitant therapies.
BERTScore F1: 0.8582

Original:          
Translated: CLICK HERE to change your name or color
Reference: Click here to change your name and / or color
BERTScore F1: 0.9605

Original:             
Translated: Calculating interest rate increases very heavily from monthly expenses.
Reference: Monthly installments increases more because of compound interst.
BERTScore F1: 0.8582

Original:   -     
Translated: sex and foreign sexual connections are carried out
Reference: Orogenital sex is being performed.
BERTScore F1: 0.8834

Average BERTScore F1: 0.8943
Average BLEU score: 0.1967
Original:   1315    
Translated: This release issued at 1315 hrs.
Reference: This release issued at 1315 hrs.
BLEU score: 1.0000

Original:               
Translated: Time estimates are drawn from the heavenly position of the stars.
Reference: The passage of time during nights is reckoned by having a look at the position of the stars above.
BLEU score: 0.1003

Original: (   ,   ,  , ,  , , ,,   , , ,  ,   )
Translated: In the field of Purabity, minimum standards of monopoly and epigraphis, procurement, administration, p
Reference: (In the field of Archaeology, Numismatics & Epigraphy, Pre History, Anthropology, Fine Arts, Conservation,  Publication, Administration, Finance & Accounts, Establishment, Civil, Legal matters, Stores & Purchase).
BLEU score: 0.0218

Original:                      
Translated: When innovative measures are not directly beneficial for others, they often stop them.
Reference: People often lose interest in egalitarian measures when such measures do not directly benefit them.
BLEU score: 0.0926

Original:  ,    . '' 
Translated: He wanted to have a merchant.  he remarked.
Reference: He said, 'Hero banna chahta hoon'. 
BLEU score: 0.0971

Original:               
Translated: For work in Noord - Loire, Please write these:
Reference: 33. For work permits to work in Northern Ireland, please write to: 33
BLEU score: 0.0551

Original:            
Translated: They became farmers but did not give degrees.
Reference: They emerged as cultivators, but were denied twice - born status.
BLEU score: 0.0338

Original: % s  
Translated: % s authentication failed as authentication failed
Reference: % s authentication failed
BLEU score: 0.5157

Original:  - 209, - , 1961-2018
Translated: Section - 209, Income-tax Act, 1961-2018
Reference: Section - 209, Income-tax Act, 1961-2018
BLEU score: 1.0000

Original:     . 
Translated: All these summonses were given to the Deputy Commissioner.
Reference: the duties of the rich to the poor and the poor to the rich.
BLEU score: 0.0381

Original:  (  )    -   
Translated: Mozilla Firefox is based on Simanski (Mozilla) earlier.
Reference: CIM Key (past in Mozilla) based on mozilla fire box browsing software.
BLEU score: 0.1204

Original:       
Translated: Which is associated with the agricultural land.
Reference: Relating to agriculture land.
BLEU score: 0.0528

Original:  ,       . 
Translated: But no, CRISC app could not be launched.
Reference: Darn, the kiosk application could not be launched.
BLEU score: 0.4605

Original:        
Translated: Skins are a plant of family Euphorbiaceae with dyare specimens.
Reference: A plant of family Euphorbiaceae with brightly colored foliage.
BLEU score: 0.4112

Original:             10  . 
Translated: railways contracts had been made when the rate of exchange was 10 pt.
Reference: The railway contracts were made when the exchange was at Is 10d.
BLEU score: 0.1967

Original:      
Translated: Charles Simmons, with his efforts, proved to be one of the most despicable and distinction points
Reference: Charlie Simpson helped to raise
BLEU score: 0.0133

Original:        
Translated: Please accept my heartfelt congratulations and best wishes.
Reference: Please accept my hearty congratulations and best wishes.
BLEU score: 0.8003

Original:     ,         , -              
Translated: The book, which is briefly - inspired by the Rajbhasha and even today - 
Reference: This book- part autobiography, part a conservationists handbook and part travelogue- traces the course of wildlife from the princely and British era to the present.
BLEU score: 0.0097

Original:     ()                 
Translated: Do you consider (Allah) the most wicked is He who has His treasuries and has none
Reference: Do you call upon Ba 'l and leave the best of creators -
BLEU score: 0.0330

Original:         
Translated: As he came to know from the later experiments.
Reference: A battery of thirty drag ovens was added a little later.
BLEU score: 0.0180

Original:  :      
Translated: . UNEP Project: Streciation of public administration and governance;
Reference: UNDP Project: Strengthening Public Administration and Governance.
BLEU score: 0.0934

Original:    , 50              
Translated: The first claim from this relief has been signed few weeks in advance.
Reference: The first tranche - of 50 million US Dollars of this grant - was handed over a few weeks ago.
BLEU score: 0.1036

Original:       
Translated: And when the eyes are wrinkled forth, - - then - - they 
Reference: But when sight is confounded
BLEU score: 0.0289

Original:                    
Translated: In certain cases, special provision for entire value of capital for transfer of assets other than capital assets.
Reference: Special provision for full value of consideration for transfer of assets other than capital assets in certain cases.
BLEU score: 0.4633

Original:                    . 
Translated: From the point of view, jurisdiction of matters was not based on worth of crime.
Reference: Cases were not classified for jurisdiction according to either the seriousness of the offence or the value of the property involved.
BLEU score: 0.0283

Original:         
Translated: Something that works naturally
Reference: Something which functions naturally.
BLEU score: 0.0834

Original:            
Translated: These awards are a collective recognition for the utmost effort and hard work of your years.
Reference: These Awards are a recognition of your years of sincere effort and hard work.
BLEU score: 0.3338

Original:          . 
Translated: In such cases, the support assistance will not be available from PODF in any cases either through 
Reference: In such a case, the grant support from PODF is not available.
BLEU score: 0.1129

Original:     . 
Translated: The default height of the Composer Window.
Reference: Default height of the Composer Window.
BLEU score: 0.6989

Original:     ,  ,                    ; 
Translated: Granting of adequate remunerative staff, as set out for theoretical and practical training; and
Reference: To provide adequate instructional staff, possessing such qualifications as may be prescribed, for imparting practical and theoretical training and facilities for trade test of apprentices; and
BLEU score: 0.0647

Original:    ,         -  . 
Translated: These include the units of the hill stove, bamboo huts and other well - kept 
Reference: At these brisk sales there are woollen shawls and sheets, bamboo and other handicraft goods.
BLEU score: 0.0648

Original:    ,              
Translated: Mental or emotional indifference is an attribute of lack of enthusiasm or enthusiasm
Reference: a mental or emotional depression, characterized by low level of enthusiasm or eagerness for activity
BLEU score: 0.3347

Original:     % s
Translated: Failed to create child process:% s < / s > Failed to create child process
Reference: Failed to create child process'% s':% s'% s'
BLEU score: 0.3009

Original: LDAP     ... 
Translated: Reconnecting to LDAP server...
Reference: Reconnecting to LDAP server...
BLEU score: 1.0000

Original:                       -  
Translated: When news is brought to one of them, they fall in their bones and wait for a
Reference: When good news of the birth of a female is given to any of them, his face grows dark and inwardly he chokes.
BLEU score: 0.0639

Original:     . 
Translated: Invalid authentication response from server.
Reference: Bad authentication response from server.
BLEU score: 0.6804

Original:       
Translated: As far as he has been associated with it and followed them, they are bound to agree.
Reference: as between him and them
BLEU score: 0.0164

Original:   ,              ; 
Translated: So face the unbelievers a day when their dejections are severe (some) and
Reference: So leave them until they encounter the day when they will be thunderstruck,
BLEU score: 0.0688

Original:              -  ,      
Translated: The device produces a highly stratified goods and drives with it an economies like
Reference: The machine produces much too fast, and brings with it a sort of economic system which I cannot grasp.
BLEU score: 0.0702

Original:     ()        ? 
Translated: Or that the Unseen in it (the Quran) which they write down?
Reference: Or is the hidden with them, by which they pass judgements?
BLEU score: 0.1507

Original:                   ,          
Translated: Among the skilfully debated learned and author, Balvantrai Thakor, are better in regard to his
Reference: The fiery controversies between him and an equally firm - headed scholar and poet, Balawantrai Thakore, are well known to students of Gujarati literature.
BLEU score: 0.0169

Original:          
Translated: Specify the value of the color value for filter - wheel slots
Reference: Assign color values for your filter wheel slots
BLEU score: 0.1037

Original:            -
Translated: You are provided two types of options for NPS investment: -
Reference: The NPS offers two approaches to invest subscribers money:
BLEU score: 0.0450

Original: , , , , ,             . 
Translated: Suggested government grievances covering electricity, water, waste, labour, etc. should be
Reference: For one, the stranglehold of the Government, which today controls power, water, fertiliser, seeds, wages and trade of agriculture, must be loosened.
BLEU score: 0.0420

Original: (    )                    
Translated: And they whose scales will be light, will be punished by Our command.
Reference: And those whose scales are light are the people who put themselves to ruin  the recompense of the injustice they used to do to Our signs.
BLEU score: 0.0664

Original:  1928                
Translated: From 1926 to 1928, Jawaharlal was served as General Secretary of All India Congress Committee. 1926
Reference: from 1926 to 1928, jawaharlal nehru served as the main representative of the all india national committee 1926
BLEU score: 0.1634

Original:      
Translated: dressed herself well, and she 'd rather be dressed up with her.
Reference: After a quick bath, they get into their best clothes.
BLEU score: 0.0172

Original:    ,     , ,                 
Translated: They are universal people who atrophy our minds from fundamentalismos, dalliancer, oppressors and
Reference: They are universal men, who free ourminds from bigotry and superstition, dogma and ritual, and emphasise the central simplicities of religion.
BLEU score: 0.0836

Original:         , ,        
Translated: Conduct inspection, verification, surveillance and overall process related submitted policy.
Reference: Revised draft Policy on Inspection, Verification, Monitoring and Overall Procedure Relating to Grant of Forest Clearances and Identification of Forests
BLEU score: 0.0307

Original:        
Translated: The proposals of the Rules are invited to invite further kommentarer of the stakeholders
Reference: Draft Recruitment Rules for comments from Stakeholders
BLEU score: 0.0375

Original:  -      
Translated: Measure in full, pure expenses, and do not be of the deserved 
Reference: Give full measure and do not cheat;
BLEU score: 0.0642

Original:            
Translated: The term Sujhaarishi occurred about two decades ago.
Reference: The term, Good Governance, appeared in the development lexicon about two decades back.
BLEU score: 0.1333

Original:          . 
Translated: The Mixed Haemorrhage refers to changes in the human gallows.
Reference: Mixed Albuminurai is related to the changes in the human kidney.
BLEU score: 0.2254

Original:            ,         /  
Translated: It has a widespread potential for increasing and upgrading the crops.
Reference: Considering the utility and food value of various palm products, there is immense potential / scope for further growth and development.
BLEU score: 0.0485

Original:    ,    .             . 
Translated: Something went wrong, while loading this page. Please go to a different page to continue.
Reference: Something went wrong while displaying this page. Please reload or visit a different page to continue.
BLEU score: 0.5420

Original:      '92      1994    . 
Translated: The share bond which the Ambani Ghani aunty was released in December 1994.
Reference: The share warrants issued to the Ambanis in December 1992 were actually allotted to them in 1994.
BLEU score: 0.0850

Original:                   
Translated: The choice of books included therewith has been seriously done in this respect.
Reference: Those recommended here are chosen with care and definite purpose.
BLEU score: 0.0157

Original:              , ,   , ,        
Translated: Our country will benefit from INSR application which includes spatial, marine landing, vehicle management, etc.
Reference: The nation will immensely benefit from the applications of IRNSS which include terrestrial, aerial and marine navigation, disaster management, vehicle tracking and fleet management etc.
BLEU score: 0.0311

Original:  URL  
Translated: Remove the file URL:
Reference: File / URL to Remove:
BLEU score: 0.0828

Original:           /           
Translated: The State Governments / UTs are asked to pass periodical information by the Education Department of Govt.
Reference: The State Government / UT is also required to submit periodic returns to the Department of School Education and Literacy, Government of India to provide information on:
BLEU score: 0.0758

Original: 50                  
Translated: After 50 years of tireless imprint, Costa Rica has taken an extraordinarily good fare.
Reference: More than 50 years later, Costa Rica is still seeing the benefits of this enlightened position.
BLEU score: 0.0802

Original:  "         "-              
Translated: "And do good deeds; verily I shall see what you used to do.
Reference: Saying: "Make you perfect coats of mail, balancing well the rings of chain armour, and work you (men) righteousness. Truly, I am AllSeer of what you do."
BLEU score: 0.0109

Original:                  
Translated: forward from the recess and you can write a signal here and you can write a text
Reference: flip the slide back and forth and you have a pointer and you can type text on the
BLEU score: 0.0982

Original:  ,      , 
Translated: This Orchid is called Orchid - Orchid - This is called Orchid -
Reference: This orchid, known as Darwin 's orchid,
BLEU score: 0.0357

Original:       
Translated: Please include commission on sale of laceiries and commission on purchase of laceiries.
Reference: Commission, etc., on the sale of lottery tickets.
BLEU score: 0.0356

Original: . 5/4/2011-. . ()  14-07-2011
Translated: No. 5 / 4 / 2011 - Ralbal (Service) Date 14 - 07 - 2011
Reference: No. 5 / 4 / 20ll - Ralbal (Service) Date 14 - 07 - 2011
BLEU score: 0.8483

Original:                     . 
Translated: For jihad in In Laden, the International Intellectual Reserve of America and Israel, one hundred of ethnic
Reference: Bin Laden 's International Islamic Front for Jehad against the US and Israel brings together nearly a dozen Islamic terrorist groups.
BLEU score: 0.0249

Original:     3
Translated: Google Talk Work Name 3
Reference: Google Talk Work Name 3
BLEU score: 1.0000

Original:     
Translated: IFCI's contributing to the economy and contributes to the economy of Nepal, according to
Reference: IFCI 's ECONOMIC CONTRIBUTION
BLEU score: 0.0393

Original:   , 1953
Translated: The Collections of Statistics Act, 1953 was mooted in all the works of the Collections Act and the Act that contain
Reference: The Collections of Statistics Act, 1953
BLEU score: 0.2849

Original:    -    
Translated: His notable authors will remain for ever in the country.
Reference: Their unknown authors came from all over the country.
BLEU score: 0.1186

Original:              
Translated: When a child has fever or exaggeration, it is considered worthy of a gift to
Reference: It is especially useful when the child has fever and diarrhoea.
BLEU score: 0.1206

Original:          
Translated: The cost will be levied within the Court within four working days.
Reference: The costs shall be deposited in the Court within four weeks.
BLEU score: 0.2770

Original:              
Translated: The process of bringing some change in economic matters.
Reference: To make something different in economic matters or a process of change in economic matters.
BLEU score: 0.2619

Original:                       
Translated: Mr. Suratand Gauhar was charged with the Ministry of Chemicals and Fertilizers and
Reference: SHRI D. V. SADANANDA GOWDA AND SHRI NARENDRA SINGH TOMAR GETS ADDITIONAL CHARGE OF THE MINISTRY OF CHEMICALS &amp; FERTILIZERS AND THE MINISTRY OF PARLIAMENTARY AFFAIRS RESPECTIVELY
BLEU score: 0.0033

Original:                      
Translated: It provides for reducing damage for comparatively lower costs and for incurring cases of fatal
Reference: It provides for risk cover at a comparatively low cost and relief for disability arising due to accident or illness.
BLEU score: 0.1242

Original:    21 
Translated: And the thing that 's going on is 21, and it' s 21 - prostrate.
Reference: And that 's twenty - one.
BLEU score: 0.1888

Original:              
Translated: And it 's a basic factor as to the basic reason for us think that age is
Reference: And the fundamental reason, I think, why we feel that aging is inevitable
BLEU score: 0.0365

Original:             
Translated: Practice as well as effective check in this area for appropriate and effective detection.
Reference: To devise suitable and effective check-point for this purpose.
BLEU score: 0.0579

Original:    
Translated: The automobile industry in India has become one of the biggest losers in the transport industry across India.
Reference: Automotive industry in India
BLEU score: 0.0562

Original:       . 
Translated: Send selected contacts to another person
Reference: Send selected contacts to another person
BLEU score: 1.0000

Original:     
Translated: Wooden belt was factory de - manufactured wooden belt.
Reference: Wooden Marker is developed.
BLEU score: 0.0491

Original:              
Translated: A solid external membrane which covers the palp with the entire eye, shrinking with the turbid
Reference: a tough, white, outer layer of the eye covering all the eyeball except cornea
BLEU score: 0.0355

Original:               ? 
Translated: Where even after large technological changes people are filming?
Reference: full of innovative people making films despite great technical odds?
BLEU score: 0.0228

Original:     -     
Translated: They help you green out and clean your environment.
Reference: They keep your environment green and healthy
BLEU score: 0.0812

Original:    -            
Translated: Along with the causes of the lingh, the shrubs of the goose are seen
Reference: You can see the beautiful meadows and huts of the shepherds along this route.
BLEU score: 0.0906

Original:                       
Translated: These two songs became very popular and the dialogues were extremely popular between the directors and
Reference: These two songs became very popular and also Ralesh Khana the actor of the film including film director got huge popularty.
BLEU score: 0.3284

Original:                       , 2006     
Translated: The National Project for Rural Water Quality Improvement and Enforcement Programme was launched in February, 2006.
Reference: To further strengthen community participation in the drinking water sector for sustainability, National Rural Drinking Water Quality Monitoring & Surveillance programme has been launched in February, 2006
BLEU score: 0.1256

Original:       ,     
Translated: except the sincere worshipers of Allah.
Reference: except for God 's sincere servants;
BLEU score: 0.0516

Original:     (        ) 
Translated: Howe schemes in India (External website that opens in a new window)
Reference: EcomarkScheme of India (External website that opens in a new window)
BLEU score: 0.6198

Original:      ... 
Translated: View the details of the account...
Reference: Looking up account details...
BLEU score: 0.0426

Original:     RSS     
Translated: Display a RSS or item feed on your video.
Reference: Display a RSS or ATOM Feed on your video
BLEU score: 0.4240

Original:       -  ,       ! 
Translated: Those who hold God along with God they shall know.
Reference: Who set up along with Allah anot her god; presently they shall know.
BLEU score: 0.3157

Original:     
Translated: A set of reference related to medication.
Reference: A collection related to drugs.
BLEU score: 0.1462

Original:   1.0   (c) 2002  .  http:// www. reallyslick. com/     
Translated: SpamAssassin - 0. 0 server (c) 2002 Written by Scarlett M. Wills http
Reference: Solar Winds 1. 0 Copyright (c) 2002 Terence M. Welsh http: / / www. reallyslick. com / Ported to KDE by Karl Robillard
BLEU score: 0.0725

Original:      1000       
Translated: He said the State has already constructed 1000 km of new rail lines.
Reference: He added another 1000 km of new rail lines are under construction.
BLEU score: 0.3807

Original:        ,              
Translated: Instead of co - operative medication, it is not taken as magical pill.
Reference: The rasayana therapy therefore cannot be capsulated into a sort of magic pill and taken without paying heed to the concomitant therapies.
BLEU score: 0.0167

Original:          
Translated: CLICK HERE to change your name or color
Reference: Click here to change your name and / or color
BLEU score: 0.2938

Original:             
Translated: Calculating interest rate increases very heavily from monthly expenses.
Reference: Monthly installments increases more because of compound interst.
BLEU score: 0.1025

Original:   -     
Translated: sex and foreign sexual connections are carried out
Reference: Orogenital sex is being performed.
BLEU score: 0.0257

Average ROUGE-1 F1 score: 0.4627
Average ROUGE-2 F1 score: 0.2592
Average ROUGE-L F1 score: 0.4287
Original:   1315    
Translated: This release issued at 1315 hrs.
Reference: This release issued at 1315 hrs.
ROUGE-1 F1 score: 1.0000
ROUGE-2 F1 score: 1.0000
ROUGE-L F1 score: 1.0000

Original:               
Translated: Time estimates are drawn from the heavenly position of the stars.
Reference: The passage of time during nights is reckoned by having a look at the position of the stars above.
ROUGE-1 F1 score: 0.4000
ROUGE-2 F1 score: 0.2143
ROUGE-L F1 score: 0.4000

Original: (   ,   ,  , ,  , , ,,   , , ,  ,   )
Translated: In the field of Purabity, minimum standards of monopoly and epigraphis, procurement, administration, p
Reference: (In the field of Archaeology, Numismatics & Epigraphy, Pre History, Anthropology, Fine Arts, Conservation,  Publication, Administration, Finance & Accounts, Establishment, Civil, Legal matters, Stores & Purchase).
ROUGE-1 F1 score: 0.3243
ROUGE-2 F1 score: 0.1714
ROUGE-L F1 score: 0.3243

Original:                      
Translated: When innovative measures are not directly beneficial for others, they often stop them.
Reference: People often lose interest in egalitarian measures when such measures do not directly benefit them.
ROUGE-1 F1 score: 0.4286
ROUGE-2 F1 score: 0.0769
ROUGE-L F1 score: 0.3571

Original:  ,    . '' 
Translated: He wanted to have a merchant.  he remarked.
Reference: He said, 'Hero banna chahta hoon'. 
ROUGE-1 F1 score: 0.1429
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.1429

Original:               
Translated: For work in Noord - Loire, Please write these:
Reference: 33. For work permits to work in Northern Ireland, please write to: 33
ROUGE-1 F1 score: 0.4762
ROUGE-2 F1 score: 0.3158
ROUGE-L F1 score: 0.4762

Original:            
Translated: They became farmers but did not give degrees.
Reference: They emerged as cultivators, but were denied twice - born status.
ROUGE-1 F1 score: 0.2222
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.2222

Original: % s  
Translated: % s authentication failed as authentication failed
Reference: % s authentication failed
ROUGE-1 F1 score: 0.6667
ROUGE-2 F1 score: 0.5714
ROUGE-L F1 score: 0.6667

Original:  - 209, - , 1961-2018
Translated: Section - 209, Income-tax Act, 1961-2018
Reference: Section - 209, Income-tax Act, 1961-2018
ROUGE-1 F1 score: 1.0000
ROUGE-2 F1 score: 1.0000
ROUGE-L F1 score: 1.0000

Original:     . 
Translated: All these summonses were given to the Deputy Commissioner.
Reference: the duties of the rich to the poor and the poor to the rich.
ROUGE-1 F1 score: 0.1739
ROUGE-2 F1 score: 0.0952
ROUGE-L F1 score: 0.1739

Original:  (  )    -   
Translated: Mozilla Firefox is based on Simanski (Mozilla) earlier.
Reference: CIM Key (past in Mozilla) based on mozilla fire box browsing software.
ROUGE-1 F1 score: 0.4000
ROUGE-2 F1 score: 0.1111
ROUGE-L F1 score: 0.4000

Original:       
Translated: Which is associated with the agricultural land.
Reference: Relating to agriculture land.
ROUGE-1 F1 score: 0.3636
ROUGE-2 F1 score: 0.2222
ROUGE-L F1 score: 0.3636

Original:  ,       . 
Translated: But no, CRISC app could not be launched.
Reference: Darn, the kiosk application could not be launched.
ROUGE-1 F1 score: 0.5000
ROUGE-2 F1 score: 0.4286
ROUGE-L F1 score: 0.5000

Original:        
Translated: Skins are a plant of family Euphorbiaceae with dyare specimens.
Reference: A plant of family Euphorbiaceae with brightly colored foliage.
ROUGE-1 F1 score: 0.6316
ROUGE-2 F1 score: 0.5882
ROUGE-L F1 score: 0.6316

Original:             10  . 
Translated: railways contracts had been made when the rate of exchange was 10 pt.
Reference: The railway contracts were made when the exchange was at Is 10d.
ROUGE-1 F1 score: 0.5600
ROUGE-2 F1 score: 0.3478
ROUGE-L F1 score: 0.5600

Original:      
Translated: Charles Simmons, with his efforts, proved to be one of the most despicable and distinction points
Reference: Charlie Simpson helped to raise
ROUGE-1 F1 score: 0.0952
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0952

Original:        
Translated: Please accept my heartfelt congratulations and best wishes.
Reference: Please accept my hearty congratulations and best wishes.
ROUGE-1 F1 score: 0.8750
ROUGE-2 F1 score: 0.7143
ROUGE-L F1 score: 0.8750

Original:     ,         , -              
Translated: The book, which is briefly - inspired by the Rajbhasha and even today - 
Reference: This book- part autobiography, part a conservationists handbook and part travelogue- traces the course of wildlife from the princely and British era to the present.
ROUGE-1 F1 score: 0.2105
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.1579

Original:     ()                 
Translated: Do you consider (Allah) the most wicked is He who has His treasuries and has none
Reference: Do you call upon Ba 'l and leave the best of creators -
ROUGE-1 F1 score: 0.2857
ROUGE-2 F1 score: 0.0769
ROUGE-L F1 score: 0.2143

Original:         
Translated: As he came to know from the later experiments.
Reference: A battery of thirty drag ovens was added a little later.
ROUGE-1 F1 score: 0.1000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.1000

Original:  :      
Translated: . UNEP Project: Streciation of public administration and governance;
Reference: UNDP Project: Strengthening Public Administration and Governance.
ROUGE-1 F1 score: 0.6250
ROUGE-2 F1 score: 0.4286
ROUGE-L F1 score: 0.6250

Original:    , 50              
Translated: The first claim from this relief has been signed few weeks in advance.
Reference: The first tranche - of 50 million US Dollars of this grant - was handed over a few weeks ago.
ROUGE-1 F1 score: 0.3226
ROUGE-2 F1 score: 0.1379
ROUGE-L F1 score: 0.3226

Original:       
Translated: And when the eyes are wrinkled forth, - - then - - they 
Reference: But when sight is confounded
ROUGE-1 F1 score: 0.1429
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.1429

Original:                    
Translated: In certain cases, special provision for entire value of capital for transfer of assets other than capital assets.
Reference: Special provision for full value of consideration for transfer of assets other than capital assets in certain cases.
ROUGE-1 F1 score: 0.8889
ROUGE-2 F1 score: 0.7059
ROUGE-L F1 score: 0.7222

Original:                    . 
Translated: From the point of view, jurisdiction of matters was not based on worth of crime.
Reference: Cases were not classified for jurisdiction according to either the seriousness of the offence or the value of the property involved.
ROUGE-1 F1 score: 0.2778
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.1667

Original:         
Translated: Something that works naturally
Reference: Something which functions naturally.
ROUGE-1 F1 score: 0.5000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.5000

Original:            
Translated: These awards are a collective recognition for the utmost effort and hard work of your years.
Reference: These Awards are a recognition of your years of sincere effort and hard work.
ROUGE-1 F1 score: 0.8000
ROUGE-2 F1 score: 0.5714
ROUGE-L F1 score: 0.6000

Original:          . 
Translated: In such cases, the support assistance will not be available from PODF in any cases either through 
Reference: In such a case, the grant support from PODF is not available.
ROUGE-1 F1 score: 0.6207
ROUGE-2 F1 score: 0.2222
ROUGE-L F1 score: 0.4828

Original:     . 
Translated: The default height of the Composer Window.
Reference: Default height of the Composer Window.
ROUGE-1 F1 score: 0.9231
ROUGE-2 F1 score: 0.9091
ROUGE-L F1 score: 0.9231

Original:     ,  ,                    ; 
Translated: Granting of adequate remunerative staff, as set out for theoretical and practical training; and
Reference: To provide adequate instructional staff, possessing such qualifications as may be prescribed, for imparting practical and theoretical training and facilities for trade test of apprentices; and
ROUGE-1 F1 score: 0.5000
ROUGE-2 F1 score: 0.0526
ROUGE-L F1 score: 0.3500

Original:    ,         -  . 
Translated: These include the units of the hill stove, bamboo huts and other well - kept 
Reference: At these brisk sales there are woollen shawls and sheets, bamboo and other handicraft goods.
ROUGE-1 F1 score: 0.2759
ROUGE-2 F1 score: 0.0741
ROUGE-L F1 score: 0.2759

Original:    ,              
Translated: Mental or emotional indifference is an attribute of lack of enthusiasm or enthusiasm
Reference: a mental or emotional depression, characterized by low level of enthusiasm or eagerness for activity
ROUGE-1 F1 score: 0.4286
ROUGE-2 F1 score: 0.3077
ROUGE-L F1 score: 0.4286

Original:     % s
Translated: Failed to create child process:% s < / s > Failed to create child process
Reference: Failed to create child process'% s':% s'% s'
ROUGE-1 F1 score: 0.7000
ROUGE-2 F1 score: 0.6667
ROUGE-L F1 score: 0.7000

Original: LDAP     ... 
Translated: Reconnecting to LDAP server...
Reference: Reconnecting to LDAP server...
ROUGE-1 F1 score: 1.0000
ROUGE-2 F1 score: 1.0000
ROUGE-L F1 score: 1.0000

Original:                       -  
Translated: When news is brought to one of them, they fall in their bones and wait for a
Reference: When good news of the birth of a female is given to any of them, his face grows dark and inwardly he chokes.
ROUGE-1 F1 score: 0.4000
ROUGE-2 F1 score: 0.0526
ROUGE-L F1 score: 0.3500

Original:     . 
Translated: Invalid authentication response from server.
Reference: Bad authentication response from server.
ROUGE-1 F1 score: 0.8000
ROUGE-2 F1 score: 0.7500
ROUGE-L F1 score: 0.8000

Original:       
Translated: As far as he has been associated with it and followed them, they are bound to agree.
Reference: as between him and them
ROUGE-1 F1 score: 0.2727
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.2727

Original:   ,              ; 
Translated: So face the unbelievers a day when their dejections are severe (some) and
Reference: So leave them until they encounter the day when they will be thunderstruck,
ROUGE-1 F1 score: 0.3077
ROUGE-2 F1 score: 0.0833
ROUGE-L F1 score: 0.3077

Original:              -  ,      
Translated: The device produces a highly stratified goods and drives with it an economies like
Reference: The machine produces much too fast, and brings with it a sort of economic system which I cannot grasp.
ROUGE-1 F1 score: 0.3636
ROUGE-2 F1 score: 0.0645
ROUGE-L F1 score: 0.3030

Original:     ()        ? 
Translated: Or that the Unseen in it (the Quran) which they write down?
Reference: Or is the hidden with them, by which they pass judgements?
ROUGE-1 F1 score: 0.3478
ROUGE-2 F1 score: 0.0952
ROUGE-L F1 score: 0.3478

Original:                   ,          
Translated: Among the skilfully debated learned and author, Balvantrai Thakor, are better in regard to his
Reference: The fiery controversies between him and an equally firm - headed scholar and poet, Balawantrai Thakore, are well known to students of Gujarati literature.
ROUGE-1 F1 score: 0.2632
ROUGE-2 F1 score: 0.0556
ROUGE-L F1 score: 0.2632

Original:          
Translated: Specify the value of the color value for filter - wheel slots
Reference: Assign color values for your filter wheel slots
ROUGE-1 F1 score: 0.6316
ROUGE-2 F1 score: 0.4706
ROUGE-L F1 score: 0.6316

Original:            -
Translated: You are provided two types of options for NPS investment: -
Reference: The NPS offers two approaches to invest subscribers money:
ROUGE-1 F1 score: 0.3000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.2000

Original: , , , , ,             . 
Translated: Suggested government grievances covering electricity, water, waste, labour, etc. should be
Reference: For one, the stranglehold of the Government, which today controls power, water, fertiliser, seeds, wages and trade of agriculture, must be loosened.
ROUGE-1 F1 score: 0.1818
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.1818

Original: (    )                    
Translated: And they whose scales will be light, will be punished by Our command.
Reference: And those whose scales are light are the people who put themselves to ruin  the recompense of the injustice they used to do to Our signs.
ROUGE-1 F1 score: 0.3077
ROUGE-2 F1 score: 0.0541
ROUGE-L F1 score: 0.2564

Original:  1928                
Translated: From 1926 to 1928, Jawaharlal was served as General Secretary of All India Congress Committee. 1926
Reference: from 1926 to 1928, jawaharlal nehru served as the main representative of the all india national committee 1926
ROUGE-1 F1 score: 0.7059
ROUGE-2 F1 score: 0.4375
ROUGE-L F1 score: 0.7059

Original:      
Translated: dressed herself well, and she 'd rather be dressed up with her.
Reference: After a quick bath, they get into their best clothes.
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original:    ,     , ,                 
Translated: They are universal people who atrophy our minds from fundamentalismos, dalliancer, oppressors and
Reference: They are universal men, who free ourminds from bigotry and superstition, dogma and ritual, and emphasise the central simplicities of religion.
ROUGE-1 F1 score: 0.3529
ROUGE-2 F1 score: 0.1250
ROUGE-L F1 score: 0.3529

Original:         , ,        
Translated: Conduct inspection, verification, surveillance and overall process related submitted policy.
Reference: Revised draft Policy on Inspection, Verification, Monitoring and Overall Procedure Relating to Grant of Forest Clearances and Identification of Forests
ROUGE-1 F1 score: 0.4000
ROUGE-2 F1 score: 0.1429
ROUGE-L F1 score: 0.3333

Original:        
Translated: The proposals of the Rules are invited to invite further kommentarer of the stakeholders
Reference: Draft Recruitment Rules for comments from Stakeholders
ROUGE-1 F1 score: 0.1905
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.1905

Original:  -      
Translated: Measure in full, pure expenses, and do not be of the deserved 
Reference: Give full measure and do not cheat;
ROUGE-1 F1 score: 0.5263
ROUGE-2 F1 score: 0.2353
ROUGE-L F1 score: 0.4211

Original:            
Translated: The term Sujhaarishi occurred about two decades ago.
Reference: The term, Good Governance, appeared in the development lexicon about two decades back.
ROUGE-1 F1 score: 0.4762
ROUGE-2 F1 score: 0.3158
ROUGE-L F1 score: 0.4762

Original:          . 
Translated: The Mixed Haemorrhage refers to changes in the human gallows.
Reference: Mixed Albuminurai is related to the changes in the human kidney.
ROUGE-1 F1 score: 0.6667
ROUGE-2 F1 score: 0.3158
ROUGE-L F1 score: 0.5714

Original:            ,         /  
Translated: It has a widespread potential for increasing and upgrading the crops.
Reference: Considering the utility and food value of various palm products, there is immense potential / scope for further growth and development.
ROUGE-1 F1 score: 0.2581
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.1935

Original:    ,    .             . 
Translated: Something went wrong, while loading this page. Please go to a different page to continue.
Reference: Something went wrong while displaying this page. Please reload or visit a different page to continue.
ROUGE-1 F1 score: 0.7742
ROUGE-2 F1 score: 0.6207
ROUGE-L F1 score: 0.7742

Original:      '92      1994    . 
Translated: The share bond which the Ambani Ghani aunty was released in December 1994.
Reference: The share warrants issued to the Ambanis in December 1992 were actually allotted to them in 1994.
ROUGE-1 F1 score: 0.4667
ROUGE-2 F1 score: 0.2143
ROUGE-L F1 score: 0.4667

Original:                   
Translated: The choice of books included therewith has been seriously done in this respect.
Reference: Those recommended here are chosen with care and definite purpose.
ROUGE-1 F1 score: 0.0000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.0000

Original:              , ,   , ,        
Translated: Our country will benefit from INSR application which includes spatial, marine landing, vehicle management, etc.
Reference: The nation will immensely benefit from the applications of IRNSS which include terrestrial, aerial and marine navigation, disaster management, vehicle tracking and fleet management etc.
ROUGE-1 F1 score: 0.5000
ROUGE-2 F1 score: 0.1579
ROUGE-L F1 score: 0.5000

Original:  URL  
Translated: Remove the file URL:
Reference: File / URL to Remove:
ROUGE-1 F1 score: 0.7500
ROUGE-2 F1 score: 0.3333
ROUGE-L F1 score: 0.5000

Original:           /           
Translated: The State Governments / UTs are asked to pass periodical information by the Education Department of Govt.
Reference: The State Government / UT is also required to submit periodic returns to the Department of School Education and Literacy, Government of India to provide information on:
ROUGE-1 F1 score: 0.4762
ROUGE-2 F1 score: 0.1500
ROUGE-L F1 score: 0.3810

Original: 50                  
Translated: After 50 years of tireless imprint, Costa Rica has taken an extraordinarily good fare.
Reference: More than 50 years later, Costa Rica is still seeing the benefits of this enlightened position.
ROUGE-1 F1 score: 0.3333
ROUGE-2 F1 score: 0.1429
ROUGE-L F1 score: 0.2667

Original:  "         "-              
Translated: "And do good deeds; verily I shall see what you used to do.
Reference: Saying: "Make you perfect coats of mail, balancing well the rings of chain armour, and work you (men) righteousness. Truly, I am AllSeer of what you do."
ROUGE-1 F1 score: 0.2500
ROUGE-2 F1 score: 0.0526
ROUGE-L F1 score: 0.2500

Original:                  
Translated: forward from the recess and you can write a signal here and you can write a text
Reference: flip the slide back and forth and you have a pointer and you can type text on the
ROUGE-1 F1 score: 0.4571
ROUGE-2 F1 score: 0.1818
ROUGE-L F1 score: 0.4571

Original:  ,      , 
Translated: This Orchid is called Orchid - Orchid - This is called Orchid -
Reference: This orchid, known as Darwin 's orchid,
ROUGE-1 F1 score: 0.3529
ROUGE-2 F1 score: 0.1333
ROUGE-L F1 score: 0.3529

Original:       
Translated: Please include commission on sale of laceiries and commission on purchase of laceiries.
Reference: Commission, etc., on the sale of lottery tickets.
ROUGE-1 F1 score: 0.3810
ROUGE-2 F1 score: 0.1053
ROUGE-L F1 score: 0.3810

Original: . 5/4/2011-. . ()  14-07-2011
Translated: No. 5 / 4 / 2011 - Ralbal (Service) Date 14 - 07 - 2011
Reference: No. 5 / 4 / 20ll - Ralbal (Service) Date 14 - 07 - 2011
ROUGE-1 F1 score: 0.9000
ROUGE-2 F1 score: 0.7778
ROUGE-L F1 score: 0.9000

Original:                     . 
Translated: For jihad in In Laden, the International Intellectual Reserve of America and Israel, one hundred of ethnic
Reference: Bin Laden 's International Islamic Front for Jehad against the US and Israel brings together nearly a dozen Islamic terrorist groups.
ROUGE-1 F1 score: 0.3158
ROUGE-2 F1 score: 0.0556
ROUGE-L F1 score: 0.2105

Original:     3
Translated: Google Talk Work Name 3
Reference: Google Talk Work Name 3
ROUGE-1 F1 score: 1.0000
ROUGE-2 F1 score: 1.0000
ROUGE-L F1 score: 1.0000

Original:     
Translated: IFCI's contributing to the economy and contributes to the economy of Nepal, according to
Reference: IFCI 's ECONOMIC CONTRIBUTION
ROUGE-1 F1 score: 0.3158
ROUGE-2 F1 score: 0.1176
ROUGE-L F1 score: 0.3158

Original:   , 1953
Translated: The Collections of Statistics Act, 1953 was mooted in all the works of the Collections Act and the Act that contain
Reference: The Collections of Statistics Act, 1953
ROUGE-1 F1 score: 0.4444
ROUGE-2 F1 score: 0.4000
ROUGE-L F1 score: 0.4444

Original:    -    
Translated: His notable authors will remain for ever in the country.
Reference: Their unknown authors came from all over the country.
ROUGE-1 F1 score: 0.3158
ROUGE-2 F1 score: 0.1176
ROUGE-L F1 score: 0.3158

Original:              
Translated: When a child has fever or exaggeration, it is considered worthy of a gift to
Reference: It is especially useful when the child has fever and diarrhoea.
ROUGE-1 F1 score: 0.4615
ROUGE-2 F1 score: 0.2500
ROUGE-L F1 score: 0.3077

Original:          
Translated: The cost will be levied within the Court within four working days.
Reference: The costs shall be deposited in the Court within four weeks.
ROUGE-1 F1 score: 0.6087
ROUGE-2 F1 score: 0.3810
ROUGE-L F1 score: 0.6087

Original:              
Translated: The process of bringing some change in economic matters.
Reference: To make something different in economic matters or a process of change in economic matters.
ROUGE-1 F1 score: 0.5000
ROUGE-2 F1 score: 0.3636
ROUGE-L F1 score: 0.5000

Original:                       
Translated: Mr. Suratand Gauhar was charged with the Ministry of Chemicals and Fertilizers and
Reference: SHRI D. V. SADANANDA GOWDA AND SHRI NARENDRA SINGH TOMAR GETS ADDITIONAL CHARGE OF THE MINISTRY OF CHEMICALS &amp; FERTILIZERS AND THE MINISTRY OF PARLIAMENTARY AFFAIRS RESPECTIVELY
ROUGE-1 F1 score: 0.4000
ROUGE-2 F1 score: 0.2105
ROUGE-L F1 score: 0.3500

Original:                      
Translated: It provides for reducing damage for comparatively lower costs and for incurring cases of fatal
Reference: It provides for risk cover at a comparatively low cost and relief for disability arising due to accident or illness.
ROUGE-1 F1 score: 0.4000
ROUGE-2 F1 score: 0.1818
ROUGE-L F1 score: 0.4000

Original:    21 
Translated: And the thing that 's going on is 21, and it' s 21 - prostrate.
Reference: And that 's twenty - one.
ROUGE-1 F1 score: 0.3158
ROUGE-2 F1 score: 0.1176
ROUGE-L F1 score: 0.3158

Original:              
Translated: And it 's a basic factor as to the basic reason for us think that age is
Reference: And the fundamental reason, I think, why we feel that aging is inevitable
ROUGE-1 F1 score: 0.4667
ROUGE-2 F1 score: 0.1429
ROUGE-L F1 score: 0.4667

Original:             
Translated: Practice as well as effective check in this area for appropriate and effective detection.
Reference: To devise suitable and effective check-point for this purpose.
ROUGE-1 F1 score: 0.4167
ROUGE-2 F1 score: 0.1818
ROUGE-L F1 score: 0.2500

Original:    
Translated: The automobile industry in India has become one of the biggest losers in the transport industry across India.
Reference: Automotive industry in India
ROUGE-1 F1 score: 0.2727
ROUGE-2 F1 score: 0.2000
ROUGE-L F1 score: 0.2727

Original:       . 
Translated: Send selected contacts to another person
Reference: Send selected contacts to another person
ROUGE-1 F1 score: 1.0000
ROUGE-2 F1 score: 1.0000
ROUGE-L F1 score: 1.0000

Original:     
Translated: Wooden belt was factory de - manufactured wooden belt.
Reference: Wooden Marker is developed.
ROUGE-1 F1 score: 0.1667
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.1667

Original:              
Translated: A solid external membrane which covers the palp with the entire eye, shrinking with the turbid
Reference: a tough, white, outer layer of the eye covering all the eyeball except cornea
ROUGE-1 F1 score: 0.3333
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.2667

Original:               ? 
Translated: Where even after large technological changes people are filming?
Reference: full of innovative people making films despite great technical odds?
ROUGE-1 F1 score: 0.2105
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.2105

Original:     -     
Translated: They help you green out and clean your environment.
Reference: They keep your environment green and healthy
ROUGE-1 F1 score: 0.6250
ROUGE-2 F1 score: 0.1429
ROUGE-L F1 score: 0.3750

Original:    -            
Translated: Along with the causes of the lingh, the shrubs of the goose are seen
Reference: You can see the beautiful meadows and huts of the shepherds along this route.
ROUGE-1 F1 score: 0.2857
ROUGE-2 F1 score: 0.0769
ROUGE-L F1 score: 0.2143

Original:                       
Translated: These two songs became very popular and the dialogues were extremely popular between the directors and
Reference: These two songs became very popular and also Ralesh Khana the actor of the film including film director got huge popularty.
ROUGE-1 F1 score: 0.5405
ROUGE-2 F1 score: 0.3429
ROUGE-L F1 score: 0.5405

Original:                       , 2006     
Translated: The National Project for Rural Water Quality Improvement and Enforcement Programme was launched in February, 2006.
Reference: To further strengthen community participation in the drinking water sector for sustainability, National Rural Drinking Water Quality Monitoring & Surveillance programme has been launched in February, 2006
ROUGE-1 F1 score: 0.5238
ROUGE-2 F1 score: 0.2000
ROUGE-L F1 score: 0.4762

Original:       ,     
Translated: except the sincere worshipers of Allah.
Reference: except for God 's sincere servants;
ROUGE-1 F1 score: 0.3333
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.3333

Original:     (        ) 
Translated: Howe schemes in India (External website that opens in a new window)
Reference: EcomarkScheme of India (External website that opens in a new window)
ROUGE-1 F1 score: 0.7826
ROUGE-2 F1 score: 0.7619
ROUGE-L F1 score: 0.7826

Original:      ... 
Translated: View the details of the account...
Reference: Looking up account details...
ROUGE-1 F1 score: 0.4000
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.2000

Original:     RSS     
Translated: Display a RSS or item feed on your video.
Reference: Display a RSS or ATOM Feed on your video
ROUGE-1 F1 score: 0.8889
ROUGE-2 F1 score: 0.7500
ROUGE-L F1 score: 0.8889

Original:       -  ,       ! 
Translated: Those who hold God along with God they shall know.
Reference: Who set up along with Allah anot her god; presently they shall know.
ROUGE-1 F1 score: 0.6087
ROUGE-2 F1 score: 0.2857
ROUGE-L F1 score: 0.6087

Original:     
Translated: A set of reference related to medication.
Reference: A collection related to drugs.
ROUGE-1 F1 score: 0.5000
ROUGE-2 F1 score: 0.2000
ROUGE-L F1 score: 0.5000

Original:   1.0   (c) 2002  .  http:// www. reallyslick. com/     
Translated: SpamAssassin - 0. 0 server (c) 2002 Written by Scarlett M. Wills http
Reference: Solar Winds 1. 0 Copyright (c) 2002 Terence M. Welsh http: / / www. reallyslick. com / Ported to KDE by Karl Robillard
ROUGE-1 F1 score: 0.3750
ROUGE-2 F1 score: 0.0667
ROUGE-L F1 score: 0.3125

Original:      1000       
Translated: He said the State has already constructed 1000 km of new rail lines.
Reference: He added another 1000 km of new rail lines are under construction.
ROUGE-1 F1 score: 0.6400
ROUGE-2 F1 score: 0.4348
ROUGE-L F1 score: 0.5600

Original:        ,              
Translated: Instead of co - operative medication, it is not taken as magical pill.
Reference: The rasayana therapy therefore cannot be capsulated into a sort of magic pill and taken without paying heed to the concomitant therapies.
ROUGE-1 F1 score: 0.2353
ROUGE-2 F1 score: 0.0625
ROUGE-L F1 score: 0.1765

Original:          
Translated: CLICK HERE to change your name or color
Reference: Click here to change your name and / or color
ROUGE-1 F1 score: 0.9412
ROUGE-2 F1 score: 0.8000
ROUGE-L F1 score: 0.9412

Original:             
Translated: Calculating interest rate increases very heavily from monthly expenses.
Reference: Monthly installments increases more because of compound interst.
ROUGE-1 F1 score: 0.2353
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.1176

Original:   -     
Translated: sex and foreign sexual connections are carried out
Reference: Orogenital sex is being performed.
ROUGE-1 F1 score: 0.1538
ROUGE-2 F1 score: 0.0000
ROUGE-L F1 score: 0.1538

Average METEOR score: 0.4144
Original:   1315    
Translated: This release issued at 1315 hrs.
Reference: This release issued at 1315 hrs.
METEOR score: 0.9995

Original:               
Translated: Time estimates are drawn from the heavenly position of the stars.
Reference: The passage of time during nights is reckoned by having a look at the position of the stars above.
METEOR score: 0.3054

Original: (   ,   ,  , ,  , , ,,   , , ,  ,   )
Translated: In the field of Purabity, minimum standards of monopoly and epigraphis, procurement, administration, p
Reference: (In the field of Archaeology, Numismatics & Epigraphy, Pre History, Anthropology, Fine Arts, Conservation,  Publication, Administration, Finance & Accounts, Establishment, Civil, Legal matters, Stores & Purchase).
METEOR score: 0.1347

Original:                      
Translated: When innovative measures are not directly beneficial for others, they often stop them.
Reference: People often lose interest in egalitarian measures when such measures do not directly benefit them.
METEOR score: 0.4185

Original:  ,    . '' 
Translated: He wanted to have a merchant.  he remarked.
Reference: He said, 'Hero banna chahta hoon'. 
METEOR score: 0.2997

Original:               
Translated: For work in Noord - Loire, Please write these:
Reference: 33. For work permits to work in Northern Ireland, please write to: 33
METEOR score: 0.2855

Original:            
Translated: They became farmers but did not give degrees.
Reference: They emerged as cultivators, but were denied twice - born status.
METEOR score: 0.1289

Original: % s  
Translated: % s authentication failed as authentication failed
Reference: % s authentication failed
METEOR score: 0.8463

Original:  - 209, - , 1961-2018
Translated: Section - 209, Income-tax Act, 1961-2018
Reference: Section - 209, Income-tax Act, 1961-2018
METEOR score: 0.9998

Original:     . 
Translated: All these summonses were given to the Deputy Commissioner.
Reference: the duties of the rich to the poor and the poor to the rich.
METEOR score: 0.1587

Original:  (  )    -   
Translated: Mozilla Firefox is based on Simanski (Mozilla) earlier.
Reference: CIM Key (past in Mozilla) based on mozilla fire box browsing software.
METEOR score: 0.4227

Original:       
Translated: Which is associated with the agricultural land.
Reference: Relating to agriculture land.
METEOR score: 0.3407

Original:  ,       . 
Translated: But no, CRISC app could not be launched.
Reference: Darn, the kiosk application could not be launched.
METEOR score: 0.6310

Original:        
Translated: Skins are a plant of family Euphorbiaceae with dyare specimens.
Reference: A plant of family Euphorbiaceae with brightly colored foliage.
METEOR score: 0.6090

Original:             10  . 
Translated: railways contracts had been made when the rate of exchange was 10 pt.
Reference: The railway contracts were made when the exchange was at Is 10d.
METEOR score: 0.4936

Original:      
Translated: Charles Simmons, with his efforts, proved to be one of the most despicable and distinction points
Reference: Charlie Simpson helped to raise
METEOR score: 0.1149

Original:        
Translated: Please accept my heartfelt congratulations and best wishes.
Reference: Please accept my hearty congratulations and best wishes.
METEOR score: 0.9320

Original:     ,         , -              
Translated: The book, which is briefly - inspired by the Rajbhasha and even today - 
Reference: This book- part autobiography, part a conservationists handbook and part travelogue- traces the course of wildlife from the princely and British era to the present.
METEOR score: 0.1531

Original:     ()                 
Translated: Do you consider (Allah) the most wicked is He who has His treasuries and has none
Reference: Do you call upon Ba 'l and leave the best of creators -
METEOR score: 0.2090

Original:         
Translated: As he came to know from the later experiments.
Reference: A battery of thirty drag ovens was added a little later.
METEOR score: 0.1290

Original:  :      
Translated: . UNEP Project: Streciation of public administration and governance;
Reference: UNDP Project: Strengthening Public Administration and Governance.
METEOR score: 0.5639

Original:    , 50              
Translated: The first claim from this relief has been signed few weeks in advance.
Reference: The first tranche - of 50 million US Dollars of this grant - was handed over a few weeks ago.
METEOR score: 0.3422

Original:       
Translated: And when the eyes are wrinkled forth, - - then - - they 
Reference: But when sight is confounded
METEOR score: 0.1579

Original:                    
Translated: In certain cases, special provision for entire value of capital for transfer of assets other than capital assets.
Reference: Special provision for full value of consideration for transfer of assets other than capital assets in certain cases.
METEOR score: 0.8140

Original:                    . 
Translated: From the point of view, jurisdiction of matters was not based on worth of crime.
Reference: Cases were not classified for jurisdiction according to either the seriousness of the offence or the value of the property involved.
METEOR score: 0.2360

Original:         
Translated: Something that works naturally
Reference: Something which functions naturally.
METEOR score: 0.3628

Original:            
Translated: These awards are a collective recognition for the utmost effort and hard work of your years.
Reference: These Awards are a recognition of your years of sincere effort and hard work.
METEOR score: 0.6886

Original:          . 
Translated: In such cases, the support assistance will not be available from PODF in any cases either through 
Reference: In such a case, the grant support from PODF is not available.
METEOR score: 0.5320

Original:     . 
Translated: The default height of the Composer Window.
Reference: Default height of the Composer Window.
METEOR score: 0.9896

Original:     ,  ,                    ; 
Translated: Granting of adequate remunerative staff, as set out for theoretical and practical training; and
Reference: To provide adequate instructional staff, possessing such qualifications as may be prescribed, for imparting practical and theoretical training and facilities for trade test of apprentices; and
METEOR score: 0.3433

Original:    ,         -  . 
Translated: These include the units of the hill stove, bamboo huts and other well - kept 
Reference: At these brisk sales there are woollen shawls and sheets, bamboo and other handicraft goods.
METEOR score: 0.2882

Original:    ,              
Translated: Mental or emotional indifference is an attribute of lack of enthusiasm or enthusiasm
Reference: a mental or emotional depression, characterized by low level of enthusiasm or eagerness for activity
METEOR score: 0.4813

Original:     % s
Translated: Failed to create child process:% s < / s > Failed to create child process
Reference: Failed to create child process'% s':% s'% s'
METEOR score: 0.5829

Original: LDAP     ... 
Translated: Reconnecting to LDAP server...
Reference: Reconnecting to LDAP server...
METEOR score: 0.9990

Original:                       -  
Translated: When news is brought to one of them, they fall in their bones and wait for a
Reference: When good news of the birth of a female is given to any of them, his face grows dark and inwardly he chokes.
METEOR score: 0.3477

Original:     . 
Translated: Invalid authentication response from server.
Reference: Bad authentication response from server.
METEOR score: 0.8431

Original:       
Translated: As far as he has been associated with it and followed them, they are bound to agree.
Reference: as between him and them
METEOR score: 0.2597

Original:   ,              ; 
Translated: So face the unbelievers a day when their dejections are severe (some) and
Reference: So leave them until they encounter the day when they will be thunderstruck,
METEOR score: 0.1948

Original:              -  ,      
Translated: The device produces a highly stratified goods and drives with it an economies like
Reference: The machine produces much too fast, and brings with it a sort of economic system which I cannot grasp.
METEOR score: 0.2607

Original:     ()        ? 
Translated: Or that the Unseen in it (the Quran) which they write down?
Reference: Or is the hidden with them, by which they pass judgements?
METEOR score: 0.3488

Original:                   ,          
Translated: Among the skilfully debated learned and author, Balvantrai Thakor, are better in regard to his
Reference: The fiery controversies between him and an equally firm - headed scholar and poet, Balawantrai Thakore, are well known to students of Gujarati literature.
METEOR score: 0.1354

Original:          
Translated: Specify the value of the color value for filter - wheel slots
Reference: Assign color values for your filter wheel slots
METEOR score: 0.5021

Original:            -
Translated: You are provided two types of options for NPS investment: -
Reference: The NPS offers two approaches to invest subscribers money:
METEOR score: 0.2838

Original: , , , , ,             . 
Translated: Suggested government grievances covering electricity, water, waste, labour, etc. should be
Reference: For one, the stranglehold of the Government, which today controls power, water, fertiliser, seeds, wages and trade of agriculture, must be loosened.
METEOR score: 0.1693

Original: (    )                    
Translated: And they whose scales will be light, will be punished by Our command.
Reference: And those whose scales are light are the people who put themselves to ruin  the recompense of the injustice they used to do to Our signs.
METEOR score: 0.2354

Original:  1928                
Translated: From 1926 to 1928, Jawaharlal was served as General Secretary of All India Congress Committee. 1926
Reference: from 1926 to 1928, jawaharlal nehru served as the main representative of the all india national committee 1926
METEOR score: 0.6207

Original:      
Translated: dressed herself well, and she 'd rather be dressed up with her.
Reference: After a quick bath, they get into their best clothes.
METEOR score: 0.0915

Original:    ,     , ,                 
Translated: They are universal people who atrophy our minds from fundamentalismos, dalliancer, oppressors and
Reference: They are universal men, who free ourminds from bigotry and superstition, dogma and ritual, and emphasise the central simplicities of religion.
METEOR score: 0.2692

Original:         , ,        
Translated: Conduct inspection, verification, surveillance and overall process related submitted policy.
Reference: Revised draft Policy on Inspection, Verification, Monitoring and Overall Procedure Relating to Grant of Forest Clearances and Identification of Forests
METEOR score: 0.3399

Original:        
Translated: The proposals of the Rules are invited to invite further kommentarer of the stakeholders
Reference: Draft Recruitment Rules for comments from Stakeholders
METEOR score: 0.2818

Original:  -      
Translated: Measure in full, pure expenses, and do not be of the deserved 
Reference: Give full measure and do not cheat;
METEOR score: 0.4032

Original:            
Translated: The term Sujhaarishi occurred about two decades ago.
Reference: The term, Good Governance, appeared in the development lexicon about two decades back.
METEOR score: 0.3127

Original:          . 
Translated: The Mixed Haemorrhage refers to changes in the human gallows.
Reference: Mixed Albuminurai is related to the changes in the human kidney.
METEOR score: 0.5017

Original:            ,         /  
Translated: It has a widespread potential for increasing and upgrading the crops.
Reference: Considering the utility and food value of various palm products, there is immense potential / scope for further growth and development.
METEOR score: 0.2242

Original:    ,    .             . 
Translated: Something went wrong, while loading this page. Please go to a different page to continue.
Reference: Something went wrong while displaying this page. Please reload or visit a different page to continue.
METEOR score: 0.7107

Original:      '92      1994    . 
Translated: The share bond which the Ambani Ghani aunty was released in December 1994.
Reference: The share warrants issued to the Ambanis in December 1992 were actually allotted to them in 1994.
METEOR score: 0.3911

Original:                   
Translated: The choice of books included therewith has been seriously done in this respect.
Reference: Those recommended here are chosen with care and definite purpose.
METEOR score: 0.0352

Original:              , ,   , ,        
Translated: Our country will benefit from INSR application which includes spatial, marine landing, vehicle management, etc.
Reference: The nation will immensely benefit from the applications of IRNSS which include terrestrial, aerial and marine navigation, disaster management, vehicle tracking and fleet management etc.
METEOR score: 0.2840

Original:  URL  
Translated: Remove the file URL:
Reference: File / URL to Remove:
METEOR score: 0.4769

Original:           /           
Translated: The State Governments / UTs are asked to pass periodical information by the Education Department of Govt.
Reference: The State Government / UT is also required to submit periodic returns to the Department of School Education and Literacy, Government of India to provide information on:
METEOR score: 0.2907

Original: 50                  
Translated: After 50 years of tireless imprint, Costa Rica has taken an extraordinarily good fare.
Reference: More than 50 years later, Costa Rica is still seeing the benefits of this enlightened position.
METEOR score: 0.3222

Original:  "         "-              
Translated: "And do good deeds; verily I shall see what you used to do.
Reference: Saying: "Make you perfect coats of mail, balancing well the rings of chain armour, and work you (men) righteousness. Truly, I am AllSeer of what you do."
METEOR score: 0.1201

Original:                  
Translated: forward from the recess and you can write a signal here and you can write a text
Reference: flip the slide back and forth and you have a pointer and you can type text on the
METEOR score: 0.4251

Original:  ,      , 
Translated: This Orchid is called Orchid - Orchid - This is called Orchid -
Reference: This orchid, known as Darwin 's orchid,
METEOR score: 0.3389

Original:       
Translated: Please include commission on sale of laceiries and commission on purchase of laceiries.
Reference: Commission, etc., on the sale of lottery tickets.
METEOR score: 0.1923

Original: . 5/4/2011-. . ()  14-07-2011
Translated: No. 5 / 4 / 2011 - Ralbal (Service) Date 14 - 07 - 2011
Reference: No. 5 / 4 / 20ll - Ralbal (Service) Date 14 - 07 - 2011
METEOR score: 0.9234

Original:                     . 
Translated: For jihad in In Laden, the International Intellectual Reserve of America and Israel, one hundred of ethnic
Reference: Bin Laden 's International Islamic Front for Jehad against the US and Israel brings together nearly a dozen Islamic terrorist groups.
METEOR score: 0.1878

Original:     3
Translated: Google Talk Work Name 3
Reference: Google Talk Work Name 3
METEOR score: 0.9960

Original:     
Translated: IFCI's contributing to the economy and contributes to the economy of Nepal, according to
Reference: IFCI 's ECONOMIC CONTRIBUTION
METEOR score: 0.3467

Original:   , 1953
Translated: The Collections of Statistics Act, 1953 was mooted in all the works of the Collections Act and the Act that contain
Reference: The Collections of Statistics Act, 1953
METEOR score: 0.6576

Original:    -    
Translated: His notable authors will remain for ever in the country.
Reference: Their unknown authors came from all over the country.
METEOR score: 0.3902

Original:              
Translated: When a child has fever or exaggeration, it is considered worthy of a gift to
Reference: It is especially useful when the child has fever and diarrhoea.
METEOR score: 0.4096

Original:          
Translated: The cost will be levied within the Court within four working days.
Reference: The costs shall be deposited in the Court within four weeks.
METEOR score: 0.5257

Original:              
Translated: The process of bringing some change in economic matters.
Reference: To make something different in economic matters or a process of change in economic matters.
METEOR score: 0.4337

Original:                       
Translated: Mr. Suratand Gauhar was charged with the Ministry of Chemicals and Fertilizers and
Reference: SHRI D. V. SADANANDA GOWDA AND SHRI NARENDRA SINGH TOMAR GETS ADDITIONAL CHARGE OF THE MINISTRY OF CHEMICALS &amp; FERTILIZERS AND THE MINISTRY OF PARLIAMENTARY AFFAIRS RESPECTIVELY
METEOR score: 0.0846

Original:                      
Translated: It provides for reducing damage for comparatively lower costs and for incurring cases of fatal
Reference: It provides for risk cover at a comparatively low cost and relief for disability arising due to accident or illness.
METEOR score: 0.2991

Original:    21 
Translated: And the thing that 's going on is 21, and it' s 21 - prostrate.
Reference: And that 's twenty - one.
METEOR score: 0.4786

Original:              
Translated: And it 's a basic factor as to the basic reason for us think that age is
Reference: And the fundamental reason, I think, why we feel that aging is inevitable
METEOR score: 0.3259

Original:             
Translated: Practice as well as effective check in this area for appropriate and effective detection.
Reference: To devise suitable and effective check-point for this purpose.
METEOR score: 0.3500

Original:    
Translated: The automobile industry in India has become one of the biggest losers in the transport industry across India.
Reference: Automotive industry in India
METEOR score: 0.2899

Original:       . 
Translated: Send selected contacts to another person
Reference: Send selected contacts to another person
METEOR score: 0.9990

Original:     
Translated: Wooden belt was factory de - manufactured wooden belt.
Reference: Wooden Marker is developed.
METEOR score: 0.3670

Original:              
Translated: A solid external membrane which covers the palp with the entire eye, shrinking with the turbid
Reference: a tough, white, outer layer of the eye covering all the eyeball except cornea
METEOR score: 0.1948

Original:               ? 
Translated: Where even after large technological changes people are filming?
Reference: full of innovative people making films despite great technical odds?
METEOR score: 0.1899

Original:     -     
Translated: They help you green out and clean your environment.
Reference: They keep your environment green and healthy
METEOR score: 0.4635

Original:    -            
Translated: Along with the causes of the lingh, the shrubs of the goose are seen
Reference: You can see the beautiful meadows and huts of the shepherds along this route.
METEOR score: 0.3100

Original:                       
Translated: These two songs became very popular and the dialogues were extremely popular between the directors and
Reference: These two songs became very popular and also Ralesh Khana the actor of the film including film director got huge popularty.
METEOR score: 0.5102

Original:                       , 2006     
Translated: The National Project for Rural Water Quality Improvement and Enforcement Programme was launched in February, 2006.
Reference: To further strengthen community participation in the drinking water sector for sustainability, National Rural Drinking Water Quality Monitoring & Surveillance programme has been launched in February, 2006
METEOR score: 0.3323

Original:       ,     
Translated: except the sincere worshipers of Allah.
Reference: except for God 's sincere servants;
METEOR score: 0.2166

Original:     (        ) 
Translated: Howe schemes in India (External website that opens in a new window)
Reference: EcomarkScheme of India (External website that opens in a new window)
METEOR score: 0.7141

Original:      ... 
Translated: View the details of the account...
Reference: Looking up account details...
METEOR score: 0.2459

Original:     RSS     
Translated: Display a RSS or item feed on your video.
Reference: Display a RSS or ATOM Feed on your video
METEOR score: 0.7752

Original:       -  ,       ! 
Translated: Those who hold God along with God they shall know.
Reference: Who set up along with Allah anot her god; presently they shall know.
METEOR score: 0.5772

Original:     
Translated: A set of reference related to medication.
Reference: A collection related to drugs.
METEOR score: 0.4537

Original:   1.0   (c) 2002  .  http:// www. reallyslick. com/     
Translated: SpamAssassin - 0. 0 server (c) 2002 Written by Scarlett M. Wills http
Reference: Solar Winds 1. 0 Copyright (c) 2002 Terence M. Welsh http: / / www. reallyslick. com / Ported to KDE by Karl Robillard
METEOR score: 0.2840

Original:      1000       
Translated: He said the State has already constructed 1000 km of new rail lines.
Reference: He added another 1000 km of new rail lines are under construction.
METEOR score: 0.6511

Original:        ,              
Translated: Instead of co - operative medication, it is not taken as magical pill.
Reference: The rasayana therapy therefore cannot be capsulated into a sort of magic pill and taken without paying heed to the concomitant therapies.
METEOR score: 0.1181

Original:          
Translated: CLICK HERE to change your name or color
Reference: Click here to change your name and / or color
METEOR score: 0.6169

Original:             
Translated: Calculating interest rate increases very heavily from monthly expenses.
Reference: Monthly installments increases more because of compound interst.
METEOR score: 0.4107

Original:   -     
Translated: sex and foreign sexual connections are carried out
Reference: Orogenital sex is being performed.
METEOR score: 0.1087

TIME_translation_testing_finetuned_4: 20.43 seconds
